<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog | Yassir Boulaamane</title>
    <link>https://yboulaamane.github.io/blog/</link>
      <atom:link href="https://yboulaamane.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <description>Blog</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 24 Dec 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yboulaamane.github.io/media/icon_hu_4d696a8ace2a642b.png</url>
      <title>Blog</title>
      <link>https://yboulaamane.github.io/blog/</link>
    </image>
    
    <item>
      <title>Stop Using B3LYP/6-31G*: Critical Pitfalls in Modern DFT Calculations and How to Avoid Them</title>
      <link>https://yboulaamane.github.io/blog/stop-using-b3lyp6-31g-a-2022-guide-to-best-practice-dft-protocols/</link>
      <pubDate>Wed, 24 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/stop-using-b3lyp6-31g-a-2022-guide-to-best-practice-dft-protocols/</guid>
      <description>&lt;p&gt;Density Functional Theory (DFT) has become the workhorse of computational chemistry, enabling routine access to molecular structures, reaction mechanisms, and noncovalent interactions at a reasonable computational cost. However, as with molecular dynamics simulations, DFT is not a black-box technique. Seemingly minor methodological choices can introduce systematic errors that quietly undermine the physical validity of the results.&lt;/p&gt;
&lt;p&gt;One of the most persistent problems in the field is the continued use of outdated protocols—most notably &lt;strong&gt;B3LYP/6-31G&lt;/strong&gt;*—long after their limitations have been clearly demonstrated. These calculations rarely fail numerically. Instead, they produce results that appear reasonable while being quantitatively wrong.&lt;/p&gt;
&lt;p&gt;This article outlines the most critical pitfalls in modern DFT calculations and provides best-practice strategies to ensure accuracy, robustness, and reproducibility.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-treating-b3lyp6-31g-as-a-safe-default&#34;&gt;1. Treating B3LYP/6-31G* as a Safe Default&lt;/h2&gt;
&lt;p&gt;For many years, B3LYP/6-31G* was considered an acceptable compromise between accuracy and efficiency. Today, this assumption is no longer valid. This protocol lacks an explicit description of London dispersion interactions and suffers from severe basis set limitations, leading to artificial error cancellation.&lt;/p&gt;
&lt;p&gt;As a result, reaction energies, conformational preferences, and intermolecular interactions are often misrepresented, with errors frequently exceeding chemical accuracy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
B3LYP/6-31G* should be avoided for production calculations. Modern alternatives such as &lt;strong&gt;r²SCAN-3c&lt;/strong&gt; or dispersion-corrected functionals with appropriate basis sets provide substantially improved accuracy at comparable computational cost.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-ignoring-london-dispersion-interactions&#34;&gt;2. Ignoring London Dispersion Interactions&lt;/h2&gt;
&lt;p&gt;Standard DFT functionals do not account for long-range electron correlation. Without explicit correction, dispersion interactions are entirely absent, leading to overly repulsive potential energy surfaces.&lt;/p&gt;
&lt;p&gt;This omission severely affects noncovalent interactions, conformational equilibria, and binding energies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Dispersion corrections are mandatory in modern DFT. Always include schemes such as &lt;strong&gt;D3(BJ)&lt;/strong&gt; or &lt;strong&gt;D4&lt;/strong&gt;, or use functionals with built-in nonlocal correlation. The additional cost is negligible compared to the improvement in physical realism.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;3-using-inadequate-basis-sets-without-correction&#34;&gt;3. Using Inadequate Basis Sets Without Correction&lt;/h2&gt;
&lt;p&gt;Small basis sets such as 6-31G* suffer from &lt;strong&gt;basis set superposition error (BSSE)&lt;/strong&gt;. This artifact artificially stabilizes interacting fragments by allowing them to borrow basis functions from each other.&lt;/p&gt;
&lt;p&gt;In many cases, BSSE leads to misleading agreement with experiment due to compensating errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Use &lt;strong&gt;triple-zeta or larger basis sets&lt;/strong&gt; for energetic quantities whenever possible. If smaller basis sets must be used, apply &lt;strong&gt;geometric counterpoise corrections (gCP)&lt;/strong&gt; or use composite methods that correct BSSE by construction.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;4-applying-a-single-level-of-theory-to-all-properties&#34;&gt;4. Applying a Single Level of Theory to All Properties&lt;/h2&gt;
&lt;p&gt;A common misconception is that one functional and basis set combination is equally suitable for geometries, reaction energies, and barrier heights. In practice, different properties have very different sensitivities to the electronic structure method.&lt;/p&gt;
&lt;p&gt;Methods that perform well for structures may fail badly for kinetics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Choose the method based on the target property. Efficient composite methods are ideal for geometry optimization, while reaction energies and barrier heights require higher-rung functionals and larger basis sets.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;5-underestimating-self-interaction-error-in-barrier-heights&#34;&gt;5. Underestimating Self-Interaction Error in Barrier Heights&lt;/h2&gt;
&lt;p&gt;Transition states are particularly sensitive to &lt;strong&gt;self-interaction error (SIE)&lt;/strong&gt;. Many (meta-)GGA functionals systematically underestimate activation barriers, leading to incorrect kinetic predictions and flawed mechanistic conclusions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Barrier height calculations should include &lt;strong&gt;Fock exchange&lt;/strong&gt;. Range-separated hybrid functionals are especially effective at reducing SIE while maintaining balanced energetics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;6-neglecting-solvation-effects&#34;&gt;6. Neglecting Solvation Effects&lt;/h2&gt;
&lt;p&gt;Gas-phase calculations are frequently compared to experimental data obtained in solution. For polar or charged systems, this mismatch can dominate the total error.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Include solvation effects routinely when modeling condensed-phase chemistry. Modern implicit models such as &lt;strong&gt;SMD&lt;/strong&gt; or &lt;strong&gt;COSMO-RS&lt;/strong&gt; provide a physically meaningful description beyond simple electrostatics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;7-relying-on-a-single-conformer-for-flexible-molecules&#34;&gt;7. Relying on a Single Conformer for Flexible Molecules&lt;/h2&gt;
&lt;p&gt;Many molecules populate multiple conformations at ambient temperature. Evaluating only a single optimized structure can lead to incorrect thermodynamic and kinetic predictions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Perform conformational sampling and compute &lt;strong&gt;Boltzmann-weighted averages&lt;/strong&gt; for relevant properties. Automated tools now make this feasible even for moderately large systems.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;8-overinterpreting-numerical-agreement-with-experiment&#34;&gt;8. Overinterpreting Numerical Agreement with Experiment&lt;/h2&gt;
&lt;p&gt;Agreement between calculated and experimental values does not guarantee correctness. Apparent accuracy can arise from compensating errors, particularly when outdated methods are used.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;br&gt;
Prioritize methodological robustness over coincidence. Use approaches that perform consistently across diverse chemical problems rather than relying on fortuitous agreement.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-takeaway&#34;&gt;Final Takeaway&lt;/h2&gt;
&lt;p&gt;Modern DFT best practice is not about increasing computational cost—it is about avoiding known failure modes. Legacy protocols persist largely due to familiarity, not reliability.&lt;/p&gt;
&lt;p&gt;Replacing B3LYP/6-31G* with contemporary, well-validated methods significantly improves accuracy at little to no additional cost and aligns computational results with physical reality.&lt;/p&gt;
&lt;p&gt;A calculation that runs smoothly is not necessarily correct. In DFT, as in molecular dynamics, methodological rigor is essential for meaningful scientific insight.&lt;/p&gt;
&lt;h2 id=&#34;reference-paper&#34;&gt;Reference Paper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bursch, M., Mewes, J.-M., Hansen, A., &amp;amp; Grimme, S.&lt;/strong&gt; (2022). Best-Practice DFT Protocols for Basic Molecular Computational Chemistry. &lt;em&gt;Angewandte Chemie International Edition&lt;/em&gt;, 61, e202205735.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ten Critical Pitfalls in Molecular Dynamics Simulations and Strategies for Mitigation</title>
      <link>https://yboulaamane.github.io/blog/ten-critical-pitfalls-in-molecular-dynamics-simulations-and-strategies-for-mitigation/</link>
      <pubDate>Sun, 21 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/ten-critical-pitfalls-in-molecular-dynamics-simulations-and-strategies-for-mitigation/</guid>
      <description>&lt;p&gt;Molecular dynamics (MD) serves as a powerful computational microscope, offering atomistic insights often unattainable through experimental methods alone. With the increasing accessibility of user-friendly software and comprehensive tutorials, the barrier to entry for new researchers has lowered significantly. However, MD is not merely a procedural task; it is a rigorous physics simulation where minor methodological errors can lead to scientifically inaccurate results.&lt;/p&gt;
&lt;p&gt;For early-stage researchers, the challenge often lies in subtle errors—mistakes that do not cause the simulation to crash but instead yield misleading trajectories. These errors often remain undetected until the peer-review stage, potentially invalidating months of computational effort.&lt;/p&gt;
&lt;p&gt;This article outlines ten of the most frequent methodological errors in molecular dynamics and provides best practices to ensure simulation reliability and reproducibility.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-inadequate-preparation-of-initial-structures&#34;&gt;1. Inadequate Preparation of Initial Structures&lt;/h2&gt;
&lt;p&gt;The validity of a simulation is strictly limited by the quality of the starting model. A common oversight is assuming that a structure downloaded from the Protein Data Bank (PDB) is immediately ready for simulation. Raw PDB files often contain experimental artifacts, such as missing atoms, unresolved residues, or crystal packing contacts that are not relevant in solution.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Rigorous structure preparation is mandatory. This includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Modeling missing loops.&lt;/li&gt;
&lt;li&gt;Resolving steric clashes.&lt;/li&gt;
&lt;li&gt;Crucially, assigning correct protonation states (e.g., Histidine tautomers) based on the specific pH of the environment rather than default settings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tools such as &lt;strong&gt;pdbfixer&lt;/strong&gt;, &lt;strong&gt;H++&lt;/strong&gt;, or &lt;strong&gt;PropKa&lt;/strong&gt; are essential for this standardization.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-incompatible-or-inappropriate-force-field-selection&#34;&gt;2. Incompatible or Inappropriate Force Field Selection&lt;/h2&gt;
&lt;p&gt;A force field represents the mathematical parameter set governing atomic interactions. A significant error involves selecting a force field based on popularity rather than its suitability for the specific molecular system (e.g., using a protein-centric force field for a complex membrane system without validation). Furthermore, combining parameters from different force fields—such as mixing CHARMM protein parameters with OPLS ligand parameters—can introduce severe imbalances in potential energy functions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Select a force field explicitly validated for your molecule class. If a complex system requires multiple parameter sets, ensure they share compatible functional forms and Lennard-Jones combination rules.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;3-mismatching-water-models&#34;&gt;3. Mismatching Water Models&lt;/h2&gt;
&lt;p&gt;Force fields are generally parameterized in conjunction with specific water models. Using a force field designed for TIP3P water with a more modern 4-point model (like OPC), or vice versa, is a frequent technical error.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Verify the primary literature for your chosen force field to identify the water model used during its parameterization. Using a mismatched water model can fundamentally alter solution density, protein-solvent interactions, and diffusion rates, rendering thermodynamic properties inaccurate.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;4-uncritical-acceptance-of-automated-ligand-topologies&#34;&gt;4. Uncritical Acceptance of Automated Ligand Topologies&lt;/h2&gt;
&lt;p&gt;When simulating non-standard residues or ligands, researchers often rely on automated servers (e.g., CGenFF, PRODRG, or MCPB) to generate topology files. Treating these servers as &amp;ldquo;black boxes&amp;rdquo; is dangerous, as automated algorithms often approximate partial charges and bond parameters incorrectly for complex chemical groups.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Automated output should be treated as a draft.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Always inspect the log files for high &amp;ldquo;penalty scores&amp;rdquo; or confidence warnings.&lt;/li&gt;
&lt;li&gt;For rigorous work, validate partial charges using Quantum Mechanics (QM) calculations and verify bonded parameters against experimental data or higher-level theory.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;5-insufficient-minimization-and-equilibration&#34;&gt;5. Insufficient Minimization and Equilibration&lt;/h2&gt;
&lt;p&gt;Initiating the production run (data collection) before the system has thermodynamically relaxed is a primary cause of instability. If high-energy contacts are not resolved, the system may exhibit unrealistic structural distortions or numerical instability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Minimization:&lt;/strong&gt; Continue until the maximum force on any atom falls below a strict threshold (e.g., 1000 kJ/mol/nm).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Equilibration:&lt;/strong&gt; Monitor temperature (NVT) and pressure (NPT) phases carefully. Production should only commence once system density and potential energy have converged to a stable plateau.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;6-incorrect-time-step-selection&#34;&gt;6. Incorrect Time Step Selection&lt;/h2&gt;
&lt;p&gt;The integration time step dictates the frequency at which the equations of motion are solved. Selecting a time step that is too large causes numerical instability (integration errors), while a time step that is too small results in computational inefficiency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; For standard biological simulations, a &lt;strong&gt;2 femtosecond (fs)&lt;/strong&gt; time step is appropriate, provided that bonds involving hydrogen atoms are constrained using algorithms such as LINCS or SHAKE. Larger time steps (e.g., 4 fs) should only be used if Hydrogen Mass Repartitioning (HMR) is applied.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;7-neglecting-periodic-boundary-condition-pbc-artifacts&#34;&gt;7. Neglecting Periodic Boundary Condition (PBC) Artifacts&lt;/h2&gt;
&lt;p&gt;Periodic Boundary Conditions are essential for simulating bulk systems, but they introduce visual and analytical artifacts, such as molecules appearing to split across simulation box boundaries.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Raw trajectories must be post-processed prior to analysis. Metrics such as Radius of Gyration ($R_g$) or RMSD will yield erroneous results if calculated on &amp;ldquo;broken&amp;rdquo; molecules. Use trajectory processing tools (e.g., &lt;code&gt;gmx trjconv&lt;/code&gt; in GROMACS or &lt;code&gt;cpptraj&lt;/code&gt; in AMBER) to re-center the protein and &amp;ldquo;unwrap&amp;rdquo; molecules across the periodic boundaries.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;8-insufficient-sampling-and-lack-of-replicates&#34;&gt;8. Insufficient Sampling and Lack of Replicates&lt;/h2&gt;
&lt;p&gt;Molecular dynamics is inherently stochastic; a single trajectory represents only one probabilistic pathway of the system. Relying on a single simulation run can lead to the &amp;ldquo;Anecdotal Evidence&amp;rdquo; fallacy, where a rare event is mistaken for a general property of the system.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Conduct replicate simulations. Ideally, run the same system &lt;strong&gt;3 to 5 times&lt;/strong&gt; with different initial velocity distributions (random seeds). Conclusions should be drawn from statistical trends observed across multiple independent replicates, not a single isolated run.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;9-over-reliance-on-rmsd-as-a-stability-metric&#34;&gt;9. Over-reliance on RMSD as a Stability Metric&lt;/h2&gt;
&lt;p&gt;Root Mean Square Deviation (RMSD) is the most common metric for assessing structural stability, but it is insufficient on its own. A plateauing RMSD indicates only that the global structure is not deviating further from the reference; it does not rule out local distortions, broken hydrogen bond networks, or incorrect energetic behavior.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Employ a multidimensional analysis strategy. Combine RMSD with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Root Mean Square Fluctuation (RMSF)&lt;/li&gt;
&lt;li&gt;Radius of Gyration ($R_g$)&lt;/li&gt;
&lt;li&gt;Solvent Accessible Surface Area (SASA)&lt;/li&gt;
&lt;li&gt;Clustering analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This provides a comprehensive view of system stability and dynamics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;10-lack-of-experimental-validation&#34;&gt;10. Lack of Experimental Validation&lt;/h2&gt;
&lt;p&gt;A simulation that runs without errors is not necessarily physically accurate. A major pitfall is failing to benchmark simulation results against known experimental observables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Always attempt to correlate simulation data with experimental results. Comparing calculated B-factors with X-ray crystallography data, or comparing NMR observables (such as chemical shifts or NOEs) with simulated values, provides the necessary validation to ensure the simulation reflects physical reality.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unlocking the Undruggable: How Biotechnology Is Rewriting Drug Discovery</title>
      <link>https://yboulaamane.github.io/blog/unlocking-the-undruggable-how-biotechnology-is-rewriting-drug-discovery/</link>
      <pubDate>Sat, 22 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/unlocking-the-undruggable-how-biotechnology-is-rewriting-drug-discovery/</guid>
      <description>&lt;p&gt;For decades, drug discovery followed a familiar path: identify a disease-driving protein, locate a surface pocket, and design a molecule to fit. This strategy produced breakthroughs—from imatinib to dozens of kinase inhibitors—but also exposed a major limitation. Many crucial proteins &lt;strong&gt;lacked druggable pockets&lt;/strong&gt; or resisted traditional therapeutics.&lt;/p&gt;
&lt;p&gt;Targets like &lt;strong&gt;KRAS, BCL-2, transcription factors, and intrinsically disordered proteins (IDPs)&lt;/strong&gt; were long considered &lt;em&gt;undruggable&lt;/em&gt;. Today, advances in biotechnology, structural biology, and computational modeling are revealing that these proteins are not undruggable—only difficult.&lt;/p&gt;
&lt;p&gt;The wall is cracking.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;from-phenotypic-screening-to-targeted-therapy&#34;&gt;From Phenotypic Screening to Targeted Therapy&lt;/h2&gt;
&lt;p&gt;Drug discovery began with &lt;strong&gt;phenotypic screens&lt;/strong&gt;: testing crude extracts and observing biological effects. With molecular biology, the field shifted toward &lt;strong&gt;target-based drug design&lt;/strong&gt;, enabling precise interventions against receptors, channels, and enzymes with clear pockets. Biologics expanded the toolbox further but still covered only &lt;strong&gt;~2% of the human proteome&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The rest—transcription factors, flexible proteins, broad PPIs—remained inaccessible.&lt;/p&gt;
&lt;p&gt;Now, computational methods, structural insights, and novel modalities are pushing the boundaries of what can be targeted.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;why-some-targets-resist&#34;&gt;Why Some Targets Resist&lt;/h2&gt;
&lt;p&gt;So-called undruggable targets present specific challenges:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Selectivity problems:&lt;/strong&gt; Highly conserved active sites make avoiding off-target effects difficult.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; IDPs refuse to conform to traditional binding models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protein–protein interfaces:&lt;/strong&gt; Flat, diffuse surfaces lack obvious cavities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chemical constraints:&lt;/strong&gt; Polar, solvent-exposed surfaces clash with drug-like property requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite this, drugs such as &lt;strong&gt;venetoclax (BCL-2 inhibitor)&lt;/strong&gt; and &lt;strong&gt;sotorasib (KRAS G12C)&lt;/strong&gt; prove these challenges can be overcome.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;repurposing-as-a-shortcut&#34;&gt;Repurposing as a Shortcut&lt;/h2&gt;
&lt;p&gt;Drug repurposing offers a fast, cost-effective strategy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Avoids early safety and manufacturing hurdles&lt;/li&gt;
&lt;li&gt;Represents &lt;strong&gt;one-third of recent FDA approvals&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Generates &lt;strong&gt;~25% of pharmaceutical revenue&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Classic examples—&lt;strong&gt;sildenafil, propranolol, aspirin&lt;/strong&gt;—show the power of reinterpreting drug effects.&lt;br&gt;
Today, AI-driven transcriptomic matching, EHR mining, and network pharmacology are transforming repurposing from luck into strategy.&lt;/p&gt;
&lt;p&gt;Challenges remain (limited IP protection, restricted data access), but opportunities in rare diseases, pandemics, and personalized medicine keep repurposing at the center of innovation.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;expanding-the-toolbox-new-biotechnologies&#34;&gt;Expanding the Toolbox: New Biotechnologies&lt;/h2&gt;
&lt;p&gt;What truly reshapes the undruggable landscape is the emergence of &lt;strong&gt;new therapeutic modalities&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PROTACs (Protein Degraders):&lt;/strong&gt; Redirect the cell’s degradation machinery to eliminate disease-driving proteins.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multispecific drugs:&lt;/strong&gt; Engineer hybrid molecules or antibodies with multiple targeting functions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nucleic acid therapeutics:&lt;/strong&gt; RNA, antisense, siRNA, and gene-editing tools that modulate expression directly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Peptidomimetics:&lt;/strong&gt; Molecules mimicking protein structures to bind difficult PPIs or flat surfaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Breakthroughs highlight the potential:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Venetoclax&lt;/strong&gt; broke into BCL-2’s stubborn PPI interface.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sotorasib&lt;/strong&gt; exploited a newly discovered KRAS pocket.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HIF-2α inhibitors&lt;/strong&gt; targeted a transcription factor once deemed inaccessible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Computational peptide design&lt;/strong&gt; (e.g., Peptilogics’ PLG0206) showcases the growing power of virtual design and optimization.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;industry-growing-pains&#34;&gt;Industry Growing Pains&lt;/h2&gt;
&lt;p&gt;Despite technological leaps, the industry faces paradoxes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Drug approval rates stagnated in the 2000s (~12% from Phase I to approval).&lt;/li&gt;
&lt;li&gt;Failures stem from &lt;strong&gt;lack of efficacy&lt;/strong&gt;, &lt;strong&gt;toxicity&lt;/strong&gt;, and &lt;strong&gt;poor pharmacology&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Outsourcing and academia–industry partnerships help, but inefficiencies persist.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Modern drug discovery must address not only &lt;em&gt;what&lt;/em&gt; to target but &lt;em&gt;how&lt;/em&gt; to streamline the entire pipeline.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;streamlining-the-path-forward&#34;&gt;Streamlining the Path Forward&lt;/h2&gt;
&lt;p&gt;New strategies aim to modernize clinical development:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Adaptive trial designs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Biomarker-driven recruitment&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI-guided study planning&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use of real-world evidence&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network pharmacology for multi-target understanding&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Regulatory pathways like &lt;strong&gt;orphan drug&lt;/strong&gt;, &lt;strong&gt;fast-track&lt;/strong&gt;, and &lt;strong&gt;breakthrough therapy&lt;/strong&gt; designations further accelerate translation.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-new-era-for-the-undruggable&#34;&gt;A New Era for the “Undruggable”&lt;/h2&gt;
&lt;p&gt;The frontier is shifting.&lt;/p&gt;
&lt;p&gt;What used to be considered undruggable is now simply &lt;strong&gt;challenging&lt;/strong&gt;. With:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Repurposing&lt;/li&gt;
&lt;li&gt;PROTACs&lt;/li&gt;
&lt;li&gt;Multispecifics&lt;/li&gt;
&lt;li&gt;Nucleic acid therapeutics&lt;/li&gt;
&lt;li&gt;AI-designed peptides&lt;/li&gt;
&lt;li&gt;High-resolution structural biology&lt;/li&gt;
&lt;li&gt;Computational screening at scale&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;the drug-discovery world is steadily expanding into previously unreachable biology.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The age of the undruggable is ending.&lt;/strong&gt;&lt;br&gt;
What follows is a landscape where creativity, computation, and biotechnology converge—and fewer targets remain truly out of reach.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt;&lt;br&gt;
DrugBank. &lt;em&gt;Unlocking Undruggable Targets: Biotechnology’s Role in Expanding Drug Discovery&lt;/em&gt;. 2024.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Use DataWarrior for Drug Discovery: Key Workflows From the Villoutreix Tutorials</title>
      <link>https://yboulaamane.github.io/blog/how-to-use-datawarrior-for-drug-discovery-key-workflows-from-the-villoutreix-tutorials/</link>
      <pubDate>Sat, 15 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/how-to-use-datawarrior-for-drug-discovery-key-workflows-from-the-villoutreix-tutorials/</guid>
      <description>&lt;h2 id=&#34;why-datawarrior-matters&#34;&gt;Why DataWarrior Matters&lt;/h2&gt;
&lt;p&gt;If you work in drug discovery or cheminformatics, you frequently handle &lt;strong&gt;large chemical datasets&lt;/strong&gt; that require cleaning, filtering, visualization, and export.&lt;br&gt;
&lt;strong&gt;DataWarrior&lt;/strong&gt; is designed exactly for this: an open-source, chemistry-aware data workbench that is free for academic and commercial use.&lt;/p&gt;
&lt;p&gt;Key advantages include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chemistry-aware filtering and visualization&lt;/li&gt;
&lt;li&gt;2D/3D plots and interactive exploration&lt;/li&gt;
&lt;li&gt;Substructure search and chemical intelligence&lt;/li&gt;
&lt;li&gt;Property calculation, combinatorial libraries, PCA/t-SNE&lt;/li&gt;
&lt;li&gt;Docking inside a protein pocket&lt;/li&gt;
&lt;li&gt;Support for SMILES, SDF, CSV, tab-delimited text&lt;/li&gt;
&lt;li&gt;Cross-platform (Windows, macOS, Linux)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bruno Villoutreix’s tutorial series provides an excellent guided introduction. This post summarizes &lt;strong&gt;Part 1&lt;/strong&gt; and connects it to practical drug-discovery workflows.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;core-capabilities-covered-in-part-1&#34;&gt;Core Capabilities Covered in Part 1&lt;/h2&gt;
&lt;h3 id=&#34;a-versatile-workbench&#34;&gt;A Versatile Workbench&lt;/h3&gt;
&lt;p&gt;DataWarrior is more than a viewer — it is a &lt;strong&gt;chemometrics and data-analysis environment&lt;/strong&gt; with dynamic plots, smart filtering, and chemical intelligence.&lt;/p&gt;
&lt;h3 id=&#34;key-features&#34;&gt;Key Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Real-time text, numeric, and chemical filtering&lt;/li&gt;
&lt;li&gt;2D / 3D visualization modules&lt;/li&gt;
&lt;li&gt;Molecular property prediction&lt;/li&gt;
&lt;li&gt;Combinatorial library enumeration&lt;/li&gt;
&lt;li&gt;PCA and t-SNE&lt;/li&gt;
&lt;li&gt;Docking and non-chemical data support&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-import--formats&#34;&gt;Data Import &amp;amp; Formats&lt;/h3&gt;
&lt;p&gt;DataWarrior handles common cheminformatics formats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SMILES&lt;/strong&gt;, &lt;strong&gt;SDF (v2/v3)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CSV&lt;/strong&gt;, &lt;strong&gt;tab-delimited text&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Native &lt;strong&gt;DWIR&lt;/strong&gt; project files&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This makes it ideal as a front-end before passing data to docking, QSAR, MD, or ML workflows.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;interface-overview&#34;&gt;Interface Overview&lt;/h2&gt;
&lt;p&gt;The interface is flexible and powerful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many options are accessible via &lt;strong&gt;right-click menus&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Layouts can be customized with sub-windows&lt;/li&gt;
&lt;li&gt;Some tools are hidden behind pop-ups&lt;/li&gt;
&lt;li&gt;Learning curve exists, but productivity increases quickly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Think of it as a &lt;strong&gt;chemistry-smart Excel&lt;/strong&gt; designed specifically for cheminformatics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;external-data-wikipedia-molecule-import&#34;&gt;External Data: Wikipedia Molecule Import&lt;/h2&gt;
&lt;p&gt;Part 1 demonstrates an impressive feature:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DataWarrior can download all &lt;strong&gt;chemical structures from Wikipedia&lt;/strong&gt; (~22,000+ molecules depending on version).&lt;/li&gt;
&lt;li&gt;You can filter, visualize, and explore the full set offline.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This dataset is perfect for practicing workflows before loading your own project data.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;practical-filtering-workflow-name--substructure&#34;&gt;Practical Filtering Workflow (Name + Substructure)&lt;/h2&gt;
&lt;p&gt;Villoutreix demonstrates a realistic medicinal-chemistry filtering pipeline:&lt;/p&gt;
&lt;h3 id=&#34;1-name-based-filtering&#34;&gt;1. Name-Based Filtering&lt;/h3&gt;
&lt;p&gt;Use &lt;strong&gt;regular expressions&lt;/strong&gt; to identify drug classes by name suffix:&lt;br&gt;
Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.*ib&lt;/code&gt; (kinase inhibitors)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.*sartan&lt;/code&gt; (angiotensin receptor blockers)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.*azole&lt;/code&gt; (antifungals)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Filtering Wikipedia’s 22k molecules yields a much smaller, focused set.&lt;/p&gt;
&lt;h3 id=&#34;2-substructure-filtering&#34;&gt;2. Substructure Filtering&lt;/h3&gt;
&lt;p&gt;Draw a functional group (e.g., &lt;strong&gt;piperazine/piperidine&lt;/strong&gt;) in the structure filter window.&lt;br&gt;
DataWarrior keeps molecules containing the substructure &lt;strong&gt;and&lt;/strong&gt; matching the name rule.&lt;br&gt;
Matching fragments appear highlighted in &lt;strong&gt;red&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;3-create-a-row-list--export&#34;&gt;3. Create a Row List &amp;amp; Export&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Create a custom list (e.g., &lt;code&gt;cancer&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Add &lt;strong&gt;SMILES code&lt;/strong&gt; for each molecule.&lt;/li&gt;
&lt;li&gt;Remove unnecessary columns (formula, MW, structure).&lt;/li&gt;
&lt;li&gt;Save as a &lt;strong&gt;tab-delimited text file&lt;/strong&gt; (&lt;code&gt;cancer.txt&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Repeat the workflow for other suffixes, such as &lt;strong&gt;“-azole”&lt;/strong&gt;, to build an antifungal set.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;integrating-datawarrior-into-your-workflow&#34;&gt;Integrating DataWarrior Into Your Workflow&lt;/h2&gt;
&lt;h3 id=&#34;1-import-your-data&#34;&gt;1. Import Your Data&lt;/h3&gt;
&lt;p&gt;Load SDF/SMILES and merge with ADMET, assay, or physicochemical tables.&lt;/p&gt;
&lt;h3 id=&#34;2-smart-filtering&#34;&gt;2. Smart Filtering&lt;/h3&gt;
&lt;p&gt;Use both:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Name patterns&lt;/strong&gt; (series, suffixes, pharmacological classes)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Substructure filters&lt;/strong&gt; (scaffolds, R-groups, functional motifs)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-visualization&#34;&gt;3. Visualization&lt;/h3&gt;
&lt;p&gt;Quickly inspect:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Activity distributions&lt;/li&gt;
&lt;li&gt;Scatter plots&lt;/li&gt;
&lt;li&gt;PCA/t-SNE chemical space&lt;/li&gt;
&lt;li&gt;Outliers and series clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-export-for-modelling&#34;&gt;4. Export for Modelling&lt;/h3&gt;
&lt;p&gt;Save clean SMILES + metadata for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;QSAR / ML&lt;/li&gt;
&lt;li&gt;Docking&lt;/li&gt;
&lt;li&gt;MD setup&lt;/li&gt;
&lt;li&gt;Library design&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DataWarrior becomes the &lt;strong&gt;interactive triage layer&lt;/strong&gt; before computational modeling.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;why-villoutreixs-series-is-worth-watching&#34;&gt;Why Villoutreix’s Series Is Worth Watching&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Short and dense: ~85 minutes across 9 videos&lt;/li&gt;
&lt;li&gt;Realistic medicinal chemistry examples&lt;/li&gt;
&lt;li&gt;Shows &lt;strong&gt;where to click&lt;/strong&gt; and how features connect&lt;/li&gt;
&lt;li&gt;Useful even for intermediate users — many hidden features become obvious after watching&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;getting-started-today&#34;&gt;Getting Started Today&lt;/h2&gt;
&lt;p&gt;You can reproduce Part 1 in minutes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install &lt;strong&gt;DataWarrior&lt;/strong&gt; from the official website.&lt;/li&gt;
&lt;li&gt;Import the &lt;strong&gt;Wikipedia dataset&lt;/strong&gt; directly from within the software.&lt;/li&gt;
&lt;li&gt;Apply regular expression filtering (e.g., &lt;code&gt;.*ib&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Add a substructure filter.&lt;/li&gt;
&lt;li&gt;Create a row list → add SMILES → export your filtered set.&lt;/li&gt;
&lt;li&gt;Repeat with another suffix (e.g., &lt;code&gt;.*azole&lt;/code&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This prepares you to bring in your own datasets and use DataWarrior as your daily workbench.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-thoughts&#34;&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;DataWarrior is a powerful, free, and chemistry-aware tool that helps you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explore large datasets interactively&lt;/li&gt;
&lt;li&gt;Build focused libraries rapidly&lt;/li&gt;
&lt;li&gt;Clean data before modeling&lt;/li&gt;
&lt;li&gt;Visualize chemical space&lt;/li&gt;
&lt;li&gt;Export ready-to-use hit lists&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paired with the Villoutreix tutorial series, it becomes a &lt;strong&gt;practical, everyday companion&lt;/strong&gt; for drug-discovery and cheminformatics work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Energy Minimization with Open Babel: Practical Guide for Ligand Preparation</title>
      <link>https://yboulaamane.github.io/blog/energy-minimization-with-open-babel-practical-guide-for-ligand-preparation/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/energy-minimization-with-open-babel-practical-guide-for-ligand-preparation/</guid>
      <description>&lt;h1 id=&#34;energy-minimization-with-open-babel-a-practical-guide-for-computational-chemists&#34;&gt;Energy Minimization with Open Babel: A Practical Guide for Computational Chemists&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Before any molecular docking or molecular dynamics simulation, &lt;strong&gt;energy minimization&lt;/strong&gt; is a crucial preprocessing step. It helps relax the structure, remove steric clashes, and bring the molecule closer to a physically meaningful conformation. While commercial tools like Chem3D are often used, &lt;strong&gt;Open Babel&lt;/strong&gt; offers a free and versatile alternative.&lt;/p&gt;
&lt;p&gt;In this post, I’ll walk through how to perform energy minimization in Open Babel, discuss the available force fields and algorithms, and highlight best practices from the perspective of computational chemistry.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;why-energy-minimization-matters&#34;&gt;Why Energy Minimization Matters&lt;/h2&gt;
&lt;p&gt;Ligand structures downloaded from databases or drawn manually often contain unrealistic bond lengths, angles, or steric overlaps. Docking such conformations may bias results or even prevent convergence. Energy minimization ensures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More realistic starting geometry&lt;/li&gt;
&lt;li&gt;Reduced steric clashes&lt;/li&gt;
&lt;li&gt;Improved stability in docking and MD workflows&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;open-babels-obminimize-command&#34;&gt;Open Babel’s &lt;code&gt;obminimize&lt;/code&gt; Command&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;&lt;code&gt;obminimize&lt;/code&gt;&lt;/strong&gt; tool in Open Babel performs energy minimization directly from the command line. Its general syntax is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;obminimize [options] input_file
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Key options include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-ff&lt;/code&gt;	: Choose force field&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-sd&lt;/code&gt;	: Steepest descent algorithm&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-cg&lt;/code&gt;	: Conjugate gradient algorithm (default)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-h&lt;/code&gt;	: Add hydrogens&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-n&lt;/code&gt;	: Maximum steps (default: 2500)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-o&lt;/code&gt;	: Output format (PDB, MOL2, SDF, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;comparing-force-fields-in-open-babel&#34;&gt;Comparing Force Fields in Open Babel&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Force Field&lt;/th&gt;
          &lt;th&gt;Typical Use&lt;/th&gt;
          &lt;th&gt;Strengths&lt;/th&gt;
          &lt;th&gt;Weaknesses&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;GAFF&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;General drug-like molecules&lt;/td&gt;
          &lt;td&gt;AMBER-compatible&lt;/td&gt;
          &lt;td&gt;Less optimized for small ligands alone&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Ghemical&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Education, small molecules&lt;/td&gt;
          &lt;td&gt;Lightweight&lt;/td&gt;
          &lt;td&gt;Limited accuracy&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;MMFF94&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Small organic ligands&lt;/td&gt;
          &lt;td&gt;Well-validated, reliable&lt;/td&gt;
          &lt;td&gt;Slightly heavier computationally&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;MMFF94s&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Variant of MMFF94&lt;/td&gt;
          &lt;td&gt;Better torsion handling&lt;/td&gt;
          &lt;td&gt;Similar cost to MMFF94&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;UFF&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Broad coverage (organics, inorganics, metals)&lt;/td&gt;
          &lt;td&gt;Universal element support&lt;/td&gt;
          &lt;td&gt;Less accurate for organics&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Recommendation:&lt;/strong&gt; For drug-like ligands, &lt;strong&gt;MMFF94&lt;/strong&gt; (or MMFF94s) is the best choice.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;minimization-algorithms-sd-vs-cg&#34;&gt;Minimization Algorithms: SD vs CG&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Algorithm&lt;/th&gt;
          &lt;th&gt;Principle&lt;/th&gt;
          &lt;th&gt;Pros&lt;/th&gt;
          &lt;th&gt;Cons&lt;/th&gt;
          &lt;th&gt;Use Case&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Steepest Descent (SD)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Moves along steepest energy gradient&lt;/td&gt;
          &lt;td&gt;Robust, removes high-energy clashes quickly&lt;/td&gt;
          &lt;td&gt;Slow near convergence&lt;/td&gt;
          &lt;td&gt;First relaxation&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Conjugate Gradient (CG)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Uses gradient + past directions for efficiency&lt;/td&gt;
          &lt;td&gt;Fast near minimum, fewer steps needed&lt;/td&gt;
          &lt;td&gt;Can fail if starting far from minimum&lt;/td&gt;
          &lt;td&gt;Fine minimization (default)&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Best practice:&lt;/strong&gt; Start with &lt;strong&gt;SD&lt;/strong&gt; to resolve bad geometries, then switch to &lt;strong&gt;CG&lt;/strong&gt; for efficient convergence.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;example-workflows&#34;&gt;Example Workflows&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Basic minimization with MMFF94 + SD:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;obminimize -sd -ff MMFF94 -h ligand.mol2 -o pdb ligand_min.pdb&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Longer minimization with more steps:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Alternative force field (UFF) for metal complexes:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;obminimize -cg -ff UFF metal_complex.mol2 -o sdf metal_min.sdf&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Energy minimization is a foundational step in computational chemistry pipelines. Open Babel’s &lt;code&gt;obminimize&lt;/code&gt; provides a free, flexible, and reliable solution to prepare ligands for docking and MD simulations. By choosing the right &lt;strong&gt;force field&lt;/strong&gt; and &lt;strong&gt;algorithm&lt;/strong&gt;, researchers can ensure accurate starting geometries and reduce artifacts in downstream analyses.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Quick Guide to Temperature Replica Exchange Molecular Dynamics</title>
      <link>https://yboulaamane.github.io/blog/a-quick-guide-to-temperature-replica-exchange-molecular-dynamics/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/a-quick-guide-to-temperature-replica-exchange-molecular-dynamics/</guid>
      <description>&lt;p&gt;Temperature Replica Exchange Molecular Dynamics (T-REMD) is an enhanced sampling method that improves conformational exploration in molecular simulations. Instead of running one simulation that may get trapped in local minima, T-REMD launches several copies—called replicas—of the same system, each running at a different temperature. These replicas periodically attempt to exchange configurations, allowing the system to more easily escape energy traps and explore relevant biological conformations.&lt;br&gt;
This method is especially helpful for complex systems like proteins or protein-ligand complexes, where conformational flexibility and rare events play a big role in biological function and binding.&lt;/p&gt;
&lt;h2 id=&#34;why-use-t-remd&#34;&gt;Why use T-REMD?&lt;/h2&gt;
&lt;p&gt;Conventional molecular dynamics (MD) can struggle with systems that have rugged energy landscapes. If your simulation starts in a local minimum, it might stay there for millions of steps, never sampling other important conformations. T-REMD helps overcome this by running high-temperature simulations in parallel with your regular one. These high-temperature replicas can cross energy barriers more easily. By allowing swaps between replicas, lower-temperature simulations benefit from this broader exploration.&lt;/p&gt;
&lt;p&gt;In drug discovery, where ligand binding, induced fit, or protein flexibility is critical, T-REMD gives you a better shot at capturing biologically meaningful states that you might miss with basic MD.&lt;/p&gt;
&lt;h2 id=&#34;how-it-works&#34;&gt;How it works&lt;/h2&gt;
&lt;p&gt;T-REMD runs &lt;strong&gt;N replicas&lt;/strong&gt; of your system, each at a different temperature. All replicas evolve independently via MD, but every few hundred or thousand steps, pairs of neighboring replicas attempt to exchange coordinates. These exchanges are accepted or rejected based on the Metropolis criterion, which preserves correct thermodynamic distributions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Replica 1: 300K  —&amp;gt; Swap? —&amp;gt; 310K  
Replica 2: 310K  —&amp;gt; Swap? —&amp;gt; 320K  
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The acceptance probability \( P \) for a swap between replica \( i \) and \( j \) is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;P = min(1, exp[(1/Ti - 1/Tj) * (Ej - Ei)])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ti and Tj are the temperatures of the replicas&lt;/li&gt;
&lt;li&gt;Ei and Ej are their potential energies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This ensures that the ensemble at each temperature follows the correct Boltzmann distribution.&lt;/p&gt;
&lt;h2 id=&#34;gromacs-example-setting-up-t-remd&#34;&gt;GROMACS Example: Setting Up T-REMD&lt;/h2&gt;
&lt;p&gt;Let’s walk through a basic GROMACS setup for T-REMD. Suppose we want 8 replicas from 300K to 370K.&lt;/p&gt;
&lt;h3 id=&#34;1-prepare-mdp-files-for-each-temperature&#34;&gt;1. Prepare &lt;code&gt;.mdp&lt;/code&gt; files for each temperature&lt;/h3&gt;
&lt;p&gt;Create &lt;code&gt;md_300.mdp&lt;/code&gt;, &lt;code&gt;md_310.mdp&lt;/code&gt;, &amp;hellip;, &lt;code&gt;md_370.mdp&lt;/code&gt; with appropriate temperature settings.&lt;/p&gt;
&lt;h3 id=&#34;2-generate-input-files&#34;&gt;2. Generate input files&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;gmx grompp -f md_300.mdp -o topol_300.tpr -c conf.gro -p topol.top -maxwarn 1
gmx grompp -f md_310.mdp -o topol_310.tpr -c conf.gro -p topol.top -maxwarn 1
...
gmx grompp -f md_370.mdp -o topol_370.tpr -c conf.gro -p topol.top -maxwarn 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-run-t-remd&#34;&gt;3. Run T-REMD&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;mpirun -np 8 gmx_mpi mdrun -multi 8 -replex 1000 -s topol_.tpr -deffnm remd
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-multi 8&lt;/code&gt;: run 8 parallel replicas&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-replex 1000&lt;/code&gt;: attempt replica exchanges every 1000 steps&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-deffnm remd&lt;/code&gt;: use common file prefix for outputs&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-post-process&#34;&gt;4. Post-process&lt;/h3&gt;
&lt;p&gt;Once your simulation is complete, you can analyze the trajectory from a specific temperature using demultiplexing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx demux -f remd0.xtc -demux replica_index.xvg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then extract frames from the trajectory that corresponds to the replica at 300K (or whatever your target temp is).&lt;/p&gt;
&lt;h2 id=&#34;tips-and-considerations&#34;&gt;Tips and Considerations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Temperature spacing matters&lt;/strong&gt;: Too far apart, and swaps won’t be accepted; too close, and you’ll need many replicas. Aim for 20–30% acceptance rate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Equilibration&lt;/strong&gt;: All replicas should be equilibrated well before starting T-REMD.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analysis&lt;/strong&gt;: Usually, you only analyze the trajectory from the lowest temperature (e.g., 300K), which contains the best physical behavior.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Computational cost&lt;/strong&gt;: You’ll need multiple CPUs/GPUs—one per replica. This can be expensive but is highly parallelizable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;when-to-use-t-remd&#34;&gt;When to use T-REMD&lt;/h2&gt;
&lt;p&gt;Use T-REMD when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You&amp;rsquo;re studying systems with &lt;strong&gt;conformational flexibility&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Your system gets &lt;strong&gt;trapped in local minima&lt;/strong&gt; during regular MD.&lt;/li&gt;
&lt;li&gt;You want to enhance sampling around &lt;strong&gt;ligand binding sites&lt;/strong&gt; or &lt;strong&gt;allosteric regions&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;You&amp;rsquo;re exploring &lt;strong&gt;folding&lt;/strong&gt;, &lt;strong&gt;loop motions&lt;/strong&gt;, or &lt;strong&gt;cryptic pockets&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;rsquo;re just optimizing a small molecule or doing very short timescale dynamics, regular MD is often sufficient. But when you want to deeply explore your system’s energy landscape, especially for drug discovery or protein-ligand complexes, T-REMD can be a game-changer.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Temperature Replica Exchange MD is a powerful tool that brings smarter sampling to your simulations. It&amp;rsquo;s especially useful when standard MD isn’t enough to explore the full range of conformations your molecule can adopt. With tools like GROMACS, setting it up is fairly straightforward—and the scientific payoff can be huge.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Principal Component Analysis and Free Energy Landscape Mapping Using GROMACS</title>
      <link>https://yboulaamane.github.io/blog/principal-component-analysis-and-free-energy-landscape-mapping-using-gromacs/</link>
      <pubDate>Wed, 09 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/principal-component-analysis-and-free-energy-landscape-mapping-using-gromacs/</guid>
      <description>&lt;p&gt;This guide outlines how to perform Principal Component Analysis (PCA) and compute Free Energy Landscapes (FEL) from molecular dynamics (MD) simulations using GROMACS. These analyses are useful to capture dominant motions and identify energetically favorable states in biomolecular systems.&lt;/p&gt;
&lt;h2 id=&#34;part-1-principal-component-analysis-pca&#34;&gt;Part 1: Principal Component Analysis (PCA)&lt;/h2&gt;
&lt;h3 id=&#34;step-1-covariance-matrix-and-eigenvector-calculation&#34;&gt;Step 1: Covariance Matrix and Eigenvector Calculation&lt;/h3&gt;
&lt;p&gt;Run the following command to compute the covariance matrix and extract eigenvectors:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx covar -s md_0_100.tpr -f md_0_100.xtc -o eigenvalues.xvg -v eigenvectors.trr -xpma covar.xpm
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: If the command fails using &lt;code&gt;md_0_100.gro&lt;/code&gt;, use &lt;code&gt;md_0_100.tpr&lt;/code&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Select &lt;strong&gt;protein&lt;/strong&gt; and &lt;strong&gt;ligand&lt;/strong&gt; when prompted.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-2-determine-the-number-of-principal-components&#34;&gt;Step 2: Determine the Number of Principal Components&lt;/h3&gt;
&lt;p&gt;Analyze &lt;code&gt;eigenvalues.xvg&lt;/code&gt; to compute:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Total Variance&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Total Variance = Σ λᵢ&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Explained Variance (%)&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Explained Variance (%) = (λᵢ / Σ λᵢ) × 100&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cumulative Variance&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Cumulative Variance = Σ (λᵢ / Σ λᵢ) × 100&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select the minimum number of components that cumulatively explain more than &lt;strong&gt;50%&lt;/strong&gt; of the total variance.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-3-plot-principal-component-projections&#34;&gt;Step 3: Plot Principal Component Projections&lt;/h3&gt;
&lt;p&gt;For projecting motion along PC1 to PC5, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx anaeig -f md_0_100.xtc -s md_0_100.tpr -v eigenvectors.trr -first 1 -last 5 \
-proj pc15_lovastatina.xvg -2d project2d_s100_lovastatina.xvg -tu ns
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-proj&lt;/code&gt;: 1D projection along each selected eigenvector&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-2d&lt;/code&gt;: Combined 2D projection using the first 5 components&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;part-2-free-energy-landscape-fel-calculation&#34;&gt;Part 2: Free Energy Landscape (FEL) Calculation&lt;/h2&gt;
&lt;h3 id=&#34;step-1-generate-principal-component-projections&#34;&gt;Step 1: Generate Principal Component Projections&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;gmx anaeig -f md_0_100.xtc -s md_0_100.tpr -v eigenvectors.trr -last 1 -proj pc1.xvg
gmx anaeig -f md_0_100.xtc -s md_0_100.tpr -v eigenvectors.trr -first 2 -last 2 -proj pc2.xvg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Merge PC1 and PC2 into a single file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;paste pc1.xvg pc2.xvg | awk &#39;{print $1, $2, $4}&#39; &amp;gt; PC1PC2.xvg
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-2-compute-free-energy-surface&#34;&gt;Step 2: Compute Free Energy Surface&lt;/h3&gt;
&lt;p&gt;Use GROMACS SHAM module:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx sham -f PC1PC2.xvg -ls FES.xpm
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Convert &lt;code&gt;.xpm&lt;/code&gt; to &lt;code&gt;.dat&lt;/code&gt; using a Python script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python2.7 xpm2txt.py -f FES.xpm -o fel.dat
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Python script &lt;code&gt;xpm2txt.py&lt;/code&gt; converts the XPM matrix to a 3-column text file (X, Y, Energy).&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;step-3-extract-minimum-energy-conformation&#34;&gt;Step 3: Extract Minimum Energy Conformation&lt;/h3&gt;
&lt;p&gt;After plotting &lt;code&gt;fel.dat&lt;/code&gt;, identify the time of the minimum energy, then extract the conformation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx trjconv -s md_0_100.tpr -f md_0_100.xtc -o min_energy.pdb -dump 520
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Replace &lt;code&gt;520&lt;/code&gt; with the appropriate time (in ps) corresponding to the energy minimum.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;This workflow provides a systematic approach to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify dominant motions in your trajectory via PCA&lt;/li&gt;
&lt;li&gt;Visualize structural variation through projection plots&lt;/li&gt;
&lt;li&gt;Map the free energy landscape based on PC space&lt;/li&gt;
&lt;li&gt;Extract the most stable conformations for further analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These methods are widely used for post-simulation analysis in structural biology and drug discovery.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Validating Molecular Docking Poses with DFT: A Quick Guide</title>
      <link>https://yboulaamane.github.io/blog/validating-molecular-docking-poses-with-dft-a-quick-guide/</link>
      <pubDate>Thu, 03 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/validating-molecular-docking-poses-with-dft-a-quick-guide/</guid>
      <description>&lt;p&gt;Molecular docking is a cornerstone of computer-aided drug discovery. In docking studies, a small molecule (ligand) is computationally “fit” into a protein’s binding site to predict the preferred orientation (pose) and binding affinity. This approach allows researchers to screen large libraries of compounds rapidly and propose how a drug candidate might bind to its target. Docking is valued for generating hypotheses and guiding experiments in the early stages of drug design.&lt;/p&gt;
&lt;h2 id=&#34;molecular-docking-in-drug-discovery-power-and-pitfalls&#34;&gt;Molecular Docking in Drug Discovery: Power and Pitfalls&lt;/h2&gt;
&lt;p&gt;Molecular docking is not foolproof. The scoring functions used in most docking programs are simplifications – they account for basic interactions like van der Waals forces and electrostatics, but often ignore ligand strain and detailed quantum effects. Docking assumes a mostly rigid receptor and sometimes forces the ligand into conformations that real molecules might not adopt easily. As a result, the &lt;strong&gt;top-ranked pose cannot always be trusted&lt;/strong&gt; – a high docking score doesn’t guarantee the pose is physically realistic. In practice, docking can produce &lt;strong&gt;false positives&lt;/strong&gt;: poses that look good in silico but are unstable or energetically unfavorable in reality. This limitation creates a need for validation steps after docking, to filter out poses that are likely artifacts of the scoring function.&lt;/p&gt;
&lt;h2 id=&#34;validating-docking-poses-with-dft-energy-calculations&#34;&gt;Validating Docking Poses with DFT Energy Calculations&lt;/h2&gt;
&lt;p&gt;This is where &lt;strong&gt;Density Functional Theory (DFT)&lt;/strong&gt; comes into play as a powerful validation tool. DFT is a quantum mechanical method that can provide a more accurate calculation of a molecule’s energy and properties by explicitly considering its electron distribution. Unlike docking’s empirical scoring, DFT is physics-based and can evaluate how “comfortable” a ligand is in a given conformation by computing its electronic energy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The core idea for pose validation&lt;/strong&gt; is simple: use DFT to optimize the ligand’s geometry starting from the docked pose, and compare the energies of the two structures (docked vs. DFT-relaxed). If the docked pose was realistic, the DFT geometry optimization should not drastically alter the ligand’s structure or energy. But if the docking pose was strained or artificially stabilized by the scoring function, the ligand will likely relax to a very different geometry and &lt;strong&gt;release a lot of energy&lt;/strong&gt; in the process. The energy difference between the initial docked structure and the optimized structure is essentially the &lt;strong&gt;strain energy&lt;/strong&gt; that was needed to force the ligand into the docked pose.&lt;/p&gt;
&lt;p&gt;In practice, the validation workflow might look like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Take the Docked Pose:&lt;/strong&gt; After docking, extract the coordinates of the top-ranked ligand pose.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Single-Point Energy (Optional):&lt;/strong&gt; Compute the DFT energy of the ligand &lt;em&gt;in the docked conformation&lt;/em&gt; (without relaxing it) to have a reference energy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Geometry Optimization:&lt;/strong&gt; Perform a DFT geometry optimization of the ligand (in isolation or in the binding pocket, see below). This yields a relaxed structure and its energy, representing a more &lt;em&gt;unstrained&lt;/em&gt; conformation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compare Energies:&lt;/strong&gt; Calculate the difference in energy between the docked pose and the DFT-optimized pose. A small difference (e.g. a few kcal/mol) suggests the docking pose was already near an energy minimum (plausible). A large difference means the docked pose was high-energy and thus likely unstable.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Why does this help? Imagine a ligand that the docking algorithm contorted to fit the protein. If that contorted shape lies, say, &lt;strong&gt;10 kcal/mol&lt;/strong&gt; higher in energy than the ligand’s preferred shape, it’s improbable that the ligand would actually bind that way – the protein would have to compensate by providing at least 10 kcal/mol of extra favorable interactions, which is quite significant. Empirical evidence and advanced workflows reflect this: if the energy gap is above a certain threshold (commonly cited around 8–10 kcal/mol), the pose is likely a false positive. In other words, a &lt;strong&gt;&amp;gt;8 kcal/mol strain&lt;/strong&gt; in the ligand often indicates an unrealistic binding mode.&lt;/p&gt;
&lt;p&gt;It’s important to note that this validation via DFT focuses on the ligand’s &lt;strong&gt;internal energy&lt;/strong&gt;. Docking scores try to estimate binding free energy (which is ligand–protein interactions minus strain and entropy costs). By using DFT, we isolate one component of that: how much strain energy the ligand must bear in that pose. An ideal binder has a low strain energy (the ligand can adopt its binding conformation easily) and strong intermolecular interactions. If strain energy is high, the binding affinity prediction from docking is overly optimistic because in reality the ligand would prefer to change shape (or not bind at all).&lt;/p&gt;
&lt;h2 id=&#34;key-dft-concepts-homo-lumo-and-energy-gaps-in-ligand-binding&#34;&gt;Key DFT Concepts: HOMO, LUMO, and Energy Gaps in Ligand Binding&lt;/h2&gt;
&lt;p&gt;When you perform DFT calculations, you gain insights beyond just geometry and total energy. DFT will provide information on the molecule’s molecular orbitals, including the &lt;strong&gt;HOMO&lt;/strong&gt; (Highest Occupied Molecular Orbital) and &lt;strong&gt;LUMO&lt;/strong&gt; (Lowest Unoccupied Molecular Orbital). These are often called the &lt;em&gt;frontier molecular orbitals&lt;/em&gt; because they represent the frontier between filled and empty electron states. The HOMO is the highest-energy orbital that contains electrons, and the LUMO is the lowest-energy orbital that is empty.&lt;/p&gt;
&lt;p&gt;Why do these matter in the context of ligand binding? The characteristics of the HOMO and LUMO can hint at how the ligand might interact electronically with the protein:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HOMO&lt;/strong&gt; – The HOMO can be thought of as the electron-donating ability of the ligand. A high-energy (less negative) HOMO means the ligand’s outermost electrons are relatively easy to donate. For example, if a ligand has a high HOMO and the protein has a region of low electron density (or a metal ion), the ligand could donate electron density into the protein’s LUMO or metal orbitals, facilitating binding. In frontier orbital theory terms, often a ligand’s HOMO will interact with the protein’s LUMO (for instance, π electrons of a ligand interacting with empty orbitals of a metal center in an enzyme).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LUMO&lt;/strong&gt; – The LUMO represents the ligand’s capacity to accept electrons. A low-energy (more negative) LUMO indicates the ligand is easily reduced or can accept electron density. If the protein has electron-rich sites (like an electron-donating amino acid side chain), a ligand with a low LUMO might accept electron density from the protein’s HOMO. One theoretical model even posits that effective binding involves the protein’s HOMO interacting with the ligand’s LUMO and &lt;em&gt;vice versa&lt;/em&gt;, aligning with classical donor–acceptor concepts in chemistry.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HOMO–LUMO Gap&lt;/strong&gt; – The difference in energy between the HOMO and LUMO (the band gap for the molecule) is a measure of the molecule’s electronic stability and reactivity. Generally, a &lt;strong&gt;small HOMO-LUMO gap&lt;/strong&gt; means the molecule is more polarizable and reactive (lower “hardness”), whereas a &lt;strong&gt;large gap&lt;/strong&gt; implies a more inert, stable molecule
. In binding terms, a highly reactive ligand (small gap) might form covalent bonds or undergo chemical reactions in the binding site, whereas a large-gap ligand is more chemically stable (it will bind through non-covalent interactions without undergoing changes). For most non-covalent docking scenarios, the HOMO-LUMO gap won’t change dramatically upon binding, but it’s a useful concept for understanding if a ligand is prone to electronic interactions. A ligand with a very small gap might require special consideration (for example, it could auto-ionize or be reactive). Conversely, if docking a very stable molecule (large gap), one might expect purely shape/steric-driven binding.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For early-career researchers, it’s not critical to master frontier orbital theory immediately, but being aware of these concepts adds depth to your analysis. For instance, if your DFT results show the ligand has a HOMO centered on a particular functional group, that group might be the one donating electron density to form a hydrogen bond or coordinate a metal in the protein. Likewise, the magnitude of the HOMO-LUMO gap can qualitatively indicate if the ligand is likely to be chemically flexible or if it might require a lot of energy to excite or change – which plays into how it might behave in a binding site.&lt;/p&gt;
&lt;h2 id=&#34;geometry-optimization-vs-docked-pose-an-orca-example&#34;&gt;Geometry Optimization vs. Docked Pose: An ORCA Example&lt;/h2&gt;
&lt;p&gt;Let’s walk through how you would actually perform a DFT geometry optimization on a docked pose, using the &lt;strong&gt;ORCA&lt;/strong&gt; quantum chemistry software as a tool of choice. ORCA is a powerful and user-friendly quantum chemistry package that is free for academic use. It can perform DFT calculations (among many other methods) and is well-suited for geometry optimizations of small molecules.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1: Preparing the Structure.&lt;/strong&gt; After docking (using AutoDock, Glide, or any other docking software), you will have a ligand pose, often saved in a file format like PDB or MOL2. The first task is to extract that ligand’s coordinates for a DFT program. You can use a molecule editor or converter (like OpenBabel or Avogadro) to get the coordinates in XYZ format or directly paste them into an ORCA input file. Ensure you have the correct atom types and that the geometry corresponds to the docked conformation you want to test.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2: Creating the ORCA Input File.&lt;/strong&gt; ORCA input files are simple text files. Below is an example of what an ORCA input might look like for optimizing a ligand geometry:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! B3LYP-D3 def2-SVP Opt TightSCF  
&amp;lt;br/&amp;gt;%pal nprocs 4 end # Use 4 CPU cores (adjust as available)  
&amp;lt;br/&amp;gt;\* xyz 0 1  
C 0.127 1.265 0.000 # (Example coordinates for the ligand)  
N -0.769 0.352 0.000 # Replace with your ligand&#39;s atoms...  
C 0.127 -0.961 0.000  
O 1.288 -1.414 0.000  
... (rest of ligand atoms)  
\*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s break down this input:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first line beginning with ! lists the &lt;strong&gt;method and options&lt;/strong&gt;. In this example, we use B3LYP-D3 def2-SVP Opt TightSCF. This specifies the DFT functional B3LYP with D3 dispersion correction, a moderate basis set (def2-SVP), and requests a geometry optimization (Opt). TightSCF is a keyword to tighten the convergence criteria of the self-consistent field (which leads to more accurate energy determination, albeit slightly longer computation). These settings are a reasonable starting point for an organic molecule optimization.&lt;/li&gt;
&lt;li&gt;The %pal section is optional; it requests parallel processing (here 4 cores). If you have access to multiple CPUs, ORCA can parallelize many tasks, speeding up the calculation.&lt;/li&gt;
&lt;li&gt;The * xyz 0 1 line begins the coordinate block. The format here is * xyz \[charge\] \[multiplicity\], followed by the atomic coordinates. In our example, 0 1 means the molecule has neutral charge and a singlet multiplicity (no unpaired electrons). Adjust these if your ligand is an ion or radical (e.g., * xyz -1 1 for a -1 charged anion, or * xyz 0 2 for a neutral doublet radical).&lt;/li&gt;
&lt;li&gt;The subsequent lines list each atom: atomic symbol and its X, Y, Z coordinates (in Angstroms). You would insert the coordinates of your ligand as obtained from the docking output.&lt;/li&gt;
&lt;li&gt;The coordinate block is closed by a line with just *.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Save this text as, for example, ligand_opt.inp. To run the calculation, you would execute ORCA from the command line (e.g., orca ligand_opt.inp &amp;gt; ligand_opt.out). ORCA will then carry out the DFT calculation, iteratively adjusting the geometry to find a minimum energy structure. After completion, you should check the output file for the results. If the optimization was successful, ORCA will report &amp;ldquo;&lt;strong&gt;OPTIMIZATION RUN DONE&lt;/strong&gt;&amp;rdquo; and provide the final coordinates and energies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3: Analyzing the Optimized Geometry and Energy.&lt;/strong&gt; Compare the final coordinates from ORCA’s output (ligand_opt.out) to the initial docked coordinates. Did the ligand change shape significantly? Often, you can visualize both the docked pose and the DFT-optimized pose in a molecular viewer (PyMOL, Chimera, or even Avogadro) to see any structural shifts. If the ligand only moved slightly, that suggests the docked pose was close to a true minimum. But if the ligand rearranged notably (e.g., flipping a ring, straightening a torsion, etc.), that indicates the docking pose might have been a high-energy conformation that the DFT relaxation corrected.&lt;/p&gt;
&lt;p&gt;From the output, note the final single-point energy of the optimized structure. Let’s say ORCA reports the optimized energy as &lt;strong&gt;E_opt&lt;/strong&gt; (in atomic units, Hartrees, which you can convert to kcal/mol if needed by multiplying the difference by 627.5). If you also computed the single-point energy of the initial structure (call it &lt;strong&gt;E_initial&lt;/strong&gt;), you can quantify the energy difference: &lt;strong&gt;ΔE = E_initial – E_opt&lt;/strong&gt;. A positive ΔE (when converted to kcal/mol) means the initial structure was that many kcal/mol higher in energy than the optimized structure.&lt;/p&gt;
&lt;p&gt;For example, if ΔE comes out to be +10.5 kcal/mol, it means the docked pose had ~10.5 kcal/mol of strain relative to the relaxed state. Such a large strain is a red flag. In contrast, if ΔE is only +2 kcal/mol, the pose is probably fine (a 2 kcal strain is quite tolerable and could easily be offset by protein–ligand interactions).&lt;/p&gt;
&lt;h2 id=&#34;transition-state-search-for-pose-validation-advanced&#34;&gt;Transition State Search for Pose Validation (Advanced)&lt;/h2&gt;
&lt;p&gt;In some cases, researchers may go a step further and perform a &lt;strong&gt;transition state (TS) search&lt;/strong&gt; related to the conformational change between the docked pose and the optimized geometry. This is a more advanced technique and not always necessary for routine docking validation, but it’s conceptually interesting. The idea is to identify the &lt;em&gt;energy barrier&lt;/em&gt; that separates the docked conformation from the optimized conformation on the potential energy surface. In other words, if the ligand must distort from shape A (optimized) to shape B (docked), what is the highest-energy point (transition state) along that path?&lt;/p&gt;
&lt;p&gt;Finding a transition state for a conformational change can be tricky, but ORCA does offer tools for this. One approach is to perform a constrained scan or use the &lt;strong&gt;eigenvector-following TS search&lt;/strong&gt; algorithm. For example, ORCA’s keyword OptTS turns on a transition state optimization using a variant of the geometry optimizer that searches for a saddle point (a maximum along one coordinate, minimum along others). To use it, you typically need a decent initial guess geometry that is partway between the two conformations or an initial guess of the normal mode that leads to the distortion.&lt;/p&gt;
&lt;p&gt;An ORCA input snippet for a transition state search might look like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! B3LYP-D3 def2-SVP OptTS TightSCF  
&amp;lt;br/&amp;gt;%geom  
TS_Mode {M 0} # follow the lowest-frequency mode (mode 0) uphill to find TS  
end  
&amp;lt;br/&amp;gt;\* xyz 0 1  
... (coordinates of a guess structure near the anticipated transition state) ...  
\*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this input, we replaced Opt with OptTS to request a transition state optimization. We also included a %geom block to specify the TS search mode. {M 0} tells ORCA to follow the eigenvector with the lowest eigenvalue (the softest vibrational mode) uphill – we assume that mode corresponds to the distortion between the two conformers. In practice, you might first do a relaxed scan of a dihedral angle or some coordinate from the docked to the optimized structure to generate an intermediate geometry, then use that as a starting point for OptTS. If ORCA succeeds, it will locate a saddle point, evidenced by one imaginary frequency in the vibrational analysis (if you request a frequency calculation).&lt;/p&gt;
&lt;p&gt;For validating docking poses, a full TS search is usually &lt;strong&gt;optional&lt;/strong&gt;. Most of the time, simply comparing energies ΔE is enough to flag problematic poses. But the concept of an “energy barrier” is useful: if the pose is &lt;strong&gt;so&lt;/strong&gt; strained that the ligand would need to overcome, say, an 8+ kcal/mol barrier to reach a stable conformation, it’s unlikely that binding is real – the protein isn’t a magical force field that can freeze the ligand in a high-energy shape without paying the price in binding affinity.&lt;/p&gt;
&lt;h2 id=&#34;interpreting-the-dft-results-when-is-a-pose-unreasonable&#34;&gt;Interpreting the DFT Results: When is a Pose Unreasonable?&lt;/h2&gt;
&lt;p&gt;After running the DFT calculations, you will have quantitative data to make a call on your docking poses. The rule of thumb mentioned earlier bears repeating: &lt;strong&gt;if the energy difference between the docked pose and the optimized geometry exceeds about 8 kcal/mol, be very skeptical of that docking pose&lt;/strong&gt;. This threshold isn’t absolute, but it comes from studies and expert recommendations that examine how much strain real protein-bound ligands typically have. Most experimentally observed ligand conformations in crystal structures don’t carry more than ~5 kcal/mol of strain energy. Thus, if your pose is demanding 10+ kcal/mol just to hold that conformation, it likely wouldn’t survive in a real biological system – the ligand would either bind in a different conformation or not bind at all.&lt;/p&gt;
&lt;p&gt;On the other hand, if ΔE is small (for example, 0–3 kcal/mol), the pose is probably physically plausible. The ligand doesn’t mind being in that conformation, and any small strain could potentially be offset by binding interactions. Gray areas are in between – e.g., a 5–7 kcal/mol strain might be borderline. In those cases, consider the context: does the protein provide exceptionally strong interactions (like multiple salt bridges or a covalent bond) that could compensate? If not, you might still doubt a 6 kcal/mol-strained pose, but it’s not as clear-cut as a 12 kcal/mol strain which is almost certainly artifactual.&lt;/p&gt;
&lt;p&gt;It’s also enlightening to look at &lt;em&gt;what parts&lt;/em&gt; of the ligand changed upon optimization. Perhaps a particular ring system flipped – that could indicate that in the docked pose, that ring was forced into an awkward orientation to make a protein contact. If the DFT opt shows it flipping 180°, it means the docking algorithm’s scoring perhaps overestimated the benefit of that contact or ignored a torsional penalty. This gives you insight into how to refine your docking: you might impose a torsion constraint in docking next time, or simply be aware that pose might need re-evaluation with induced fit or molecular dynamics.&lt;/p&gt;
&lt;p&gt;Another thing to glean from DFT output: the &lt;strong&gt;HOMO/LUMO energies&lt;/strong&gt; of the optimized ligand. While not directly telling you about the pose stability, they can hint if the ligand gained or lost any conjugation or planarity. For example, if the docked pose had a certain π–π stacking and the ligand optimized away from that planarity, its HOMO-LUMO gap might increase (less conjugation). This is more of a niche consideration, but as you grow more comfortable with DFT data, you’ll start to connect these dots.&lt;/p&gt;
&lt;h2 id=&#34;practical-advice-for-integrating-dft-into-docking-workflows&#34;&gt;Practical Advice for Integrating DFT into Docking Workflows&lt;/h2&gt;
&lt;p&gt;For early-career researchers with limited computational chemistry experience, integrating DFT checks into your docking workflow might seem daunting at first. Here are some practical tips to help you get started:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use DFT selectively:&lt;/strong&gt; You don’t need to DFT-optimize every single docking result (that could be thousands of compounds!). Prioritize a small set of top-scoring poses or any pose that looks chemically suspicious. For instance, if a docking pose shows a ligand in an unusual contortion or with strained bond angles just to fit the pocket, that’s a prime candidate for DFT validation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Choose the right level of theory:&lt;/strong&gt; Aim for a balance between accuracy and speed. Methods like B3LYP (a popular DFT functional) with at least a double-zeta basis set (e.g., def2-SVP or 6-31G**) are a common starting point for organic molecules. Include dispersion corrections (e.g., the D3 or D4 dispersion in ORCA, invoked by adding -D3 or similar in the functional line) because dispersion can affect conformational energies. You can often get good results with these settings without the calculation taking too long. If your ligand contains metal atoms or is very large, you may need to use effective core potentials or a smaller basis set respectively, or consider semi-empirical methods as a preliminary filter.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leverage faster methods for initial screening:&lt;/strong&gt; If full DFT is too slow for the number of poses you want to check, consider using a semi-empirical QM method or a fast approximate DFT like &lt;strong&gt;GFN2-xTB&lt;/strong&gt; or &lt;strong&gt;PM6&lt;/strong&gt; just to weed out obviously high-strain poses. ORCA can run semi-empirical calculations as well (e.g., using the GFN2-xTB keyword). These methods are less accurate than DFT but much faster – a reasonable compromise for initial strain assessment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimize in context if possible:&lt;/strong&gt; The simplest DFT check is to optimize the ligand in vacuum (or implicit solvent) as we described. This tells you the ligand’s intrinsic strain. In reality, the protein might stabilize some strained conformations. For a more nuanced check, you can do a &lt;strong&gt;QM/MM optimization&lt;/strong&gt; – where the ligand is treated with DFT and the protein with a molecular mechanics force field. ORCA supports QM/MM calculations, though setting them up is more complex. Alternatively, you could constrain key interaction distances during the ligand optimization to mimic the protein’s hold. These advanced approaches can be considered if a vacuum-phase optimization suggests strain, but you suspect the protein’s environment might significantly alter the picture.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check for convergence and errors:&lt;/strong&gt; When running ORCA (or any QM software), always verify that the calculation converged properly. In ORCA, if the geometry optimizer failed (e.g., due to a bad initial geometry or insufficient iterations), the results won’t be reliable. You might need to increase MaxIter in the %geom settings or tweak the initial structure. Similarly, watch out for any error messages in the output (like SCF not converged, which you can address by adding SlowConv or other SCF convergence aids).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpret results conservatively:&lt;/strong&gt; Remember that computed energies have some error bars. A ~2 kcal/mol difference is probably within the “noise” of method accuracy – it means essentially no significant strain. A &amp;gt;10 kcal/mol difference is huge and almost certainly meaningful. Middle values (e.g., 4–7 kcal/mol) might depend on method, so consider doing a sanity check: perhaps re-optimize using a different functional (like M06-2X or PBE0) or a higher basis set for a single-point energy on the optimized geometry to see if the gap persists. If all methods agree that a pose is high-strain, you can be confident in flagging it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use visualization and intuition:&lt;/strong&gt; DFT numbers are great, but always circle back to the chemistry. Visualize the DFT-relaxed pose overlaid with the docked pose. Which bonds rotated? Which angles opened up? Does that make chemical sense (e.g., a steric clash was resolved, an eclipsed conformation went to staggered)? This can teach you &lt;em&gt;why&lt;/em&gt; a pose was unstable and improve your docking criteria next time (for example, you might realize a particular functional group prefers to be planar but the docking forced it non-planar).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time and resource management:&lt;/strong&gt; DFT calculations can be time-consuming, especially for larger molecules. If you’re working on a laptop, start with very small tests. Perhaps try optimizing just a piece of the ligand or a single pose and see how long it takes. Make use of any high-performance computing resources your institution provides for larger jobs. And be mindful of ORCA’s memory and disk usage settings if your system is large (these can be controlled via %maxcore and other inputs).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learn from community examples:&lt;/strong&gt; Many researchers have shared tutorials and benchmarks on docking and QM. Don’t hesitate to look up examples (including the ORCA forum and manual) for similar use-cases. For instance, searching for “ligand strain DFT docking” might lead you to studies where they did exactly this kind of validation, giving you a sense of typical values and pitfalls to watch out for.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By incorporating DFT into your workflow, you add a layer of rigor that can save you from chasing false leads. It trains your chemical intuition as well – after a few such exercises, you’ll start to anticipate which poses are likely strained without even computing them, simply by recognizing telltale geometrical quirks.&lt;/p&gt;
&lt;h2 id=&#34;conclusion-a-stronger-docking-workflow-with-quantum-insights&#34;&gt;Conclusion: A Stronger Docking Workflow with Quantum Insights&lt;/h2&gt;
&lt;p&gt;In summary, molecular docking is a powerful technique for generating hypotheses in drug discovery, but it has well-known limitations in accuracy. DFT provides a complementary approach to &lt;strong&gt;double-check and validate docking poses&lt;/strong&gt; by focusing on the fundamental question: Is this pose physically reasonable for the ligand molecule? By optimizing the ligand geometry and examining energies, DFT can expose cases where the docking solution is riding on unrealistically high internal strain. Early-career researchers can greatly benefit from this approach, as it not only improves the reliability of computational predictions but also deepens one’s understanding of molecular behavior.&lt;/p&gt;
&lt;p&gt;Using ORCA or similar quantum chemistry tools to perform these validations might seem like extra work, but it pays off by preventing wasted effort on false positives. Moreover, it offers a learning opportunity to become familiar with quantum chemical concepts like HOMOs, LUMOs, and energy landscapes in a very practical context. Over time, these skills will strengthen your ability to critically evaluate computational results and make you a more effective researcher in computational chemistry and drug design.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Integrating DFT into docking workflows doesn’t mean abandoning speed or simplicity – it means knowing when to switch from a fast, heuristic method to a detailed, first-principles check.&lt;/strong&gt; With the tips and examples provided, you should be well on your way to applying DFT validation in your own projects. Happy docking, and may your binding poses be ever in your favor (and physically plausible)!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt; The concepts and strategies discussed here are informed by both practical computational experience and literature. The idea of using DFT to optimize ligand geometries and flag strained poses is highlighted in advanced docking validation workflows. The limitations of docking scoring functions in accounting for ligand strain have been noted in the literature, leading to recommendations for post-docking refinement. Definitions of HOMO/LUMO and their relevance to chemical reactivity are well-established in molecular orbital theory
, and even in the context of protein–ligand interactions the frontier orbital alignment can play a role. ORCA, as a chosen tool in our examples, is a widely used quantum chemistry package available to academics, and its manual provides details on techniques like transition state searches. These sources and the accumulated knowledge from them reinforce the practices recommended in this guide.&lt;/p&gt;
&lt;p&gt;
 HOMO, LUMO, gap, hardness, and softness of all compounds.&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI &#43; Chemistry: Building Drug Discovery Pipelines with Free Tools</title>
      <link>https://yboulaamane.github.io/blog/ai-chemistry-building-drug-discovery-pipelines-with-free-tools/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/ai-chemistry-building-drug-discovery-pipelines-with-free-tools/</guid>
      <description>&lt;p&gt;The future of drug discovery is open, smart, and community-driven. Gone are the days of relying solely on expensive, proprietary platforms, today’s open-source AI tools are transforming how we explore chemical space, and they’re accessible to all.&lt;br&gt;
Whether you&amp;rsquo;re screening billions of compounds or predicting molecular properties, a rich ecosystem of open-source libraries and data is leveling the playing field for startups, academics, and even “indie” scientists. To illustrate this revolution, let’s walk through a drug discovery pipeline for a real target – the ABL kinase (the c-Abl tyrosine kinase, infamous as the target of the leukemia drug imatinib). We’ll see how open tools empower every step, from data to models to visualization, with code snippets showing these tools in action.&lt;/p&gt;
&lt;h2 id=&#34;from-data-to-discovery-the-open-source-pipeline-case-study-abl-kinase&#34;&gt;From Data to Discovery: The Open-Source Pipeline (Case Study: ABL Kinase)&lt;/h2&gt;
&lt;p&gt;To ground things, imagine we’re hunting for new inhibitors of the ABL kinase, a critical enzyme in cancer (Bcr-Abl causes chronic myeloid leukemia when mutated). We want to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Gather known bioactivity data for ABL&lt;/li&gt;
&lt;li&gt;Featurize and analyze molecules&lt;/li&gt;
&lt;li&gt;Train an AI model to predict new inhibitors&lt;/li&gt;
&lt;li&gt;Convert and prepare compounds for simulation&lt;/li&gt;
&lt;li&gt;Visualize how they bind&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Open resources make this feasible:&lt;/p&gt;
&lt;h3 id=&#34;open-data-chembl&#34;&gt;Open Data (ChEMBL)&lt;/h3&gt;
&lt;p&gt;We can retrieve ABL bioactivity data from ChEMBL, a large open database of drug-like molecules and their biological activities. (ChEMBL contains millions of measured compound-target activities – over 5.4 million bioactivity data points for 1M+ compounds as of 2012, and it’s grown even larger since!). This gives us a training dataset of known ABL inhibitors and non-inhibitors without any paywalls. We can use ChEMBL’s web services or downloads to get, say, all compounds tested against ABL (IC50, Ki values, etc.), then use Pandas to filter and tabulate the data.&lt;/p&gt;
&lt;h3 id=&#34;data-handling-pandas--numpy&#34;&gt;Data Handling (Pandas &amp;amp; NumPy)&lt;/h3&gt;
&lt;p&gt;With our ABL dataset in hand (e.g. as a CSV of SMILES and activity labels), we use Pandas to clean and manipulate it and NumPy for any numerical computing. These “classics” form the backbone of any custom pipeline – e.g., grouping data, normalizing values, splitting into train/test sets. They might not be drug discovery-specific, but their flexibility is indispensable. We might do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
df = pd.read_csv(&amp;quot;ABL_bioactivity.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;rdkit--the-unsung-hero-of-cheminformatics&#34;&gt;RDKit – The Unsung Hero of Cheminformatics&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re doing anything with molecules in Python, chances are RDKit is working behind the scenes. RDKit is an open-source cheminformatics toolkit widely used for tasks like generating molecular fingerprints, performing substructure searches, computing descriptors, and manipulating chemical structures.&lt;/p&gt;
&lt;p&gt;In our ABL example, we use RDKit to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate Morgan fingerprints&lt;/li&gt;
&lt;li&gt;Perform substructure searches&lt;/li&gt;
&lt;li&gt;Compute molecular descriptors&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;code-example&#34;&gt;Code Example:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;from rdkit import Chem, DataStructs
from rdkit.Chem import AllChem

imatinib_smiles = &amp;quot;Cc1ccc(cc1Nc2nccc(n2)c3cccnc3)NC(=O)c4ccc(cc4)CN5CCN(CC5)C&amp;quot;
nilotinib_smiles = &amp;quot;Cc1ccc(cc1Nc2nccc(n2)c3cccnc3)C(=O)Nc4cc(cc(c4)n5cc(nc5)C)C(F)(F)F&amp;quot;

mol1 = Chem.MolFromSmiles(imatinib_smiles)
mol2 = Chem.MolFromSmiles(nilotinib_smiles)

fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, radius=2, nBits=2048)
fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, radius=2, nBits=2048)

sim = DataStructs.TanimotoSimilarity(fp1, fp2)
print(f&amp;quot;Tanimoto similarity: {sim:.2f}&amp;quot;)

query = Chem.MolFromSmarts(&amp;quot;c1ccc(cc1)Nc2nccc(n2)&amp;quot;)
match = mol1.HasSubstructMatch(query)
print(&amp;quot;Substructure match:&amp;quot;, match)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;deepchem--ai-made-beautifully-simple&#34;&gt;DeepChem – AI Made Beautifully Simple&lt;/h2&gt;
&lt;p&gt;DeepChem is an open-source library that brings advanced models like GCNs and multitask networks to your fingertips. It’s built on TensorFlow/PyTorch but hides the complexity.&lt;/p&gt;
&lt;h3 id=&#34;code-example-1&#34;&gt;Code Example:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;import deepchem as dc
import numpy as np

smiles_list = [
&amp;quot;Cc1ccc(cc1Nc2nccc(n2)c3cccnc3)NC(=O)c4ccc(cc4)CN5CCN(CC5)C&amp;quot;,  # active
&amp;quot;CCOC(=O)c1ccc(cc1)N&amp;quot;,  # inactive
]
labels = np.array([1, 0])

featurizer = dc.feat.MolGraphConvFeaturizer()
X = featurizer.featurize(smiles_list)
y = labels

dataset = dc.data.NumpyDataset(X, y)

model = dc.models.GraphConvModel(n_tasks=1, mode=&#39;classification&#39;, metrics=[dc.metrics.Metric(dc.metrics.roc_auc_score)])
model.fit(dataset, nb_epoch=20)

pred_probs = model.predict(dataset)
print(pred_probs)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;open-babel--convert-like-a-pro&#34;&gt;Open Babel – Convert Like a Pro&lt;/h2&gt;
&lt;p&gt;Open Babel helps switch between formats like SMILES, SDF, PDB, etc.&lt;/p&gt;
&lt;h3 id=&#34;code-example-2&#34;&gt;Code Example:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;from openbabel import pybel

smiles = &amp;quot;Cc1ccc(cc1Nc2nccc(n2)c3cccnc3)NC(=O)c4ccc(cc4)CN5CCN(CC5)C&amp;quot;
mol = pybel.readstring(&amp;quot;smi&amp;quot;, smiles)
mol.addh()
mol.make3D()
mol.write(&amp;quot;sdf&amp;quot;, &amp;quot;imatinib_3D.sdf&amp;quot;, overwrite=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pymol--visualize-what-ai-discovers&#34;&gt;PyMOL – Visualize What AI Discovers&lt;/h2&gt;
&lt;p&gt;PyMOL is great for inspecting protein–ligand complexes and generating publication-quality figures.&lt;/p&gt;
&lt;h3 id=&#34;code-example-3&#34;&gt;Code Example:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;import pymol2

with pymol2.PyMOL() as pymol:
	cmd = pymol.cmd
	cmd.load(&amp;quot;ABL_kinase.pdb&amp;quot;, &amp;quot;protein&amp;quot;)
	cmd.load(&amp;quot;imatinib_3D.sdf&amp;quot;, &amp;quot;ligand&amp;quot;)
	cmd.hide(&amp;quot;everything&amp;quot;)
	cmd.show(&amp;quot;cartoon&amp;quot;, &amp;quot;protein&amp;quot;)
	cmd.show(&amp;quot;sticks&amp;quot;, &amp;quot;ligand&amp;quot;)
	cmd.zoom(&amp;quot;ligand&amp;quot;, 5)
	cmd.png(&amp;quot;abl_imatinib.png&amp;quot;, width=800, height=600, ray=1)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;chemprop--graph-neural-networks-made-easy&#34;&gt;Chemprop – Graph Neural Networks Made Easy&lt;/h2&gt;
&lt;p&gt;Chemprop offers fast training of MPNNs for tasks like QSAR and virtual screening.&lt;/p&gt;
&lt;h3 id=&#34;cli-example&#34;&gt;CLI Example:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;chemprop_train --data_path abl_activity.csv --smiles_column smiles --target_columns active \
           --dataset_type classification --save_dir abl_model
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;python-example&#34;&gt;Python Example:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;from chemprop.train import run_training

params = {
&amp;quot;data_path&amp;quot;: &amp;quot;abl_activity.csv&amp;quot;,
&amp;quot;smiles_column&amp;quot;: &amp;quot;smiles&amp;quot;,
&amp;quot;target_columns&amp;quot;: [&amp;quot;active&amp;quot;],
&amp;quot;dataset_type&amp;quot;: &amp;quot;classification&amp;quot;,
&amp;quot;save_dir&amp;quot;: &amp;quot;abl_model&amp;quot;,
&amp;quot;epochs&amp;quot;: 30
}
run_training(params)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-classics-pandas-numpy-scikit-learn--data-science-backbone&#34;&gt;The Classics: Pandas, NumPy, Scikit-Learn – Data Science Backbone&lt;/h2&gt;
&lt;p&gt;These libraries handle everything from preprocessing to baseline models.&lt;/p&gt;
&lt;h3 id=&#34;example-random-forest&#34;&gt;Example Random Forest:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X = [list(map(int, fp.ToBitString())) for fp in [fp1, fp2]]
y = labels

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)
model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)
print(&amp;quot;Validation accuracy:&amp;quot;, model.score(X_val, y_val))
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-open-source-revolution-in-action&#34;&gt;The Open-Source Revolution in Action&lt;/h2&gt;
&lt;p&gt;As we’ve seen, an end-to-end drug discovery pipeline can now be constructed with open-source tools at every step, with each tool excelling in its domain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data acquisition from open databases (ChEMBL, PubChem, etc.) provides the fuel.&lt;/li&gt;
&lt;li&gt;RDKit ensures we can manipulate and understand chemical structures easily.&lt;/li&gt;
&lt;li&gt;DeepChem and Chemprop bring powerful AI models to make predictions or generate new hypotheses.&lt;/li&gt;
&lt;li&gt;Open Babel makes sure our data can move anywhere it needs to (no format silos).&lt;/li&gt;
&lt;li&gt;PyMOL lets us visualize and validate the AI’s suggestions in the context of 3D biology.&lt;/li&gt;
&lt;li&gt;Pandas/NumPy/Sci-kit tie everything together with data handling and auxiliary analyses.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Importantly, all of these are free and open. There are no license fees or onerous contracts – you can install them on your laptop right now and get to work. This open-source ecosystem is accelerating innovation by putting incredible power in the hands of anyone with an idea and a bit of coding knowledge. It lowers the barrier to entry for drug discovery projects: a small startup or an academic lab can now deploy workflows that rival those in big pharma, without spending a fortune on software.&lt;/p&gt;
&lt;p&gt;The open-source revolution is not just about cost savings; it’s about community and collaboration. These tools are constantly improving through contributions from users worldwide. For example, new algorithms and best practices in chemoinformatics are often rapidly integrated into RDKit or DeepChem by community members. If a feature is missing, you can add it or request it. This fosters an environment where researchers share not just data, but also the methods to analyze that data – leading to more reproducible and transparent science.&lt;/p&gt;
&lt;p&gt;What’s in your AI drug discovery toolkit? Chances are, if you start exploring, you’ll end up with many of the open-source tools above in your repertoire. And you’ll be joining a movement that is driving the future of pharmaceutical innovation. No paywalls, no red tape – just raw potential and a community eager to push the boundaries of what AI can do for medicine. The open-source revolution in drug discovery is here, and it’s incredibly exciting. Get involved, experiment with these tools, and who knows – you might discover the next Halicin or imatinib, and you’ll have the open-source community cheering you on every step of the way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Step-by-Step MD Simulation of a Protein–Ligand Complex with GROMACS</title>
      <link>https://yboulaamane.github.io/blog/an-in-depth-guide-to-md-simulation-and-analysis-of-a-proteinligand-complex/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/an-in-depth-guide-to-md-simulation-and-analysis-of-a-proteinligand-complex/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This post walks through the &lt;strong&gt;complete setup of a protein–ligand MD simulation&lt;/strong&gt; with GROMACS.&lt;br&gt;
We use &lt;strong&gt;CHARMM36&lt;/strong&gt; for proteins, &lt;strong&gt;CGenFF&lt;/strong&gt; for ligands, and the &lt;strong&gt;TIP3P water model&lt;/strong&gt;.&lt;br&gt;
Each step is explained briefly before showing the corresponding command.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-0-pdbfixer&#34;&gt;Step 0: PDBFixer&lt;/h2&gt;
&lt;p&gt;We begin by repairing the input PDB file (adding missing atoms, hydrogens, etc.). This ensures the protein structure is suitable for simulations.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda activate pdbfixer
pdbfixer protein.pdb --output=protein_fixed.pdb
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-1-extract-and-clean-the-protein&#34;&gt;Step 1: Extract and clean the protein&lt;/h2&gt;
&lt;p&gt;Next, we separate the ligand (UNK or cofactors like FAD) and clean the protein file.&lt;br&gt;
This avoids force field issues caused by unknown residues.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grep UNK protein.pdb &amp;gt; unk.pdb
grep -v &amp;quot;UNK&amp;quot; protein.pdb &amp;gt; clean.pdb

grep -v -e &amp;quot;UNK&amp;quot; -e &amp;quot;FAD&amp;quot; protein_fixed.pdb &amp;gt; clean.pdb

conda activate pdbfixer
pdbfixer clean.pdb --output=clean.pdb
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-2-generate-protein-topology&#34;&gt;Step 2: Generate protein topology&lt;/h2&gt;
&lt;p&gt;We use &lt;code&gt;pdb2gmx&lt;/code&gt; to generate the topology of the clean protein with CHARMM36.&lt;br&gt;
Here we also choose protonation states interactively.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx pdb2gmx -f clean.pdb -o processed.gro -ter -ignh &amp;lt;&amp;lt; EOF
1
1
0
0
0
0
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-3-convert-ligand-to-mol2-format&#34;&gt;Step 3: Convert ligand to MOL2 format&lt;/h2&gt;
&lt;p&gt;The ligand is converted to &lt;code&gt;.mol2&lt;/code&gt; format with hydrogens added and atom typing corrected.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;obabel unk.pdb -O unk.mol2 --addh --gen3d
sed -i &#39;2s/.*/UNK/; s/UNK1/UNK/g&#39; unk.mol2
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-4-sort-ligand-bonds&#34;&gt;Step 4: Sort ligand bonds&lt;/h2&gt;
&lt;p&gt;We ensure the bond ordering in the MOL2 file is consistent using a Perl script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;perl sort_mol2_bonds.pl unk.mol2 unk_fix.mol2
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-5-parameterize-the-ligand-with-cgenff&#34;&gt;Step 5: Parameterize the ligand with CGenFF&lt;/h2&gt;
&lt;p&gt;The ligand is parameterized using &lt;strong&gt;CGenFF&lt;/strong&gt;, and converted to a GROMACS-compatible format.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~/mdrun/silcsbio.2024.1/cgenff/cgenff unk_fix.mol2 -f unk.str
chmod +x cgenff_charmm2gmx.py

conda activate cgenff
python cgenff_charmm2gmx.py UNK unk_fix.mol2 unk.str charmm36-jul2022.ff

rm cgenff_charmm2gmx.py
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-6-convert-ligandcofactor-to-gromacs-format&#34;&gt;Step 6: Convert ligand/cofactor to GROMACS format&lt;/h2&gt;
&lt;p&gt;We now generate &lt;code&gt;.gro&lt;/code&gt; files for both the ligand and cofactor (if present).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx editconf -f unk_ini.pdb -o unk.gro
gmx editconf -f fad_ini.pdb -o fad.gro
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-7-merge-protein-and-ligands&#34;&gt;Step 7: Merge protein and ligands&lt;/h2&gt;
&lt;p&gt;We merge the protein, ligand, and optional cofactors into one structure file.&lt;br&gt;
Atom counts are updated to reflect the combined system.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp processed.gro complex.gro &amp;amp;&amp;amp; sed -i &#39;$d&#39; complex.gro &amp;amp;&amp;amp; tail -n +3 unk.gro &amp;gt;&amp;gt; complex.gro &amp;amp;&amp;amp; echo &amp;quot;   &amp;quot; &amp;gt;&amp;gt; complex.gro

num1=$(sed -n &#39;2p&#39; complex.gro)
num2=$(sed -n &#39;2p&#39; unk.gro)
sum=$((num1 + num2))
sed -i &amp;quot;2s/.*/ $sum/&amp;quot; complex.gro
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For protein + FAD + UNK:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp processed.gro complex.gro &amp;amp;&amp;amp; \
sed -i &#39;$d&#39; complex.gro &amp;amp;&amp;amp; \
tail -n +3 fad.gro &amp;gt;&amp;gt; complex.gro &amp;amp;&amp;amp; \
tail -n +3 unk.gro &amp;gt;&amp;gt; complex.gro &amp;amp;&amp;amp; \
echo &amp;quot;   &amp;quot; &amp;gt;&amp;gt; complex.gro

num1=$(sed -n &#39;2p&#39; processed.gro)
num2=$(sed -n &#39;2p&#39; fad.gro)
num3=$(sed -n &#39;2p&#39; unk.gro)
sum=$((num1 + num2 + num3))
sed -i &amp;quot;2s/.*/ $sum/&amp;quot; complex.gro
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-8-update-topology-file&#34;&gt;Step 8: Update topology file&lt;/h2&gt;
&lt;p&gt;We edit &lt;code&gt;topol.top&lt;/code&gt; to include the ligand topologies and parameters.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;/; Include Position restraint file/{:a;N;/#endif/!ba;s/\n#endif\n/\n#endif/;s/#endif/#endif\n\n; Include ligand topology\n#include &amp;quot;unk.itp&amp;quot;/}&#39; topol.top

sed -i &#39;/; Include forcefield parameters/{:a;N;/#include &amp;quot;.\/charmm36-jul2022.ff\/forcefield.itp&amp;quot;/!ba;s/#include &amp;quot;.\/charmm36-jul2022.ff\/forcefield.itp&amp;quot;/&amp;amp;\n\n; Include ligand parameters\n#include &amp;quot;unk.prm&amp;quot;/}&#39; topol.top

sed -i &#39;/\[ molecules \]/,/Protein_chain_A/ {/Protein_chain_A/ a\\nUNK                 1\n}&#39; topol.top
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For FAD + UNK:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;/; Include Position restraint file/{:a;N;/#endif/!ba;s/#endif/#endif\n\n; Include ligand topologies\n#include &amp;quot;fad.itp&amp;quot;\n#include &amp;quot;unk.itp&amp;quot;/}&#39; topol.top

sed -i &#39;/; Include forcefield parameters/{:a;N;/#include &amp;quot;.\/charmm36-jul2022.ff\/forcefield.itp&amp;quot;/!ba;s|#include &amp;quot;.\/charmm36-jul2022.ff\/forcefield.itp&amp;quot;|&amp;amp;\n\n; Include ligand parameters\n#include &amp;quot;fad.prm&amp;quot;\n#include &amp;quot;unk.prm&amp;quot;|}&#39; topol.top

sed -i &#39;/\[ molecules \]/,/Protein_chain_A/ {/Protein_chain_A/ a\\nFAD                 1\\nUNK                 1\n}&#39; topol.top
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-9-define-box-and-solvate&#34;&gt;Step 9: Define box and solvate&lt;/h2&gt;
&lt;p&gt;We place the system in a cubic box with a 1.4 nm buffer and solvate with TIP3P water.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx editconf -f complex.gro -o newbox.gro -bt cubic -c -d 1.4
gmx solvate -cp newbox.gro -cs spc216.gro -p topol.top -o solv.gro
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-10-add-ions&#34;&gt;Step 10: Add ions&lt;/h2&gt;
&lt;p&gt;We neutralize the system and add physiological salt concentration (0.15 M NaCl).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; ions.mdp
integrator     = steep
emtol          = 1000.0
nsteps         = 50000
cutoff-scheme  = Verlet
coulombtype    = PME
rcoulomb       = 1.0
rvdw           = 1.0
constraints    = none
EOF

gmx grompp -f ions.mdp -c solv.gro -p topol.top -o ions.tpr -maxwarn 3
gmx genion -s ions.tpr -o solv_ions.gro -p topol.top -pname NA -nname CL -neutral -conc 0.15 &amp;lt;&amp;lt;EOF
15
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-11-energy-minimization&#34;&gt;Step 11: Energy minimization&lt;/h2&gt;
&lt;p&gt;We relax steric clashes by running a steepest descent minimization.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx grompp -f em.mdp -c solv_ions.gro -p topol.top -o em.tpr
gmx mdrun -v -deffnm em
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-12-generate-ligand-restraints&#34;&gt;Step 12: Generate ligand restraints&lt;/h2&gt;
&lt;p&gt;Ligand restraints are generated for equilibration to avoid large displacements.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx make_ndx -f unk.gro -o index_unk.ndx &amp;lt;&amp;lt; EOF
0 &amp;amp; ! a H*
q
EOF

gmx genrestr -f unk.gro -n index_unk.ndx -o posre_unk.itp -fc 1000 1000 1000 &amp;lt;&amp;lt;EOF
3
EOF

sed -i &#39;/; Include water topology/{x;s/.*/\n; Ligand position restraints\n#ifdef POSRES\n#include &amp;quot;posre_unk.itp&amp;quot;\n#endif\n/;G}&#39; topol.top
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-13-create-index-for-complex&#34;&gt;Step 13: Create index for complex&lt;/h2&gt;
&lt;p&gt;We define a custom index file including protein and ligand groups.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx make_ndx -f solv_ions.gro -o index.ndx &amp;lt;&amp;lt; EOF
1 | 13
q
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-14-nvt-equilibration&#34;&gt;Step 14: NVT equilibration&lt;/h2&gt;
&lt;p&gt;We equilibrate temperature at 300 K with position restraints.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx grompp -f nvt.mdp -c solv_ions.gro -r solv_ions.gro -p topol.top -n index.ndx -o nvt.tpr
gmx mdrun -deffnm nvt
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-15-npt-equilibration&#34;&gt;Step 15: NPT equilibration&lt;/h2&gt;
&lt;p&gt;We equilibrate pressure at 1 bar using the Parrinello-Rahman barostat.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx grompp -f npt.mdp -c nvt.gro -t nvt.cpt -r nvt.gro -p topol.top -n index.ndx -o npt.tpr
gmx mdrun -deffnm npt
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;step-16-production-md&#34;&gt;Step 16: Production MD&lt;/h2&gt;
&lt;p&gt;Finally, we run a 100 ns production simulation in the NPT ensemble.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gmx grompp -f md.mdp -c npt.gro -t npt.cpt -p topol.top -n index.ndx -o md_0_100.tpr
gmx mdrun -deffnm md_0_100
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;notes&#34;&gt;Notes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Always &lt;strong&gt;fix PBC&lt;/strong&gt; before analysis.&lt;/li&gt;
&lt;li&gt;Discard the first &lt;strong&gt;5–10 ns&lt;/strong&gt; of equilibration before data collection.&lt;/li&gt;
&lt;li&gt;Stable &lt;strong&gt;RMSD, Rg, SASA&lt;/strong&gt; values indicate good simulation behavior.&lt;/li&gt;
&lt;li&gt;Use &lt;strong&gt;PCA/FEL&lt;/strong&gt; to explore large-scale motions and free energy landscapes.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Molecular Simulation in Drug Discovery: A Strategic Guide to Core Methods</title>
      <link>https://yboulaamane.github.io/blog/molecular-simulation-in-drug-discovery-a-strategic-guide-to-core-methods/</link>
      <pubDate>Wed, 08 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/molecular-simulation-in-drug-discovery-a-strategic-guide-to-core-methods/</guid>
      <description>&lt;p&gt;Molecular simulation has emerged as a cornerstone in modern drug discovery, enabling researchers to predict and understand molecular behavior across scales. From the atomic resolution of quantum mechanical models to the mesoscale insights of coarse-grained systems, the range of available techniques is vast. Each method offers unique capabilities, making them invaluable tools when applied judiciously to specific drug discovery problems.
This post offers a coherent overview of the most widely used molecular simulation methods in drug development. The aim is not only to clarify what each method does, but to provide insight into how and when they are best used — especially for early-career scientists and interdisciplinary teams navigating increasingly complex pipelines.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/yboulaamane/yboulaamane.github.io/refs/heads/master/images/posts/md.jpg&#34; alt=&#34;Recap of Molecular Simulation Methods&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;-quantum-mechanics-precision-at-the-electronic-level&#34;&gt;🔬 Quantum Mechanics: Precision at the Electronic Level&lt;/h2&gt;
&lt;p&gt;Quantum mechanical (QM) methods are the most fundamental level of simulation, solving the Schrödinger equation to describe the behavior of electrons within molecules. In drug discovery, their primary utility lies in modeling chemical reactivity, enzymatic mechanisms, and molecular properties that depend on electronic structure. QM calculations are routinely used to characterize transition states, derive force field parameters, and evaluate the electronic distribution in drug–target complexes, particularly when metal ions or covalent interactions are involved.&lt;/p&gt;
&lt;p&gt;However, QM simulations are computationally intensive, restricting their application to relatively small systems or localized regions of interest, such as enzyme active sites. To address this, hybrid approaches like QM/MM (quantum mechanics/molecular mechanics) allow the detailed modeling of a reactive center within a broader biological system, balancing accuracy and feasibility.&lt;/p&gt;
&lt;h2 id=&#34;-molecular-dynamics-tracking-molecular-motion-over-time&#34;&gt;🧪 Molecular Dynamics: Tracking Molecular Motion Over Time&lt;/h2&gt;
&lt;p&gt;Molecular dynamics (MD) simulations occupy the center of the simulation spectrum, offering atomistic insights into molecular behavior over time by solving Newton’s equations of motion. MD is widely used to investigate protein dynamics, ligand binding, solvent effects, and structural stability. Its primary strength lies in providing time-resolved information about molecular conformations, which is essential for validating docking poses, studying induced fit mechanisms, and calculating thermodynamic properties such as binding free energies.&lt;/p&gt;
&lt;p&gt;The major challenge in MD is sampling — simulations can become trapped in local minima, failing to explore relevant conformational states. To overcome this, enhanced sampling techniques such as metadynamics, accelerated MD, and replica exchange MD have been developed, allowing for more efficient exploration of energy landscapes. When combined with robust force fields and explicit solvent models, MD becomes a powerful tool for validating hypotheses, predicting structure–function relationships, and guiding lead optimization.&lt;/p&gt;
&lt;h2 id=&#34;-coarse-grained-md-scaling-up-without-losing-insight&#34;&gt;⚙️ Coarse-Grained MD: Scaling Up Without Losing Insight&lt;/h2&gt;
&lt;p&gt;While all-atom MD provides detailed information, it becomes prohibitively expensive for large or complex systems. Coarse-grained molecular dynamics (CGMD) addresses this by simplifying the representation of molecules — grouping atoms into larger “beads” — thereby reducing computational overhead and smoothing the energy landscape. This abstraction allows the simulation of mesoscale phenomena such as membrane remodeling, vesicle formation, and nanoparticle self-assembly.&lt;/p&gt;
&lt;p&gt;In drug discovery, CGMD is especially useful for studying processes that occur over long timescales or involve large supramolecular assemblies, such as the behavior of drug delivery systems and the formation of lipid rafts. Although it lacks atomic detail, CGMD provides qualitative and semi-quantitative insights into the dynamics and organization of biological membranes and nanocarriers, helping to optimize formulations and delivery strategies.&lt;/p&gt;
&lt;h2 id=&#34;-monte-carlo-methods-efficient-sampling-and-free-energy-estimation&#34;&gt;🎲 Monte Carlo Methods: Efficient Sampling and Free Energy Estimation&lt;/h2&gt;
&lt;p&gt;Monte Carlo (MC) simulations take a different approach by using random sampling to explore a system’s phase space. Rather than evolving a system over time, MC simulations generate configurations based on probability, making them efficient for systems with rugged energy landscapes. In drug discovery, MC is widely used for conformational sampling, protein side-chain modeling, and free energy calculations, particularly in docking workflows.&lt;/p&gt;
&lt;p&gt;Grand canonical Monte Carlo (GCMC) techniques extend this framework by allowing the insertion and deletion of molecules — such as water — in a simulation box, which is useful for identifying binding hotspots and hydration sites in protein structures. This capability is particularly valuable during the lead optimization phase, where understanding solvation effects can inform the design of more potent ligands.&lt;/p&gt;
&lt;h2 id=&#34;-brownian-dynamics-capturing-long-timescale-diffusion&#34;&gt;🌊 Brownian Dynamics: Capturing Long-Timescale Diffusion&lt;/h2&gt;
&lt;p&gt;Brownian dynamics (BD) simplifies the simulation of molecular motion by neglecting inertia and focusing on diffusion-driven behavior under thermal noise. This allows for the simulation of much longer timescales than MD, albeit at the cost of structural and energetic detail. BD is particularly useful for modeling molecular recognition events, such as the initial encounter between a ligand and a target protein.&lt;/p&gt;
&lt;p&gt;In the context of drug discovery, BD is often used to estimate association rate constants (kon) or to model how molecules diffuse through crowded environments, such as cellular compartments. By focusing on diffusive behavior, BD complements atomistic MD, enabling a multiscale view of binding events.&lt;/p&gt;
&lt;h2 id=&#34;-langevin-dynamics-bridging-time-and-temperature-control&#34;&gt;💧 Langevin Dynamics: Bridging Time and Temperature Control&lt;/h2&gt;
&lt;p&gt;Langevin dynamics (LD) enhances traditional MD by introducing friction and random forces to mimic solvent effects and maintain temperature control. This stochastic approach is especially useful for simulations in implicit solvent models, or when a simple thermostat is needed to stabilize the system.&lt;/p&gt;
&lt;p&gt;LD is often used in systems where damping effects — such as those found in intracellular environments — play a role in modulating dynamics. It provides a smoother simulation trajectory and can accelerate equilibration, making it a practical tool for early-stage explorations of ligand binding or conformational changes.&lt;/p&gt;
&lt;h2 id=&#34;-dissipative-particle-dynamics-modeling-soft-matter-systems&#34;&gt;🌀 Dissipative Particle Dynamics: Modeling Soft Matter Systems&lt;/h2&gt;
&lt;p&gt;Dissipative particle dynamics (DPD) is a mesoscale simulation technique tailored for soft matter systems, such as polymers, lipids, and surfactants. Like CGMD, DPD uses coarse-grained particles, but adds hydrodynamic interactions via dissipative and random forces that preserve momentum. This makes it especially suitable for modeling flow, self-assembly, and large-scale organization in complex fluids.&lt;/p&gt;
&lt;p&gt;In drug discovery, DPD is increasingly applied to the study of drug delivery systems — from nanoparticle encapsulation to vesicle formation and drug release. It allows researchers to simulate phenomena that are difficult to capture with more detailed methods, making it an essential tool in pharmaceutical formulation and nanomedicine research.&lt;/p&gt;
&lt;h2 id=&#34;-hybrid-and-multiscale-approaches-the-future-of-simulation&#34;&gt;🔁 Hybrid and Multiscale Approaches: The Future of Simulation&lt;/h2&gt;
&lt;p&gt;As biological questions grow more complex, so does the need for simulation approaches that integrate different levels of theory. Hybrid methods — such as QM/MM — combine the strengths of high-resolution QM with the scalability of classical MD. Multiscale pipelines also pair BD with MD, or CGMD with atomistic refinement, to explore phenomena across spatial and temporal scales.&lt;/p&gt;
&lt;p&gt;These approaches are not only more realistic but increasingly necessary. Whether it’s using BD to guide a ligand to its target, MD to refine the binding pose, and QM to compute the final interaction energy — multiscale strategies provide a comprehensive view of drug–target interactions that would be inaccessible with a single method.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Each molecular simulation method offers a distinct window into the behavior of biomolecules and drug candidates. By understanding the strengths and limitations of each technique — from the quantum accuracy of QM to the system-wide insights of DPD — researchers can better design studies, interpret results, and make informed decisions in the drug discovery process.&lt;/p&gt;
&lt;p&gt;Ultimately, the power of molecular simulation lies in using the right tool for the right question — and, increasingly, in combining those tools into coherent, multiscale workflows. As computational power and algorithms continue to improve, these simulations will only become more predictive, more accessible, and more central to the future of drug discovery.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computational Drug Repurposing with Multiscale Interactomes</title>
      <link>https://yboulaamane.github.io/blog/computational-drug-repurposing-with-multiscale-interactomes/</link>
      <pubDate>Tue, 23 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/computational-drug-repurposing-with-multiscale-interactomes/</guid>
      <description>&lt;p&gt;Drug repurposing offers a rapid, cost-effective route to new therapies by identifying novel uses for existing compounds. When paired with &lt;strong&gt;multiscale interactome analysis&lt;/strong&gt;, it becomes possible to explore the complex molecular relationships between drugs, targets, pathways, and diseases at a systems level.&lt;br&gt;
This workflow outlines how to construct, analyze, and exploit a heterogeneous biomedical network to identify repurposing candidates, combining graph-based learning with experimental prioritization.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-building-the-interactome&#34;&gt;&lt;strong&gt;1. Building the Interactome&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The foundation of the approach is a &lt;strong&gt;heterogeneous graph&lt;/strong&gt; that integrates multiple layers of biological knowledge. Nodes can represent drugs, proteins, pathways, or diseases, while edges encode interactions—drug–target binding, protein–protein interactions, pathway memberships, and disease associations.&lt;/p&gt;
&lt;p&gt;Sources like &lt;strong&gt;DrugBank&lt;/strong&gt; provide curated drug–protein relationships, while protein–protein interaction maps can be drawn from high-confidence databases. For disease biology, integrate experimentally validated or literature-reported links, such as host–pathogen PPIs for infectious diseases or α-synuclein interactors in Parkinson’s disease.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-anchoring-the-disease-context&#34;&gt;&lt;strong&gt;2. Anchoring the Disease Context&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Once the network is assembled, the specific disease of interest is added as a node and connected to known associated proteins or pathways. This grounding ensures that the graph captures both molecular interactions and the functional context of the disease.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;3-learning-from-network-structure&#34;&gt;&lt;strong&gt;3. Learning from Network Structure&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Graph embedding techniques transform the raw network into a form suitable for machine learning. A &lt;strong&gt;Node2Vec&lt;/strong&gt; pre-processing step captures both local neighborhoods and broader network context. These embeddings are then refined through a &lt;strong&gt;Graph Convolutional Network (GCN)&lt;/strong&gt;, trained with a diffusion-based loss function that clusters nodes according to their network proximity to the disease node.&lt;/p&gt;
&lt;p&gt;The result is a set of optimized vector representations for every entity in the network—drugs, proteins, and pathways—enabling quantitative similarity searches.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;4-prioritizing-candidates&#34;&gt;&lt;strong&gt;4. Prioritizing Candidates&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;With embeddings in hand, candidate ranking is straightforward: compute cosine similarity between the disease node and other nodes. This yields:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Drug proximity scores&lt;/strong&gt; – for direct repurposing candidates.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protein proximity scores&lt;/strong&gt; – highlighting potential new therapeutic targets.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;5-multiple-selection-strategies&#34;&gt;&lt;strong&gt;5. Multiple Selection Strategies&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Three complementary selection approaches can be applied:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Target-centric&lt;/strong&gt;: Choose drugs directly most similar to the disease node.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protein-centric&lt;/strong&gt;: Identify top-ranked proteins, then retrieve predicted binders from platforms like &lt;strong&gt;PolypharmDB&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Polypharmacology-focused&lt;/strong&gt;: Prioritize drugs predicted to act on multiple high-value targets simultaneously.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;6-rational-filtering&#34;&gt;&lt;strong&gt;6. Rational Filtering&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;To refine the shortlist, apply pragmatic filters: retain only FDA-approved small molecules with drug-like properties, ensure scaffold diversity, and avoid redundancy in mechanism of action or target profile.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;7-from-prediction-to-validation&#34;&gt;&lt;strong&gt;7. From Prediction to Validation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Predicted candidates move to experimental testing, starting with &lt;strong&gt;cell-based assays&lt;/strong&gt; tailored to the disease model—such as infection inhibition assays, pseudovirus entry tests, or phenotypic screens. Hits are further confirmed with orthogonal validation techniques, from qRT-PCR to targeted inhibition assays.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;By uniting &lt;strong&gt;network pharmacology&lt;/strong&gt;, &lt;strong&gt;graph machine learning&lt;/strong&gt;, and &lt;strong&gt;experimental feedback&lt;/strong&gt;, this interactome-driven strategy offers a scalable framework for uncovering repurposing opportunities across a broad range of diseases. Its strength lies in connecting molecular context with computational inference—transforming existing drugs into tomorrow’s targeted therapies.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Validate AlphaFold Structures</title>
      <link>https://yboulaamane.github.io/blog/how-to-validate-alphafold-structures/</link>
      <pubDate>Thu, 28 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/how-to-validate-alphafold-structures/</guid>
      <description>&lt;p&gt;AlphaFold has revolutionized protein structure prediction by achieving unprecedented accuracy in many cases​ (1). However, even high-quality predicted models should be rigorously validated before use in research.
Just as experimental structures undergo validation (geometry checks, reliability scores, etc.), &lt;strong&gt;AlphaFold-predicted structures&lt;/strong&gt; require careful assessment of confidence, stereochemistry, and functional plausibility. In this comprehensive guide, we outline practical strategies to validate an AlphaFold model, from interpreting AlphaFold’s own confidence metrics to using external validation tools, comparing against known structures, and even testing the model’s behavior in silico. The goal is to ensure the predicted structure is trustworthy for drawing biological conclusions.&lt;/p&gt;
&lt;h2 id=&#34;alphafold-confidence-metrics-plddt-and-pae&#34;&gt;AlphaFold Confidence Metrics: pLDDT and PAE&lt;/h2&gt;
&lt;p&gt;AlphaFold provides intrinsic confidence measures that are the first step in validation. &lt;strong&gt;pLDDT (predicted Local Distance Difference Test)&lt;/strong&gt; is a per-residue confidence score ranging from 0 to 100. Higher pLDDT means the model is more confident that the local structure around that residue is accurate​ (2). This metric is based on the lDDT-Cα score, which assesses local structural accuracy without requiring a global superposition​ (3). In practice, AlphaFold classifies residues into confidence bands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;pLDDT ≥ 90&lt;/strong&gt;: Very high confidence (high accuracy for backbone and side chains)​.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;70 ≤ pLDDT &amp;lt; 90&lt;/strong&gt;: Confident – backbone likely correct, though side chains may have some error​.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;50 ≤ pLDDT &amp;lt; 70&lt;/strong&gt;: Low confidence – the region is less reliable, possibly mis-modeled.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pLDDT &amp;lt; 50&lt;/strong&gt;: Very low confidence – often indicates disordered or flexible regions​, which AlphaFold expects might not adopt a single stable structure in reality.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AlphaFold typically &lt;strong&gt;encodes pLDDT in the B-factor field&lt;/strong&gt; of the output PDB/mmCIF file​ (4). This means visualization programs can color the structure by B-factor to see confidence per residue. For example, in PyMOL you can load the model and run a command to color by B-factor (pLDDT):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# In PyMOL, after loading the AlphaFold model:
spectrum b, red_white_blue, minimum=0, maximum=100
# This colors residues from red (low pLDDT) to blue (high pLDDT).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AlphaFold’s second key metric is the &lt;strong&gt;PAE (Predicted Aligned Error)&lt;/strong&gt;. PAE is a measure of the model’s confidence in the relative positions of two residues​ (5). More formally, &lt;em&gt;PAE(x, y)&lt;/em&gt; is the expected error (in Å) at residue &lt;em&gt;x&lt;/em&gt;’s position &lt;strong&gt;if&lt;/strong&gt; the predicted structure were aligned to the (unknown) true structure on residue _y_​ (6). In simpler terms, &lt;strong&gt;PAE tells us how well the model thinks region &lt;em&gt;x&lt;/em&gt; and region &lt;em&gt;y&lt;/em&gt; are positioned relative to each other&lt;/strong&gt;. A low PAE between two residues (or domains) implies the model is confident about their relative arrangement, whereas a high PAE means the relative placement is uncertain​ (7). For example, if two domains have consistently high PAE with each other, the model is essentially saying &lt;em&gt;“these domains might move relative to each other, so don’t trust the exact orientation.”&lt;/em&gt; By contrast, low PAE between two domains suggests a well-defined domain packing​ (8).&lt;/p&gt;
&lt;p&gt;PAE is often visualized as a heatmap (matrix) where each axis is residue index. AlphaFold’s structure database provides an interactive PAE plot alongside each model​ (9,10). In a PAE heatmap, the diagonal is always dark (zero error when a residue is aligned on itself) and can be ignored​ (10). Off-diagonal blocks indicate inter-residue or inter-domain confidence: &lt;strong&gt;dark green/blue regions = low error (high confidence)&lt;/strong&gt;, and **light colors = high error (low confidence)**​. For instance, a multi-domain protein often shows clear dark blocks along the diagonal (each domain internally high confidence) separated by lighter regions (uncertain relative domain orientation). &lt;strong&gt;Interpreting PAE&lt;/strong&gt; in validation is crucial: even if each domain has high pLDDT, a high PAE between domains means you should not assume the domain arrangement is correct​ (10). In such cases, additional validation (or experimental data) is needed to confirm domain orientations.&lt;/p&gt;
&lt;p&gt;In summary, &lt;strong&gt;check pLDDT and PAE first&lt;/strong&gt;. These tell you which parts of the model are likely reliable and whether the overall fold (especially multi-domain architecture) is predicted with confidence. Regions with low pLDDT or very high PAE should be treated with caution – they might be disordered in reality or simply modeled inaccurately. Often, those regions may require further analysis or may be trimmed out if you only need the stable core of the structure.&lt;/p&gt;
&lt;h2 id=&#34;visual-inspection-of-the-model&#34;&gt;Visual Inspection of the Model&lt;/h2&gt;
&lt;p&gt;After reviewing AlphaFold’s confidence metrics, the next validation step is a &lt;strong&gt;careful visual inspection&lt;/strong&gt; of the model. This is a straightforward but powerful way to catch obvious issues. Tools such as &lt;strong&gt;PyMOL&lt;/strong&gt;, &lt;strong&gt;UCSF ChimeraX&lt;/strong&gt;, and &lt;strong&gt;Mol*&lt;/strong&gt; (MolStar) are invaluable for this task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PyMOL&lt;/strong&gt; – A widely-used molecular graphics tool. Load the AlphaFold PDB, and visualize secondary structure (cartoon view) to see if helices and strands look well-formed. Color the model by pLDDT (as described above) to highlight low-confidence segments. Pay attention to any steric clashes or oddly twisted geometries. For example, check if any side chains deeply penetrate other parts of the protein (which might indicate a clash or error). PyMOL’s distance measurement can help verify if supposed disulfide bonds or salt bridges are geometrically plausible. If you have a known motif (e.g., a catalytic triad), inspect whether those residues align in the expected geometry.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UCSF ChimeraX&lt;/strong&gt; – A modern visualization tool that can directly fetch AlphaFold models from the AlphaFold DB by UniProt ID, and it has built-in presets for AlphaFold confidence coloring. In ChimeraX, one can simply use the command color bfactor palette alphafold to apply the standard pLDDT color scheme (blue = high confidence, orange/red = low)​. Use ChimeraX’s structure analysis features to examine hydrogen bonds, contacts, and clashes. Chimera(X) also allows viewing the PAE map if you have it, or you can segment the model by domains to see how they interact. If the model has flexible termini (often glowing red/orange from low pLDDT), you might visualize those separately – they could be flopping around and not relevant to the stable core.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mol&lt;/strong&gt;* – This is the web-based 3D viewer used by the AlphaFold Protein Structure Database​ (11). If you obtained your model from AlphaFold DB, you can use the online Mol* viewer to instantly see the structure colored by confidence and the PAE plot side-by-side. Mol* is great for a quick look without installing software. Through Mol*, you can rotate the model, identify secondary structure elements, and even select a region on the PAE plot to highlight which parts of the 3D structure are uncertain​ (12). While not as feature-rich as desktop tools, it’s convenient for an initial overview.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;During visual inspection, &lt;strong&gt;look for red flags&lt;/strong&gt; such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unphysical bond lengths or angles&lt;/strong&gt;: AlphaFold generally produces chemically sensible structures, but extremely distorted geometries (e.g., a peptide bond angle that looks abnormal) could appear in low-confidence regions. These are rare, but if present, they’ll likely be flagged by subsequent validation tools as well.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clashes&lt;/strong&gt;: Overlapping atoms or very tightly packed regions. Our eyes might miss slight clashes, so after visual review you’ll use tools like MolProbity to quantify this. But obvious clashes (like two side chains on top of each other) can sometimes be spotted visually.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chain breaks or gaps&lt;/strong&gt;: Check if the protein backbone is continuous. If AlphaFold was unsure in a region, it might produce an unphysical loop. Usually AlphaFold does not literally break the chain (except maybe at extreme low confidence segments, it still gives a continuous but perhaps highly extended or tangled loop). If you do see a gap (missing residues), it could be because the input sequence had a region AlphaFold couldn’t model confidently or was omitted – though in normal operation AlphaFold predicts all residues provided.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secondary structure mismatches&lt;/strong&gt;: Does the model’s secondary structure make sense given the sequence? If you have prior knowledge (say from sequence analysis, you expect three transmembrane helices or a beta-sheet in a certain region), see if the model matches that. If AlphaFold predicts a region to be helical (and with high confidence), it likely is. But if you see something like a beta-strand contorted oddly, or a helix with a kink, note those for further scrutiny.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Active site or binding site conformation&lt;/strong&gt;: If the protein’s function is known and certain residues are critical (e.g., enzyme active site), inspect that region. Are the catalytic residues oriented in a plausible way? Is there a cavity where a substrate could bind? Sometimes AlphaFold might predict a side chain orientation that blocks a known binding cleft (especially if no ligand was present during prediction). Visualizing this early can hint if the model is consistent with function or if something might be off.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Visual inspection is mostly qualitative, but it sets the stage for targeted questions. For instance, if you notice the model has an unexpected large cavity or an unusual domain orientation, you might plan specific validations (like docking a ligand into that cavity, or checking if domain orientation is supported by known data). At this stage, you should also decide if any segments of the model might be so low confidence that they should be treated separately (for example, you might exclude a floppy tail from further analysis if it’s not essential to the protein’s folded core).&lt;/p&gt;
&lt;h2 id=&#34;using-structural-validation-tools&#34;&gt;Using Structural Validation Tools&lt;/h2&gt;
&lt;p&gt;Automated structure-validation tools provide quantitative checks on your model’s stereochemistry and overall quality. Many of these tools were originally developed for validating experimentally determined structures, but they are equally applicable to predicted models. Here are some key validation tools and what they offer:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MolProbity&lt;/strong&gt; – A comprehensive &lt;strong&gt;all-atom structure validation&lt;/strong&gt; server (13). 
 checks for steric clashes by adding hydrogens to the structure and finding all-atom overlaps. It also evaluates bond angles and dihedrals, highlighting &lt;strong&gt;Ramachandran outliers&lt;/strong&gt; (phi/psi angles that fall in disallowed regions of the Ramachandran plot) and &lt;strong&gt;rotamer outliers&lt;/strong&gt; (unusual side chain conformations). MolProbity provides an overall score (the “MolProbity score”) and specific metrics like &lt;strong&gt;clashscore&lt;/strong&gt; (number of serious clashes per 1000 atoms), percentage of Ramachandran favored/allowed/outlier residues, and more ​(14,15). A good AlphaFold model should have low clashscore and few (if any) Ramachandran outliers. However, it’s not uncommon for some &lt;strong&gt;low-pLDDT loops&lt;/strong&gt; in AlphaFold models to show outliers or clashes, since the model wasn’t physics-refined. MolProbity can guide you to those problematic spots; you can then consider refining them (e.g., via energy minimization or rebuilding). &lt;strong&gt;Tip:&lt;/strong&gt; If MolProbity reports many clashes or poor geometry in a high-pLDDT region, that’s a red flag – the model might be locally strained, and further investigation is needed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PROCHECK&lt;/strong&gt; – A classic tool (from 1993) that checks the &lt;strong&gt;stereochemical quality&lt;/strong&gt; of a protein structure​ (16). 
 generates a number of outputs, the most famous being the Ramachandran plot. It will tell you what fraction of residues lie in favored, allowed, and disallowed regions of Ramachandran space. It also checks other parameters: peptide bond planarity, bond length deviations, Cβ deviations, and backbone torsion angle quality. In essence, PROCHECK ensures your model’s geometry is within typical bounds seen in crystallographic structures. For an AlphaFold model, you’d like to see the vast majority of residues in the favored regions of the Ramachandran plot (ideally &amp;gt;90% favored, &amp;lt;1% outliers, similar to high-resolution crystal structures). AlphaFold models generally fare well here, especially in well-defined regions, but if you have an outlier, PROCHECK will pinpoint it. You can run PROCHECK via the command-line (it’s part of the CCP4 suite) or conveniently through web servers like PDBsum (which can generate PROCHECK analysis for any uploaded structure)​.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WHAT_CHECK&lt;/strong&gt; – Part of the &lt;strong&gt;WHAT IF&lt;/strong&gt; software suite, 
 is an extensive consistency check for protein structures. It examines a wide range of criteria: geometry, van der Waals contacts, environment of residues, and more. For example, it will check if buried polar groups have hydrogen-bonding partners, if side chain torsions are consistent with electron density (for experimental structures), etc. With a predicted model, some checks (like comparison to electron density) don’t apply, but WHAT_CHECK’s geometrical and empirical rules can still flag issues. It’s quite thorough – sometimes producing a long report. If you have access to the WHAT IF web interface or servers, running WHAT_CHECK can complement PROCHECK/MolProbity by catching subtle issues. However, if you’re already using MolProbity and PROCHECK, you may get sufficient info; use WHAT_CHECK if you want an extra layer of scrutiny.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Verify3D&lt;/strong&gt; – A &lt;strong&gt;3D-1D profile&lt;/strong&gt; method that checks &lt;strong&gt;residue environment compatibility&lt;/strong&gt;​ (17). Essentially, 
 evaluates each residue in the model to see if its environment (surface vs buried, secondary structure context, etc.) is consistent with what one would expect for that amino acid. It returns a score for each residue and an overall percentage of residues that pass a threshold. Typically, you want a Verify3D result where &amp;gt;80% of residues have a score above the cutoff (0.2 in the original scoring scheme)​ (18). If Verify3D flags certain residues, it means those amino acids are in an environment that is unusual (e.g., a polar residue buried without contacts, or a hydrophobic residue exposed to solvent) – potentially indicating a modeling error or an unusual but real feature. When validating an AlphaFold model, a &lt;strong&gt;low Verify3D percentage (significantly below 80%) is a warning&lt;/strong&gt;. It could be due to a genuine peculiarity of the protein, but often it suggests some regions of the model are not structurally sound. Verify3D is available via the 
 server (which bundles several validation tools).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ERRAT&lt;/strong&gt; – A program that analyzes &lt;strong&gt;non-bonded atom-atom interactions&lt;/strong&gt; in the model and identifies regions that deviate from expected patterns​ (19). 
 essentially plots a quality score across the protein and gives an overall quality factor (as a percentage). High-quality structures tend to have an ERRAT overall quality score in the high 80s or 90s (out of 100), whereas a significantly lower score might indicate problems. For example, an ERRAT score of ~79% (as seen in some homology models) is marginal, and one would try to improve the model (20). ERRAT is also available via the UCLA SAVES server. If ERRAT flags a specific region (say residues 50–60) as problematic, that region likely has odd interatomic distances (perhaps a mis-packed helix or something). Cross-check such regions with what pLDDT said – often they coincide with low pLDDT stretches.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SwissModel Structure Assessment (QMEAN)&lt;/strong&gt; – The 
 server provides a &lt;strong&gt;model quality assessment&lt;/strong&gt; tool that includes the QMEAN scoring function. &lt;strong&gt;QMEAN&lt;/strong&gt; (Qualitative Model Energy ANalysis) is a composite score evaluating various geometrical aspects (e.g., torsion angles, solvation, secondary structure packing) to estimate how “protein-like” a model is​ (21). When you submit a model to SwissModel’s Assessment, you receive a QMEAN score and a &lt;strong&gt;QMEAN Z-score&lt;/strong&gt; which compares your model to a baseline of experimental structures of similar size. A QMEAN Z-score around 0 is good (meaning your model is in the range of normal structures); a score significantly below -4.0 indicates a model of low quality (likely incorrect)​ (22). QMEAN also provides per-residue scores, so you can see which regions contribute to lowering the score. For AlphaFold models, QMEAN often yields scores consistent with high accuracy for high-pLDDT regions, but may penalize the low-confidence regions. Use this as an overall “sanity check” – if even QMEAN (which is trained on typical protein statistics) finds your entire model to be an outlier, you should be cautious. SwissModel will also report other descriptors like predicted secondary structure vs model secondary structure agreement, and possible buriedness mismatches.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All these tools provide &lt;strong&gt;complementary views of model quality&lt;/strong&gt;. In practice, you don’t have to use every single one for every model; but it’s wise to use at least one geometry-focused tool (MolProbity/PROCHECK) and one environment-focused tool (Verify3D/ERRAT/QMEAN). Many of these can be run easily via web servers. For instance, the &lt;strong&gt;UCLA SAVES&lt;/strong&gt; web server allows you to upload a PDB and get results from PROCHECK, Verify3D, and ERRAT together. MolProbity has its own web server (as part of Phenix or standalone). SwissModel’s assessment is another one-stop option for QMEAN and additional analyses.&lt;/p&gt;
&lt;p&gt;When you get the results, pay attention to consistent signals: e.g., if &lt;strong&gt;MolProbity and PROCHECK both say the same residue is an outlier&lt;/strong&gt; (bad geometry) and &lt;strong&gt;Verify3D also flags that region&lt;/strong&gt;, that part of the model is definitely suspect. You might then decide to remodel that segment or simply note that it’s unreliable. On the other hand, if all tools give you largely clean reports (few clashes, good Ramachandran stats, high Verify3D percentage, high ERRAT score), you can be more confident the model is reasonable.&lt;/p&gt;
&lt;h2 id=&#34;comparison-with-experimental-structures&#34;&gt;Comparison with Experimental Structures&lt;/h2&gt;
&lt;p&gt;If a related experimental structure is available, comparing your AlphaFold model to it is one of the most telling validations. Such comparisons can &lt;strong&gt;quantify the accuracy&lt;/strong&gt; of the prediction and highlight any differences that might be important.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Finding a reference structure:&lt;/strong&gt; First, determine if the same protein (or a homolog with significant sequence identity) has a known structure in the Protein Data Bank (PDB). You might have done this prior to running AlphaFold, but it’s worth doing a BLAST or HHPred search of your sequence against PDB. Even if an exact match isn’t found, perhaps a homologous domain or a partial structure exists. Any high-resolution structure (X-ray, cryo-EM, NMR) of a similar sequence can serve as a reference to validate fold correctness.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Structural alignment tools:&lt;/strong&gt; To compare the 3D structures, you can use alignment programs like &lt;strong&gt;TM-align&lt;/strong&gt; or built-in tools in PyMOL/Chimera.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TM-align&lt;/strong&gt; – A command-line tool that superimposes two protein structures and calculates the TM-score and RMSD. The &lt;strong&gt;TM-score&lt;/strong&gt; is particularly useful; it ranges from 0 to 1, where 1 indicates an identical structure. Importantly, TM-score is designed to be length-independent and sensitive to overall fold​ (23,24). A TM-score &amp;gt; 0.5 generally indicates the two structures share the same fold​ (25) (and &amp;gt;0.9 would mean almost identical). Scores &amp;lt; 0.2 indicate essentially unrelated structures (random similarity) (26). RMSD (root-mean-square deviation) in Å is also output, but RMSD can be misleading for large proteins or ones with flexible termini, so TM-score is the better metric for global accuracy. To use TM-align, download it from the Zhang Lab website and run it on your model and the reference PDB:&lt;/p&gt;
&lt;h1 id=&#34;example-usage-of-tm-align&#34;&gt;Example usage of TM-align&lt;/h1&gt;
&lt;p&gt;TMalign model.pdb reference.pdb &amp;gt; tmalign_output.txt&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The output will list aligned length, RMSD, and TM-scores. Check the TM-score first. For instance, if you get TM-score = 0.65, that’s a strong confirmation the fold is correct (assuming the reference covers the full length). You might also get a per-residue alignment which can identify where differences occur (e.g., a loop in the model that deviates from the crystal structure).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PyMOL or Chimera(X) alignment&lt;/strong&gt; – In PyMOL, you can use the align or cealign commands to superimpose two structures (if sequences are identical or very similar, a straightforward align model, reference works; for more distantly related, PyMOL’s built-in alignment might struggle, so TM-align is better). UCSF Chimera has a tool called MatchMaker which can align structures based on sequences and secondary structure. After superposition, you can visually inspect differences and also measure RMSD over aligned regions. Look at the &lt;strong&gt;alpha carbon trace&lt;/strong&gt;: do the helices and strands overlap well? Are there specific regions where the model deviates? Often, you’ll find that high-pLDDT regions of the AlphaFold model align closely with the experimental structure (perhaps within 1–2 Å RMSD), whereas low-confidence loops might be displaced or completely different (AlphaFold might have modeled a loop arbitrarily if there was no template or signal for it).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Interpreting differences:&lt;/strong&gt; If your model aligns well (high TM-score, low RMSD) with an experimental structure, that’s great validation. Minor differences in side chain conformations are expected and not usually concerning, especially if the experimental structure was determined at moderate resolution or is in a different environment (AlphaFold predictions are effectively in isolation, whereas a crystal structure might have bound ligands or lattice contacts that shift things). Focus on larger deviations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Domain shifts:&lt;/strong&gt; Perhaps the model predicted a closed conformation whereas the crystal is open (or vice versa). Check the PAE from AlphaFold; it might have indicated uncertainty between domains, and indeed the experimental structure shows a different orientation. This doesn’t mean the model is “wrong” per se, but that the protein might be dynamic or the model chose one plausible state. You might then need to verify which state is relevant biologically (through experiments or further modeling).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loop conformations:&lt;/strong&gt; A common scenario is that AlphaFold modeled a loop one way (especially if low confidence, it might even be a nonsense loop), and the crystal structure shows a different loop conformation. If the loop is functionally important (e.g., part of an active site), you’d want to trust the experimental structure more. If it’s surface-exposed, it might be flexible in reality; AlphaFold’s guess is just one of many conformations it could take. In such cases, don’t over-interpret that part of the model.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secondary structure errors:&lt;/strong&gt; Rarely, AlphaFold might predict a helix where the actual structure has a strand, or vice versa. This usually happens in lower confidence regions or if the sequence had an unusual pattern. If you find such a discrepancy, that region of the model is likely incorrect. Use the experimental structure’s assignment as the truth. It’s worth noting if the pLDDT was low there (likely yes); AlphaFold was unsure and picked one possibility. Knowing the correct secondary structure, you might rebuild that segment or simply note the model’s limitation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If no experimental structure is available for the exact protein, you can still do &lt;strong&gt;remote validations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Align the model to the closest known structure (even if only part of it aligns). For example, maybe one domain matches a known protein family structure. Validate that portion – a good alignment (say TM-score &amp;gt;0.5 for that domain) gives confidence that domain is correct. The other parts of your model that have no benchmark will rely on the internal metrics and other validations we discuss.&lt;/li&gt;
&lt;li&gt;Use multiple structure prediction approaches and compare (e.g., if there’s an older homology model or a Rosetta model for the protein). Consistency between different models can be somewhat validating, though remember they might all be wrong in the same way if based on the same inputs. Still, if AlphaFold and, say, Rosetta both produce a similar fold for a novel protein, that convergence is encouraging.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall, &lt;strong&gt;structural comparison is the gold standard&lt;/strong&gt; when you have an experimental reference. It can confirm that AlphaFold got it right, or pinpoint exactly where it differs. In favorable cases (AlphaFold’s high-accuracy predictions), you might find your model is virtually identical to the crystal structure of a homolog, with perhaps a TM-score ~0.9 and main-chain RMSD ~1 Å​. That level of agreement would give you great confidence moving forward. On the other hand, if the model and experiment differ significantly (low TM-score), you should trust the experiment more – and treat the model with skepticism or use it only for qualitative insights in regions that do align well.&lt;/p&gt;
&lt;h2 id=&#34;functional-validation-ligand-binding-and-dynamics&#34;&gt;Functional Validation: Ligand Binding and Dynamics&lt;/h2&gt;
&lt;p&gt;The ultimate purpose of a protein structure is often to investigate function – e.g., how it binds to a ligand, catalyzes a reaction, or interacts with other molecules. Thus, validating an AlphaFold model also involves asking: &lt;em&gt;Does this structure make sense functionally?&lt;/em&gt; There are a few approaches to explore this:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Checking Binding Sites and Docking Ligands:&lt;/strong&gt; If your protein is known (or suspected) to bind a small-molecule ligand, cofactor, or substrate, examine the predicted structure for the binding site. AlphaFold might not explicitly indicate pockets, but you can use tools or visual cues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a pocket detection tool like &lt;strong&gt;CASTp&lt;/strong&gt; or &lt;strong&gt;Fpocket&lt;/strong&gt; to identify cavities on the model. These tools will list pockets by volume and residues lining them. Check if a known active site corresponds to one of the top pockets.&lt;/li&gt;
&lt;li&gt;If you have a known ligand (say, the substrate of an enzyme or a cofactor like NADH), try &lt;strong&gt;docking&lt;/strong&gt; it into the model. Software like &lt;strong&gt;AutoDock Vina&lt;/strong&gt; (open source) or &lt;strong&gt;SwissDock&lt;/strong&gt;, &lt;strong&gt;Glide&lt;/strong&gt; (commercial) can take your model (treated as the receptor) and the ligand structure and attempt to find plausible binding poses. Before docking, prepare the protein: add hydrogens (especially if using AutoDock, you’d prepare a PDBQT file with charges), and consider making the protein rigid for the initial docking. A successful dock would show the ligand fitting well into a pocket, with key interactions (hydrogen bonds to the right residues, hydrophobics nestled in hydrophobic patches, etc.) similar to what you’d expect. If docking suggests a reasonable pose and binding energy, it &lt;strong&gt;supports the validity of the binding site conformation&lt;/strong&gt; in the model. If the ligand cannot dock or only docks in a bizarre way (or with a very poor score), that might indicate the binding site in the model is not accurately formed. Perhaps a side chain that should move is blocking the pocket, or a loop is mis-modeled.&lt;/li&gt;
&lt;li&gt;For enzymes, check the geometry of catalytic residues. Do they form the correct arrangement? For example, a catalytic triad (Ser-His-Asp) should be in the right orientation to form hydrogen bonds. If the model’s active site residues are far apart or oriented incorrectly, the model might represent an inactive conformation, or it might be wrong in that region. Sometimes, energy-minimizing that region or running a short MD (see below) can relax the structure into a more favorable active-site geometry.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Protein-Protein Interactions:&lt;/strong&gt; If your protein’s function involves other macromolecules (another protein, DNA/RNA, etc.), consider validating those interfaces. AlphaFold-Multimer (a version of AlphaFold for complexes) might predict complexes, but if you only have a monomeric model, you can still simulate docking:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a protein-protein docking server (e.g., &lt;strong&gt;HADDOCK&lt;/strong&gt; or &lt;strong&gt;ClusPro&lt;/strong&gt;) to see if your model can interact with its partner in a way that’s consistent with known data. This is more advanced, but if an interface is known experimentally (like mutagenesis showed certain residues are important), check if those residues are surface-exposed and clustered, as they should be if an interface is there.&lt;/li&gt;
&lt;li&gt;If the model is of a single chain that normally oligomerizes (dimer, etc.), you might superpose multiple copies or use symmetry to see if a plausible dimer can form. Again, low PAE between chains in an AlphaFold-Multimer prediction would signal a confident multimer interface​ (27), but for a single-chain prediction you have to manually inspect.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Molecular Dynamics (MD) Simulations:&lt;/strong&gt; This is a powerful way to &lt;strong&gt;test the stability&lt;/strong&gt; of the predicted structure and to possibly refine it. In MD, you treat the model with physical force fields and see if it holds up under simulation (e.g., in water at 300 K). MD can reveal if the structure wants to &lt;strong&gt;unfold or change&lt;/strong&gt; and can also relieve any residual strain by nudging the model into a more favorable state.&lt;/p&gt;
&lt;p&gt;Common MD packages include &lt;strong&gt;GROMACS&lt;/strong&gt; (free, open-source), &lt;strong&gt;AMBER&lt;/strong&gt; (academic, partly free tools), and &lt;strong&gt;NAMD&lt;/strong&gt; (free, optimized for large systems). An example workflow using GROMACS will be covered in another blog post.&lt;/p&gt;
&lt;p&gt;During the simulation, monitor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RMSD over time:&lt;/strong&gt; Does the protein rapidly drift away from the starting structure, or does it stabilize? A stable RMSD (plateauing after some fluctuation) suggests the structure is in a favourable energy well (likely a correct fold). If RMSD keeps increasing or the protein partially unfolds, that indicates the model had instabilities (perhaps that region was incorrect or inherently flexible).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secondary structure retention:&lt;/strong&gt; You can use tools (like DSSP on each frame) to see if helices and strands remain intact. If a predicted helix quickly unravels in MD, maybe that segment wasn’t truly helical.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key interactions:&lt;/strong&gt; Check if critical hydrogen bonds or salt bridges persist. For example, if the model suggested a salt bridge that’s important for stability, does MD maintain it or does it break?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Refinement:&lt;/strong&gt; MD often causes side chains to adjust, sometimes resolving minor clashes automatically. You might take an &lt;strong&gt;average or low-energy structure from the simulation&lt;/strong&gt; as a refined model. Many researchers use short MD refinement to improve homology models​ (28); the same can be done for AlphaFold models, especially to relax strained loops. As one approach, you could restrain the well-defined parts of the structure (to prevent them from moving too much) and let a loop of interest move freely; this can relieve local strain​ (28).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MD simulation essentially serves as a &lt;strong&gt;reality check&lt;/strong&gt;: AlphaFold’s neural network prediction isn’t guaranteed to be at an energy minimum. If the model is good, it should withstand simulation in a realistic environment. If it’s not, you might see it start to collapse or drift, which tells you that at least some interactions in the model were not favorable. Of course, MD itself is an approximation (dependent on the force field, etc.), but it’s a well-established method to refine and validate structures.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After MD analysis:&lt;/strong&gt; If the structure proved stable, you gain confidence. You might also use the MD trajectory to estimate the flexibility of different regions (e.g., high B-factor regions in a crystal often correspond to mobile loops in MD). If the structure was unstable, identify what broke down – was it the interface between two domains? Was it a particular loop that kept swinging out? This can pinpoint the weak spots of the model that might need revision or cautious interpretation.&lt;/p&gt;
&lt;p&gt;Lastly, &lt;strong&gt;tie back to experiments whenever possible&lt;/strong&gt;. If you have biochemical data (e.g., mutation effects, binding assays), see if the model’s features align with them. For example, if a mutation is known to disrupt function and your model places that residue in the core of the active site, that’s consistent and supports the model. If instead the model has that residue on the surface away from any obvious functional site, maybe the model is missing something (like maybe it’s actually part of a protein-protein interface that wasn’t modeled).&lt;/p&gt;
&lt;p&gt;By this point, you have examined the model from every angle: intrinsic confidence (AlphaFold metrics), overall geometry and quality (validation tools), comparison to known structures, and functional plausibility (docking, pockets, MD). Based on all these, you can form a judgment on how &lt;strong&gt;reliable each part of the model is&lt;/strong&gt;. It’s often useful to summarize this in a &lt;strong&gt;table or checklist&lt;/strong&gt;, as we do below.&lt;/p&gt;
&lt;h2 id=&#34;summary-of-validation-steps&#34;&gt;Summary of Validation Steps&lt;/h2&gt;
&lt;p&gt;The following table summarizes key validation steps for an AlphaFold model and why each step is important:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;strong&gt;Validation Step&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Purpose and Importance&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;AlphaFold Confidence (pLDDT &amp;amp; PAE)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Identify which regions of the model are predicted with high confidence and which are uncertain. pLDDT highlights local reliability (e.g., core vs. floppy tail) and PAE indicates confidence in domain orientation​ (29). This guides where to focus further validation – low pLDDT or high PAE regions are likely error-prone or flexible.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Visual Inspection (PyMOL/ChimeraX/Mol)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Catch obvious structural anomalies and get an intuitive feel for the model. By coloring the structure by confidence and examining secondary structure, one can see if the fold makes sense. Visual checks can reveal steric clashes, weird loops, or missing pockets early on. It’s a simple sanity check before delving into metrics.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Geometric Validation (MolProbity, PROCHECK, WHAT_CHECK)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Ensure the model’s geometry is physically plausible. These tools check bond lengths, angles, dihedral angles (Ramachandran plot) and detect atomic clashes​ (29). Good geometry (few outliers, low clashscore) means the model is stereochemically sound, while many violations indicate errors or regions that may need refinement.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Residue Environment Validation (Verify3D, ERRAT, QMEAN)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Assess whether each residue is in a realistic environment and the model has protein-like statistical features. Verify3D and ERRAT compare the structure to empirical rules derived from real proteins​ (19). A high Verify3D score or ERRAT quality factor, and a QMEAN Z-score near 0, suggest the model is globally consistent with known protein structures. Poor scores flag unlikely regions (e.g., a hydrophobic residue exposed, or an odd packing) for further scrutiny.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Comparison to Known Structures (TM-align, structural superposition)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Quantify accuracy by comparing to experimental data. If a PDB structure exists, a high TM-score (≈0.5–1.0) and low RMSD confirm the model’s correctness​. Even partial matches validate domains or motifs. Discrepancies pinpoint specific errors or alternative conformations. This step effectively benchmarks the model against reality.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Functional Site Check (Docking &amp;amp; Pockets)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Verify that the model supports the protein’s known function. Checking for expected pockets and docking ligands tests if the active or binding site is correctly formed. Successful docking (reasonable poses &amp;amp; scores) means the geometry allows the interaction, while failures could mean the site is modeled incorrectly. This links structure to biochemical function, an essential validation for usability in studies (e.g., drug design).&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Molecular Dynamics Simulation (GROMACS/AMBER/NAMD)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Test the model’s stability and refine it in a physics-based environment. A stable trajectory (little deviation) indicates the model sits in an energy minimum (likely correct fold), whereas structural unraveling signals problems. MD can also relieve minor clashes and adjust the model to be more realistic. In sum, MD validation ensures the model’s behavior is consistent with a real protein in solvent over time.&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Each step adds a layer of confidence to your AlphaFold-predicted structure. By the end of this process, you should have a detailed understanding of your model’s strengths and weaknesses: which parts you can trust, which parts should be treated as hypotheses, and what further experiments or refinements might be necessary. Validating computational models is crucial for &lt;strong&gt;responsible use of AlphaFold predictions&lt;/strong&gt; in research – it separates the cases where the model is as good as a crystal structure from those where it might mislead if taken at face value​ (30). With the strategies outlined above, researchers and students can robustly assess their AlphaFold structures and proceed with confidence in subsequent analyses.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;1- Jumper, J., Evans, R., Pritzel, A., et al. (2021). Highly accurate protein structure prediction with AlphaFold. &lt;em&gt;Nature&lt;/em&gt;, 596(7873), 583–589. 
&lt;/p&gt;
&lt;p&gt;2- European Bioinformatics Institute. (n.d.). &lt;em&gt;pLDDT: Understanding local confidence&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;3- European Bioinformatics Institute. (n.d.). &lt;em&gt;pLDDT measures confidence in the predicted position of residues&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;4- Jumper et al., 2021 – (lDDT, pLDDT also reflects local geometry) 
&lt;/p&gt;
&lt;p&gt;5- European Bioinformatics Institute. (n.d.). &lt;em&gt;Predicted aligned error (PAE) – Explanation&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;6- European Bioinformatics Institute. (n.d.). &lt;em&gt;Low PAE score implies confident relative positions&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;7- European Bioinformatics Institute. (n.d.). &lt;em&gt;PAE visualisation explanation&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;8- EBI (n.d.). &lt;em&gt;Image: Figure 18 – PAE plot&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;9- EBI (n.d.). &lt;em&gt;Explanation of diagonal PAE plot&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;10- EBI (n.d.). &lt;em&gt;Comparison of pLDDT and PAE&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;11- Jumper et al., 2021 – (residue confidence metric pLDDT) 
&lt;/p&gt;
&lt;p&gt;12- EBI (n.d.). &lt;em&gt;How to view PAE plots in structure viewer&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;13- Chen, V. B., Arendall, W. B., Headd, J. J., et al. (2010). MolProbity: All-atom structure validation for macromolecular crystallography. &lt;em&gt;Acta Crystallographica Section D: Biological Crystallography&lt;/em&gt;, 66(1), 12–21. 
&lt;/p&gt;
&lt;p&gt;14- Chen et al., 2010 – (integration with other resources) 
&lt;/p&gt;
&lt;p&gt;15- Laskowski, R. A., MacArthur, M. W., Moss, D. S., &amp;amp; Thornton, J. M. (1993). PROCHECK: A program to check the stereochemical quality of protein structures. &lt;em&gt;Journal of Applied Crystallography&lt;/em&gt;, 26(2), 283–291. 
&lt;/p&gt;
&lt;p&gt;16- EBI (n.d.). &lt;em&gt;PROCHECK hand menu image&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;17- SAVES. (n.d.). &lt;em&gt;VERIFY 3D&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;18- ResearchGate. (n.d.). &lt;em&gt;Interpreting ERRAT, Verify3D and PROCHECK scores&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;19- SAVES. (n.d.). &lt;em&gt;ERRAT&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;20- BioStars. (n.d.). &lt;em&gt;Verify3D result discussion&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;21- Benkert, P., Tosatto, S. C., &amp;amp; Schwede, T. (2009). QMEAN: A comprehensive scoring function for model quality assessment. &lt;em&gt;Proteins: Structure, Function, and Bioinformatics&lt;/em&gt;, 71(1), 261–277. 
&lt;/p&gt;
&lt;p&gt;22- Bonvin Lab. (n.d.). &lt;em&gt;QMEAN Z-score&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;23- Zhang, Y., &amp;amp; Skolnick, J. (2005). TM-align: A protein structure alignment algorithm based on the TM-score. &lt;em&gt;Nucleic Acids Research&lt;/em&gt;, 33(7), 2302–2309. 
&lt;/p&gt;
&lt;p&gt;24- ZhangGroup. (n.d.). &lt;em&gt;TM-score info&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;25- Varadi, M., Anyango, S., Deshpande, M., et al. (2022). AlphaFold Protein Structure Database: Massively expanding the structural coverage of protein-sequence space with high-accuracy models. &lt;em&gt;Nucleic Acids Research&lt;/em&gt;, 50(D1), D439–D444. 
&lt;/p&gt;
&lt;p&gt;26- EBI (n.d.). &lt;em&gt;Residue confidence within structure prediction&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;27- EBI (n.d.). &lt;em&gt;pLDDT: More accurate structures&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;28- BioStars. (n.d.). &lt;em&gt;Simulations and MD prep&lt;/em&gt;. 
&lt;/p&gt;
&lt;p&gt;29- Jumper et al., 2021 – (Predicted Aligned Error detail) 
&lt;/p&gt;
&lt;p&gt;30- EBI (n.d.). &lt;em&gt;PAE score importance for AlphaFold ID&lt;/em&gt;. 
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Comprehensive Guide to Scientific Writing and Publishing</title>
      <link>https://yboulaamane.github.io/blog/a-comprehensive-guide-to-scientific-writing-and-publishing/</link>
      <pubDate>Tue, 23 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/a-comprehensive-guide-to-scientific-writing-and-publishing/</guid>
      <description>&lt;p&gt;Writing a scientific paper is both an art and a process. Beyond simply reporting results, effective writing ensures your research &lt;strong&gt;connects with the right audience&lt;/strong&gt;, &lt;strong&gt;contributes to the literature&lt;/strong&gt;, and &lt;strong&gt;stands up to peer review&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This guide compiles &lt;strong&gt;frameworks, examples, and checklists&lt;/strong&gt; to help researchers—from graduate students to seasoned scientists—communicate their work clearly, concisely, and convincingly.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;finding-the-right-words--expressions&#34;&gt;Finding the Right Words &amp;amp; Expressions&lt;/h2&gt;
&lt;p&gt;Clarity often comes from using the right connectors. These words shape the &lt;em&gt;flow&lt;/em&gt; of your arguments.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Purpose&lt;/th&gt;
          &lt;th&gt;Useful Expressions&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Adding to an idea&lt;/td&gt;
          &lt;td&gt;Additionally, Furthermore, Moreover, In addition&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Showing consequence&lt;/td&gt;
          &lt;td&gt;Therefore, Thus, As a result, Hence&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Emphasizing&lt;/td&gt;
          &lt;td&gt;Especially, Of course, Certainly, Indeed&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Giving a reason&lt;/td&gt;
          &lt;td&gt;Because, Due to, Owing to, Since&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Showing contrast&lt;/td&gt;
          &lt;td&gt;However, Although, Whereas, In contrast, Nevertheless&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Summarizing&lt;/td&gt;
          &lt;td&gt;In summary, To conclude, In short, In brief&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Providing examples&lt;/td&gt;
          &lt;td&gt;For instance, Such as, Namely, In particular&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;👉 &lt;em&gt;Tip&lt;/em&gt;: Avoid overusing “However” and “Therefore.” Varying transitions makes your writing smoother.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;structuring-the-discussion--conclusion&#34;&gt;Structuring the Discussion &amp;amp; Conclusion&lt;/h2&gt;
&lt;p&gt;The discussion is where you “sell” the value of your work. A logical flow makes it compelling:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Answer the research question&lt;/strong&gt; – restate your hypothesis and findings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support the answer&lt;/strong&gt; – integrate with key studies, highlight novelty.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Defend the answer&lt;/strong&gt; – address potential criticisms or alternative explanations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strengths &amp;amp; limitations&lt;/strong&gt; – show awareness of your study’s scope.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conclude&lt;/strong&gt; – state the broader implications, practical applications, or next steps.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;👉 &lt;em&gt;Engaging twist&lt;/em&gt;: End with a forward-looking statement, e.g. &lt;em&gt;“This framework opens the door for clinical validation in larger patient cohorts.”&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;writing-a-literature-review&#34;&gt;Writing a Literature Review&lt;/h2&gt;
&lt;p&gt;A strong literature review goes beyond summary—it &lt;strong&gt;creates a story&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Synthesize&lt;/strong&gt; across studies, not just list them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Position&lt;/strong&gt; your work: what’s been done, and where you fit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identify gaps&lt;/strong&gt; that justify your research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suggest directions&lt;/strong&gt; for others to follow.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;purposes-of-a-literature-review&#34;&gt;Purposes of a literature review&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Show relationships between studies.&lt;/li&gt;
&lt;li&gt;Provide context for your question.&lt;/li&gt;
&lt;li&gt;Highlight methods that work (and those that don’t).&lt;/li&gt;
&lt;li&gt;Spot contradictions and unresolved debates.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;👉 &lt;em&gt;Pro tip&lt;/em&gt;: Use &lt;strong&gt;concept maps&lt;/strong&gt; or tables to visualize clusters of related work.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;materials--methods-checklist&#34;&gt;Materials &amp;amp; Methods Checklist&lt;/h2&gt;
&lt;p&gt;A reproducible methods section is a &lt;strong&gt;hallmark of good science&lt;/strong&gt;. Include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detailed experimental procedures.&lt;/li&gt;
&lt;li&gt;Quantities, timings, parameters.&lt;/li&gt;
&lt;li&gt;Software, datasets, equipment versions.&lt;/li&gt;
&lt;li&gt;Statistical tests and significance levels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Writing tips&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use &lt;strong&gt;past tense&lt;/strong&gt; and &lt;strong&gt;passive voice&lt;/strong&gt; (“Samples were analyzed…”).&lt;/li&gt;
&lt;li&gt;Organize under &lt;strong&gt;Materials&lt;/strong&gt;, &lt;strong&gt;Instrumentation&lt;/strong&gt;, &lt;strong&gt;Procedures&lt;/strong&gt;, &lt;strong&gt;Statistics&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Provide supplementary material for lengthy protocols.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;research-paper-vs-review-paper&#34;&gt;Research Paper vs Review Paper&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Feature&lt;/th&gt;
          &lt;th&gt;Research Paper&lt;/th&gt;
          &lt;th&gt;Review Paper&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Purpose&lt;/td&gt;
          &lt;td&gt;Present original findings&lt;/td&gt;
          &lt;td&gt;Critically analyze existing literature&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Source type&lt;/td&gt;
          &lt;td&gt;Primary data&lt;/td&gt;
          &lt;td&gt;Secondary sources&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Structure&lt;/td&gt;
          &lt;td&gt;IMRaD (Intro, Methods, Results, Discussion)&lt;/td&gt;
          &lt;td&gt;Thematic or chronological&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Typical length&lt;/td&gt;
          &lt;td&gt;3,000–12,000 words&lt;/td&gt;
          &lt;td&gt;3,000–5,000 words&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;writing-key-sections&#34;&gt;Writing Key Sections&lt;/h2&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Think of the abstract as the &lt;strong&gt;elevator pitch&lt;/strong&gt; for your paper:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Introduce the field.&lt;/li&gt;
&lt;li&gt;State the gap/problem.&lt;/li&gt;
&lt;li&gt;Describe what you did.&lt;/li&gt;
&lt;li&gt;Highlight the main result.&lt;/li&gt;
&lt;li&gt;Interpret its meaning.&lt;/li&gt;
&lt;li&gt;Broaden to impact/significance.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Present each figure in order.&lt;/li&gt;
&lt;li&gt;One key takeaway per figure.&lt;/li&gt;
&lt;li&gt;Save extended interpretation for the discussion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;discussion&#34;&gt;Discussion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Lead with your &lt;strong&gt;main finding&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Compare with past studies.&lt;/li&gt;
&lt;li&gt;Discuss implications and limitations.&lt;/li&gt;
&lt;li&gt;End on how this work moves the field forward.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;research-workflow-overview&#34;&gt;Research Workflow Overview&lt;/h2&gt;
&lt;p&gt;A simple roadmap to keep your writing organized:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Introduction&lt;/strong&gt; – What’s the problem, why does it matter?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Literature Review&lt;/strong&gt; – What’s known and what’s missing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt; – How you addressed the gap.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Results&lt;/strong&gt; – What you found.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limitations&lt;/strong&gt; – What’s uncertain or needs caution.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conclusion&lt;/strong&gt; – Why it matters, and where to go next.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;writing-tips-for-impact&#34;&gt;Writing Tips for Impact&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Keep the &lt;strong&gt;introduction short&lt;/strong&gt; and hook the reader.&lt;/li&gt;
&lt;li&gt;Use &lt;strong&gt;figures and tables&lt;/strong&gt; to reduce text.&lt;/li&gt;
&lt;li&gt;Draft the &lt;strong&gt;results section first&lt;/strong&gt;, intro last.&lt;/li&gt;
&lt;li&gt;Revise in cycles: clarity → conciseness → polish.&lt;/li&gt;
&lt;li&gt;Share with peers: fresh eyes catch unclear logic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;👉 &lt;em&gt;Reader-friendly idea&lt;/em&gt;: End each draft session by writing a &lt;strong&gt;one-sentence summary&lt;/strong&gt; of your paper. If it’s unclear, refine your message.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-thoughts&#34;&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;Scientific writing is not only about transmitting facts—it’s about &lt;strong&gt;building trust&lt;/strong&gt; with your readers and reviewers. A well-structured, transparent, and engaging manuscript increases your chances of publication and ensures your contribution has real impact.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Credit:&lt;/strong&gt; Adapted from OpenAcademics, &lt;em&gt;Nature&lt;/em&gt;, &lt;em&gt;Science Translational Medicine&lt;/em&gt;, the MIT Biological Engineering Communication Lab, and other writing guides.&lt;/p&gt;&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Interpretable Machine Learning as a Key to Understanding BBB Permeability</title>
      <link>https://yboulaamane.github.io/blog/interpretable-machine-learning-model-as-a-key-to-understanding-bbb-permeability/</link>
      <pubDate>Tue, 23 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/interpretable-machine-learning-model-as-a-key-to-understanding-bbb-permeability/</guid>
      <description>&lt;p&gt;The blood-brain barrier (BBB) is a vital selective barrier in the central nervous system. Assessing the permeability of compounds across the BBB is crucial for drug development targeting the brain. While clinical experiments are accurate, they are time-consuming and costly. Computational methods offer an alternative for predicting BBB permeability.&lt;/p&gt;
&lt;h2 id=&#34;1-downloading-the-dataset&#34;&gt;1. Downloading the dataset&lt;/h2&gt;
&lt;p&gt;In the first step of our tutorial, we initiate the process by downloading the essential dataset. This dataset, curated by Meng et al. in 2021, is a valuable resource comprising over 7000 compounds and 1613 chemical descriptors, calculated using Mordred fingerprints. To ensure a seamless experience, execute the provided command in your Python environment to obtain the dataset from the specified URL. This dataset serves as the foundation for our exploration into machine learning applications for predicting chemical drug properties, particularly focusing on aqueous water solubility and BBB permeability.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!wget https://github.com/theochem/B3DB/raw/87240af2b4e585d56f9681a6426af6b7f2940e96/B3DB/B3DB_classification_extended.tsv.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the subsequent code snippet, we unpack the compressed dataset file for ease of access and analysis. The Python script utilizes the gzip library to decompress the file named &amp;ldquo;B3DB_classification_extended.tsv.gz.&amp;rdquo; The decompressed file is then saved with the name &amp;ldquo;B3DB_classification_extended.tsv.&amp;rdquo; This extraction process ensures that the dataset is in a readable format for further exploration and manipulation. After running this code, a confirmation message will be displayed, indicating that the extraction was successful. This step is crucial in preparing the dataset for subsequent machine learning analyses, allowing us to delve into predicting chemical drug properties with enhanced clarity and convenience.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import gzip
import shutil

input_file_path = &amp;quot;B3DB_classification_extended.tsv.gz&amp;quot;
output_file_path = &amp;quot;B3DB_classification_extended.tsv&amp;quot;

with gzip.open(input_file_path, &#39;rb&#39;) as f_in:
	with open(output_file_path, &#39;wb&#39;) as f_out:
		shutil.copyfileobj(f_in, f_out)

print(f&amp;quot;File &#39;{input_file_path}&#39; has been successfully extracted to &#39;{output_file_path}&#39;.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the following code snippet, we leverage the power of the pandas library to seamlessly import the extracted dataset into a structured and manipulable DataFrame. The dataset, now stored as &amp;ldquo;B3DB_classification_extended.tsv,&amp;rdquo; is read into the variable &amp;lsquo;df&amp;rsquo; using the &amp;lsquo;read_csv&amp;rsquo; function from pandas. The &amp;lsquo;sep&amp;rsquo; parameter is set to &amp;lsquo;\t&amp;rsquo; to indicate that the data is tab-separated, ensuring proper parsing. By displaying the DataFrame &amp;lsquo;df,&amp;rsquo; we gain a preliminary glimpse into the dataset&amp;rsquo;s structure and content. This step marks a pivotal moment as we transition from data acquisition to data exploration, setting the stage for in-depth analyses and insights into the chemical properties encapsulated within the dataset. With the dataset loaded into memory, we are ready to unleash the capabilities of pandas for comprehensive data exploration and preprocessing, paving the way for subsequent machine learning applications.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df = pd.read_csv(&amp;quot;B3DB_classification_extended.tsv&amp;quot;, sep=&#39;\t&#39;)
df
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/f5bbc971-d805-405b-91de-48dfd032de01&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;2-curating-the-dataset&#34;&gt;2. Curating the dataset&lt;/h2&gt;
&lt;p&gt;Next, we use the &amp;lsquo;dropna&amp;rsquo; method from pandas to efficiently handle missing values within our DataFrame (&amp;lsquo;df&amp;rsquo;). The &amp;lsquo;axis=1&amp;rsquo; parameter signifies that the operation is applied along columns, effectively removing any columns containing NaN (Not a Number) values. This step is crucial for ensuring the cleanliness and completeness of our dataset, setting the foundation for accurate and robust machine learning analyses. By executing this line, we enhance the dataset&amp;rsquo;s quality and prepare it for subsequent feature selection, model training, and predictions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df = df.dropna(axis=1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/90e8705d-76be-4ddb-942c-ba7dcd71e5ee&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;3-labelling-the-dataset&#34;&gt;3. Labelling the dataset&lt;/h2&gt;
&lt;p&gt;In this code snippet, a new column named &amp;rsquo;labels&amp;rsquo; is added to the DataFrame &amp;lsquo;df.&amp;rsquo; The values in this column are determined based on the &amp;lsquo;BBB+/BBB-&amp;rsquo; column. The &amp;lsquo;apply&amp;rsquo; function, combined with a lambda function, assigns a binary label: 0 if &amp;lsquo;BBB-&amp;rsquo; and 1 if &amp;lsquo;BBB+&amp;rsquo;. This line of code is instrumental in preparing the dataset for a supervised machine learning task, where we aim to predict the binary outcome of blood-brain barrier (BBB) permeability. The &amp;rsquo;labels&amp;rsquo; column now serves as the target variable, facilitating the training and evaluation of machine learning models for predicting BBB permeability.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df[&#39;labels&#39;] = df[&#39;BBB+/BBB-&#39;].apply(lambda x: 0 if x == &#39;BBB-&#39; else 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-selecting-chemical-descriptors&#34;&gt;4. Selecting chemical descriptors&lt;/h2&gt;
&lt;p&gt;In this code snippet, a subset of the DataFrame &amp;lsquo;df&amp;rsquo; is extracted to form the &amp;lsquo;features&amp;rsquo; DataFrame. The &amp;lsquo;iloc&amp;rsquo; method is employed to select columns within a specific index range, denoted by &amp;lsquo;abc_column_index&amp;rsquo; and &amp;lsquo;mZagreb2_column_index.&amp;rsquo; This operation isolates the columns containing the features used for machine learning analysis. By creating the &amp;lsquo;features&amp;rsquo; DataFrame, we focus on the relevant input variables necessary for training our machine learning models to predict blood-brain barrier (BBB) permeability. This step is pivotal in delineating the predictor variables from the target variable, facilitating streamlined model development and analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;features = df.iloc[:, 6:738]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we extract the binary classification labels for blood-brain barrier (BBB) permeability from the &amp;ldquo;labels&amp;rdquo; column of the DataFrame &amp;lsquo;df&amp;rsquo; and assigns them to the variable &amp;rsquo;labels.&amp;rsquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;labels = df[&amp;quot;labels&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;5-building-the-model&#34;&gt;5. Building the model&lt;/h2&gt;
&lt;p&gt;To build the ML model, we import essential modules from scikit-learn, a popular machine learning library in Python. The modules include RandomForestClassifier, svm, SVC, train_test_split for data splitting, cross_val_score, cross_val_predict for cross-validation, confusion_matrix for confusion matrix computation, roc_auc_score for ROC AUC score calculation, and classification_report for generating a classification report. These modules collectively provide a robust foundation for building, training, and evaluating machine learning models.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next line of code, the dataset is split into training and testing sets using the &amp;rsquo;train_test_split&amp;rsquo; function from scikit-learn. The &amp;lsquo;features&amp;rsquo; and &amp;rsquo;labels&amp;rsquo; variables represent the input features and target labels, respectively. The &amp;rsquo;test_size&amp;rsquo; parameter is set to 0.3, allocating 30% of the data for testing. The &amp;lsquo;random_state&amp;rsquo; ensures reproducibility, and &amp;lsquo;shuffle=True&amp;rsquo; randomizes the data before splitting. The &amp;lsquo;stratify=labels&amp;rsquo; parameter ensures that the class distribution is maintained in both the training and testing sets, which is crucial for balanced model training and evaluation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;X_train, X_test, y_train, y_test=train_test_split(features, labels, test_size=0.3, random_state=42, shuffle=True, stratify=labels)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, a RandomForestClassifier model is instantiated using scikit-learn. The model is then trained on the training data (&amp;lsquo;X_train&amp;rsquo; for features and &amp;lsquo;y_train&amp;rsquo; for labels) using the &amp;lsquo;fit&amp;rsquo; method. This marks a crucial step in the machine learning workflow, where the algorithm learns patterns from the training data to make predictions on new, unseen data. The variable &amp;lsquo;rf&amp;rsquo; now holds the trained Random Forest Classifier ready for evaluation and prediction tasks.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rf = RandomForestClassifier()
rf = rf.fit(X_train, y_train)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we employ the trained Random Forest Classifier (&amp;lsquo;rf&amp;rsquo;) to make predictions on the testing data (&amp;lsquo;X_test&amp;rsquo;). The predicted values are stored in the variable &amp;lsquo;y_pred,&amp;rsquo; representing the model&amp;rsquo;s anticipated outcomes for the corresponding features in the testing set. This step allows us to assess the model&amp;rsquo;s performance by comparing its predictions against the actual labels in the testing data.&lt;/p&gt;
&lt;h2 id=&#34;6-evaluating-the-models-performance&#34;&gt;6. Evaluating the model&amp;rsquo;s performance&lt;/h2&gt;
&lt;p&gt;The trained Random Forest Classifier (&amp;lsquo;rf&amp;rsquo;) is then employed to make predictions on the testing data (&amp;lsquo;X_test&amp;rsquo;). The predicted values are stored in the variable &amp;lsquo;y_pred,&amp;rsquo; representing the model&amp;rsquo;s anticipated outcomes for the corresponding features in the testing set. This step allows us to assess the model&amp;rsquo;s performance by comparing its predictions against the actual labels in the testing data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;y_pred = rf.predict(X_test)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next line prints a concise classification report, summarizing the performance metrics of the Random Forest Classifier on the test set.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;print(classification_report(y_pred, y_test))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/0b95329d-f1f8-4d30-8ad4-252a6bbb9337&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Afterwards, we calculate the ROC AUC score, a key performance metric for binary classification models like the Random Forest Classifier. The &amp;lsquo;roc_auc_score&amp;rsquo; function from scikit-learn computes the area under the Receiver Operating Characteristic (ROC) curve, providing a single value to gauge the model&amp;rsquo;s ability to distinguish between the two classes. The resulting score is printed as &amp;ldquo;ROC AUC Score.&amp;rdquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;roc_auc = roc_auc_score(y_test, y_pred)
print(&amp;quot;ROC AUC Score:&amp;quot;, roc_auc)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;7-calculating-the-most-important-features&#34;&gt;7. Calculating the most important features&lt;/h2&gt;
&lt;p&gt;The line of code below retrieves the feature importances calculated by the trained Random Forest Classifier. The attribute &amp;lsquo;feature_importances_&amp;rsquo; provides insights into the contribution of each feature in making predictions. The resulting array contains importance scores corresponding to the features used in the model. Analyzing these scores can help identify the most influential features in predicting blood-brain barrier (BBB) permeability.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rf.feature_importances_
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next code snippet, a new DataFrame named &amp;lsquo;xfeatures&amp;rsquo; is created, consolidating information about the features and their respective importance values obtained from the Random Forest Classifier. The DataFrame consists of two columns: &amp;ldquo;features,&amp;rdquo; representing the feature names extracted from the original dataset, and &amp;ldquo;Imp_values,&amp;rdquo; containing the corresponding feature importances calculated by the model. This DataFrame provides a clear and structured summary, making it easy to analyze and interpret the significance of each feature in predicting blood-brain barrier (BBB) permeability.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xfeatures=pd.DataFrame({&amp;quot;features&amp;quot;:features.columns, &amp;quot;Imp_values&amp;quot;:rf.feature_importances_})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We sort the &amp;lsquo;xfeatures&amp;rsquo; DataFrame in descending order based on the &amp;ldquo;Imp_values&amp;rdquo; column, providing a ranked view of feature importances. The resulting DataFrame showcases the features in decreasing order of importance, enabling a quick identification of the most influential factors in predicting blood-brain barrier (BBB) permeability according to the Random Forest Classifier.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xfeatures=xfeatures.sort_values(&amp;quot;Imp_values&amp;quot;, ascending=False)
xfeatures
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/fb2c60dc-41dc-4048-8d34-82f2615c8be0&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;8-interpreting-the-model-using-shap-explainer&#34;&gt;8. Interpreting the model using SHAP explainer&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll use the &amp;lsquo;pip&amp;rsquo; package manager to install the &amp;lsquo;shap&amp;rsquo; library. The &amp;lsquo;shap&amp;rsquo; library is often used for explaining the output of machine learning models, providing insights into the contribution of each feature to individual predictions. Once installed, the &amp;lsquo;shap&amp;rsquo; library can be imported and utilized in the analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!pip install shap
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &amp;lsquo;shap&amp;rsquo; library is employed to create an explainer (&amp;rsquo;explain&amp;rsquo;) for the trained Random Forest Classifier (&amp;lsquo;rf&amp;rsquo;). The explainer is then used to compute Shapley values (&amp;lsquo;shapvalues&amp;rsquo;) for the features in the testing set (&amp;lsquo;X_test&amp;rsquo;). Shapley values offer insights into the impact of each feature on individual predictions, providing a valuable tool for interpreting and understanding the model&amp;rsquo;s decision-making process.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import shap
explain=shap.Explainer(rf)
shapvalues=explain.shap_values(X_test)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we generate a summary plot using the &amp;lsquo;shap&amp;rsquo; library, visualizing the Shapley values for each feature across the entire testing set (&amp;lsquo;X_test&amp;rsquo;). The plot provides a concise overview of feature importance and their impact on model predictions, aiding in the interpretation of the Random Forest Classifier&amp;rsquo;s decision-making process.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shap.summary_plot(shapvalues,X_test)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/d584b45b-c037-4594-9b2d-c8fcc5dce254&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We can also create a summary plot using the &amp;lsquo;shap&amp;rsquo; library, specifically focusing on the Shapley values for the first class in the binary classification. The plot visualizes the impact of each feature on model predictions for this specific class across the testing set (&amp;lsquo;X_test&amp;rsquo;). This targeted summary aids in understanding the contributions of individual features to predictions related to the first class.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shap.summary_plot(shapvalues[0], X_test)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/cd1822f7-0384-476a-81c6-8081bb822991&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Finally, we generate a dependence plot using the &amp;lsquo;shap&amp;rsquo; library. The plot focuses on the most important feature &amp;ldquo;TopoPSA&amp;rdquo; and illustrates how its values impact the Shapley values and, consequently, the model predictions for the first class in the binary classification. Dependence plots are valuable for visualizing the relationship between a specific feature and the model output, enhancing interpretability.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;shap.dependence_plot(&amp;quot;TopoPSA&amp;quot;, shapvalues[0], X_test)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/yboulaamane/yboulaamane.github.io/assets/7014404/9ef5df90-cfd1-48a6-9387-fa8a8bd9f70e&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;9-bottom-line&#34;&gt;9. Bottom line&lt;/h2&gt;
&lt;p&gt;In conclusion, the significance of explainable machine learning (ML) becomes evident in unraveling complex models&amp;rsquo; decision-making processes. In our analysis of blood-brain barrier (BBB) permeability prediction, employing the &amp;lsquo;shap&amp;rsquo; library allowed us to interpret the Random Forest Classifier&amp;rsquo;s output. Notably, our findings highlight &amp;ldquo;TopoPSA&amp;rdquo; as the most crucial feature influencing the model&amp;rsquo;s predictions for BBB permeable compounds. This discovery aligns with existing literature, where molecular polar surface area (TopoPSA) has been consistently linked to BBB permeability. Our transparent and interpretable ML approach not only provides valuable insights into predictive features but also reinforces the importance of understanding model decisions for informed decision-making in drug development.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to build and validate 3D-QSAR models - Insights from Xu et al., 2020</title>
      <link>https://yboulaamane.github.io/blog/3d-qsar-general-workflow-with-key-metrics-insights-from-xu-et-al-2020/</link>
      <pubDate>Sat, 13 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/3d-qsar-general-workflow-with-key-metrics-insights-from-xu-et-al-2020/</guid>
      <description>&lt;h2 id=&#34;dataset-preparation&#34;&gt;Dataset Preparation&lt;/h2&gt;
&lt;p&gt;A high-quality dataset is the cornerstone of any QSAR study.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Collect experimental bioactivity data&lt;/strong&gt; — typically IC₅₀ values from reliable sources.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normalize the activity scale&lt;/strong&gt; — convert IC₅₀ to pIC₅₀:&lt;br&gt;
$$
\text{pIC}_{50} = -\log_{10}(\text{IC}_{50} \, \text{in molar})
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data partitioning&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Training set&lt;/strong&gt;: ~75–80% of compounds for model development.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test set&lt;/strong&gt;: ~20–25% of compounds for external validation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A balanced chemical space between sets is critical to avoid extrapolation during prediction.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;molecular-docking--alignment&#34;&gt;Molecular Docking &amp;amp; Alignment&lt;/h2&gt;
&lt;p&gt;Accurate alignment of molecules is pivotal in 3D-QSAR since descriptor calculation is &lt;strong&gt;spatially dependent&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Protein structure selection&lt;/strong&gt;: Obtain the target’s crystallographic structure from the &lt;strong&gt;Protein Data Bank (PDB)&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docking&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Use software such as &lt;strong&gt;SYBYL&lt;/strong&gt;, &lt;strong&gt;AutoDock&lt;/strong&gt;, or other docking engines.&lt;/li&gt;
&lt;li&gt;Perform &lt;em&gt;redocking&lt;/em&gt; to verify reliability — &lt;strong&gt;RMSD ≤ 2.0 Å&lt;/strong&gt; is generally considered acceptable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment strategy&lt;/strong&gt;: Select the &lt;strong&gt;best-scoring pose&lt;/strong&gt; as the reference for aligning all ligands.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;descriptor-calculation&#34;&gt;Descriptor Calculation&lt;/h2&gt;
&lt;p&gt;Two classical methods dominate 3D-QSAR descriptor generation:&lt;/p&gt;
&lt;h3 id=&#34;comparative-molecular-field-analysis-comfa&#34;&gt;Comparative Molecular Field Analysis (CoMFA)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fields: &lt;strong&gt;Steric&lt;/strong&gt; + &lt;strong&gt;Electrostatic&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Grid spacing: &lt;strong&gt;2.0 Å&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Probe: sp³ carbon atom with +1 charge&lt;/li&gt;
&lt;li&gt;Energy cutoff: &lt;strong&gt;30 kcal/mol&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comparative-molecular-similarity-indices-analysis-comsia&#34;&gt;Comparative Molecular Similarity Indices Analysis (CoMSIA)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fields: Steric, Electrostatic, Hydrophobic, H-bond Donor, H-bond Acceptor&lt;/li&gt;
&lt;li&gt;Attenuation factor: &lt;strong&gt;0.3&lt;/strong&gt; — controls the exponential distance dependence.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;model-building-with-partial-least-squares-pls&#34;&gt;Model Building with Partial Least Squares (PLS)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;PLS regression&lt;/strong&gt; is the workhorse for 3D-QSAR, capable of handling collinear and noisy descriptors.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Internal validation&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Perform &lt;strong&gt;Leave-One-Out Cross-Validation (LOO-CV)&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Record:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;q²&lt;/strong&gt;: cross-validated \( R^2 \), internal predictive power.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ONC&lt;/strong&gt;: Optimal Number of Components.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Final model construction&lt;/strong&gt; (using ONC):
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;r²&lt;/strong&gt;: Goodness-of-fit to training set.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SEE&lt;/strong&gt;: Standard Error of Estimate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;F-statistic&lt;/strong&gt;: Statistical significance of the regression.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;model-validation&#34;&gt;Model Validation&lt;/h2&gt;
&lt;p&gt;Validation ensures the model is &lt;strong&gt;predictive, robust, and not the result of chance correlations&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;external-validation&#34;&gt;External Validation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Predict &lt;strong&gt;pIC₅₀&lt;/strong&gt; for the test set.&lt;/li&gt;
&lt;li&gt;Calculate &lt;strong&gt;r²ₚᵣₑd&lt;/strong&gt; for predictive performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tropshas-criteria&#34;&gt;Tropsha’s Criteria&lt;/h3&gt;
&lt;p&gt;A set of diagnostic metrics assessing external predictivity:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( r^2_0 \), \( k \), \( k&#39; \), \( r_m^2 \), \( \Delta r_m^2 \)&lt;/li&gt;
&lt;li&gt;Good predictive models: \( k \approx 1 \), \( r_m^2 &gt; 0.5 \)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;y-randomization&#34;&gt;Y-Randomization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Randomize biological activities and rebuild the model.&lt;/li&gt;
&lt;li&gt;A valid QSAR will show &lt;strong&gt;low q² and r²&lt;/strong&gt; for randomized trials.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;contour-map-interpretation&#34;&gt;Contour Map Interpretation&lt;/h2&gt;
&lt;p&gt;CoMFA and CoMSIA produce &lt;strong&gt;contour maps&lt;/strong&gt; that visually indicate where modifications may enhance or reduce activity.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Steric maps&lt;/strong&gt;: Green = bulk-favorable; Yellow = bulk-unfavorable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Electrostatic maps&lt;/strong&gt;: Blue = electropositive-favorable; Red = electronegative-favorable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hydrophobic &amp;amp; H-bond maps&lt;/strong&gt;: Guide lipophilicity and hydrogen bonding optimization.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These maps serve as &lt;strong&gt;structure–activity roadmaps&lt;/strong&gt; for rational ligand design.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;summary-of-key-metrics&#34;&gt;Summary of Key Metrics&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Metric&lt;/th&gt;
          &lt;th&gt;Purpose&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;q²&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Internal predictivity (LOO-CV)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;r²&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Fit to training data&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;r²ₚᵣₑd&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;External predictive power&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;SEE&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Estimate of prediction error&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;F-statistic&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Significance of model&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;rₘ²&lt;/strong&gt;, Δrₘ²&lt;/td&gt;
          &lt;td&gt;Robustness (Tropsha criteria)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;RMSD&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Docking pose validation&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Y-randomization&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Protection against chance correlation&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Final Note:&lt;/strong&gt;&lt;br&gt;
A robust 3D-QSAR workflow is not solely about generating good statistical values — it is about building &lt;em&gt;interpretable models&lt;/em&gt; that reliably guide the design of novel, potent ligands.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Xu, Y., He, Z., Liu, H., Chen, Y., Gao, Y., Zhang, S., &amp;hellip; &amp;amp; Yang, M. (2020). 3D-QSAR, molecular docking, and molecular dynamics simulation study of thieno [3, 2-b] pyrrole-5-carboxamide derivatives as LSD1 inhibitors. RSC advances, 10(12), 6927-6943.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Comprehensive Guide to Hybrid Assembly Pipeline for Genomic Sequencing</title>
      <link>https://yboulaamane.github.io/blog/a-comprehensive-guide-to-hybrid-assembly-pipeline-for-genomic-sequencing/</link>
      <pubDate>Thu, 11 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/a-comprehensive-guide-to-hybrid-assembly-pipeline-for-genomic-sequencing/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Microbes, life&amp;rsquo;s unseen workhorses, hold immense potential for bioremediation, medicine, and understanding our planet. Yet, their intricate workings remain largely a mystery. This is where microbial genomics steps in, offering a powerful tool to decode their genetic language. Genomic sequencing has revolutionized our understanding of microbial diversity and function.&lt;/p&gt;
&lt;p&gt;In this guide, we&amp;rsquo;ll walk through a &lt;strong&gt;hybrid assembly pipeline&lt;/strong&gt;, combining long reads (ONT) and short reads (Illumina), using tools for quality control, assembly, polishing, and assessment.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;h3 id=&#34;using-anaconda-for-package-management&#34;&gt;Using Anaconda for Package Management&lt;/h3&gt;
&lt;p&gt;
 - simplifies installing and managing bioinformatics tools.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda create --name myenv
conda activate myenv
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;quality-control-tools&#34;&gt;Quality Control Tools&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
 - visualize quality metrics of long reads (ONT/PacBio).&lt;/li&gt;
&lt;li&gt;
 - generate quality reports for short reads (Illumina).&lt;/li&gt;
&lt;li&gt;
 - filter and trim long reads by quality and length.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assembly&#34;&gt;Assembly&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
 - long-read assembler optimized for ONT and PacBio data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;polishing&#34;&gt;Polishing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
 - ONT neural-network-based polishing tool.&lt;/li&gt;
&lt;li&gt;
 - short-read aligner for mapping Illumina reads to assemblies.&lt;/li&gt;
&lt;li&gt;
 - polishing tool that uses short-read alignments to correct assembly errors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;assembly-assessment&#34;&gt;Assembly Assessment&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
 - assess genome completeness using universal single-copy orthologs.&lt;/li&gt;
&lt;li&gt;
 - evaluate assembly quality with metrics like N50, misassemblies, and GC content.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hybrid-assembly-pipeline&#34;&gt;Hybrid Assembly Pipeline&lt;/h2&gt;
&lt;h3 id=&#34;quality-control&#34;&gt;Quality Control&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;For Long Reads (ONT):&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p nanoplot_lr_raw
NanoPlot --fastq LR_input.fastq --N50 --verbose --outdir nanoplot_lr_raw/ -t 8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;For Short Reads (Illumina):&lt;/strong&gt;
mkdir -p fastqc_reports
fastqc SR_input_1.fastq SR_input_2.fastq -o fastqc_reports/ -t 8&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;filter-long-reads&#34;&gt;Filter Long Reads&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;filtlong -1 SR_input_1.fastq -2 SR_input_2.fastq --min_length 1000 --keep_percent 90 LR_input.fastq &amp;gt; LR_filtered.fastq
mkdir -p nanoplot_lr_filtered
NanoPlot --fastq LR_filtered.fastq --N50 --verbose --outdir nanoplot_lr_filtered/ -t 8
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;long-reads-assembly-flye&#34;&gt;Long Reads Assembly (Flye)&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;flye --nano-raw LR_filtered.fastq --out-dir Flye/ --threads 8 --scaffold -g 6m
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;first-polishing-medaka&#34;&gt;First Polishing (Medaka)&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;conda activate medaka
medaka_consensus -i LR_filtered.fastq -d Flye/assembly.fasta -o Polish1/ -m r941_min_fast_g303 -t 8
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;second-polishing-polypolish&#34;&gt;Second Polishing (Polypolish)&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p Polish2
bwa index Polish1/consensus.fasta
bwa mem -t 8 -a Polish1/consensus.fasta SR_input_1.fastq &amp;gt; Polish2/alignments_1.sam
bwa mem -t 8 -a Polish1/consensus.fasta SR_input_2.fastq &amp;gt; Polish2/alignments_2.sam

polypolish_insert_filter.py   --in1 Polish2/alignments_1.sam   --in2 Polish2/alignments_2.sam   --out1 Polish2/filtered_1.sam   --out2 Polish2/filtered_2.sam

polypolish Polish1/consensus.fasta   Polish2/filtered_1.sam   Polish2/filtered_2.sam &amp;gt; final_assembly.fasta
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;assembly-quality-assessment&#34;&gt;Assembly Quality Assessment&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;conda activate busco
busco -i final_assembly.fasta -l bacteria_odb10 -m genome -o busco_final_assembly

quast -o quast_final_assembly -t 8 final_assembly.fasta
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;annotation-for-16s-rrna&#34;&gt;Annotation for 16S rRNA&lt;/h2&gt;
&lt;h3 id=&#34;prokka&#34;&gt;Prokka&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge -c bioconda prokka
prokka --outdir prokka_annotation --prefix final_assembly final_assembly.fasta
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;rast&#34;&gt;RAST&lt;/h3&gt;
&lt;p&gt;Submit the genome via the 
 for functional annotation.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;bottom-line&#34;&gt;Bottom Line&lt;/h2&gt;
&lt;p&gt;This hybrid assembly pipeline, coupled with annotation tools like Prokka and RAST, empowers researchers to unravel microbial genomes. Combining long and short reads with rigorous QC and assessment ensures a reliable, accurate representation of genomic information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data-Driven Chemistry: How Data Science Empowers Drug Discovery</title>
      <link>https://yboulaamane.github.io/blog/data-driven-chemistry-how-data-science-empowers-drug-discovery/</link>
      <pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/data-driven-chemistry-how-data-science-empowers-drug-discovery/</guid>
      <description>&lt;p&gt;In today&amp;rsquo;s digital era, the vast expanse of data permeates every aspect of our lives. From online interactions to industrial processes, we find ourselves immersed in an ever-growing sea of information. Yet, the true value of this data lies in the &lt;strong&gt;insights&lt;/strong&gt; it can provide. This is where &lt;strong&gt;data science&lt;/strong&gt; steps in – the art and science of extracting meaningful patterns and insights from data to drive innovation and solve complex problems. Nowhere is this more evident than in the realm of chemistry, where data science is revolutionizing how we understand and manipulate molecules.&lt;/p&gt;
&lt;h2 id=&#34;understanding-data-science-in-chemistry&#34;&gt;Understanding Data Science in Chemistry&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Data Science&lt;/strong&gt;, an interdisciplinary field, employs mathematical and computational approaches to derive valuable insights from structured, semi-structured, or unstructured data. It encompasses skills such as &lt;strong&gt;statistics&lt;/strong&gt;, &lt;strong&gt;machine learning&lt;/strong&gt;, &lt;strong&gt;programming&lt;/strong&gt;, &lt;strong&gt;data visualization&lt;/strong&gt;, and domain expertise. This diverse toolkit empowers scientists to explore and extract knowledge from an array of chemical data, ranging from molecular structures to reaction kinetics and spectroscopic signatures.&lt;/p&gt;
&lt;h2 id=&#34;the-data-science-process-in-chemistry&#34;&gt;The Data Science Process in Chemistry&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Problem Definition&lt;/strong&gt;: The cornerstone of any scientific endeavor is a clearly defined problem. In the context of chemistry, this involves identifying the goal of the analysis, be it predicting molecular properties or optimizing chemical reactions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Collection and Cleaning&lt;/strong&gt;: Gathering and preparing data from various sources is crucial. This step ensures that the data is accurate, reliable, and ready for analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Exploration&lt;/strong&gt;: Delving into the data reveals trends, patterns, and relationships, providing critical insights into molecular behavior.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Modeling&lt;/strong&gt;: Building mathematical models and algorithms is the heart of data science. In chemistry, this translates to creating predictive models for molecular properties or reaction outcomes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: Rigorous assessment of model performance using appropriate metrics ensures the reliability of the results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Bringing the model into a production environment enables real-world applications, from drug discovery to materials development.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Monitoring and Maintenance&lt;/strong&gt;: Continuous vigilance ensures the model&amp;rsquo;s accuracy over time, allowing for necessary updates and improvements.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;data-sciences-impact-on-chemistry-and-molecules&#34;&gt;Data Science&amp;rsquo;s Impact on Chemistry and Molecules&lt;/h2&gt;
&lt;p&gt;The marriage of data science and chemistry has ushered in a new era of scientific inquiry. By applying statistical models and machine learning algorithms to vast quantities of chemical data, scientists can identify hidden patterns, make accurate predictions, and guide experimental design. This not only advances our fundamental understanding of chemistry but also opens doors to practical applications in drug discovery, materials development, and sustainable energy technologies.&lt;/p&gt;
&lt;h2 id=&#34;looking-ahead&#34;&gt;Looking Ahead&lt;/h2&gt;
&lt;p&gt;As the volume and complexity of chemical data continue to grow, the demand for professionals skilled in both chemistry and data science is set to rise. Embracing data-driven methodologies in chemical investigations will undoubtedly lead to remarkable advancements. The integration of these complementary disciplines holds the promise of enhancing scientific understanding and driving innovation in ways we once deemed unimaginable.&lt;/p&gt;
&lt;p&gt;In conclusion, the convergence of data science and chemistry marks a transformative moment in scientific exploration. By leveraging the power of data, we unlock the true potential of molecules, paving the way for groundbreaking discoveries that will shape the future of chemistry and beyond.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using PaDELPy to Generate Molecular Fingerprints for Machine Learning-Based QSAR</title>
      <link>https://yboulaamane.github.io/blog/using-padelpy-generate-molecular-fingerprints-machine-learning-based-qsar/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/using-padelpy-generate-molecular-fingerprints-machine-learning-based-qsar/</guid>
      <description>&lt;p&gt;PaDELPy is a Python library that integrates the PaDEL-Descriptor molecular descriptor calculation software, allowing efficient generation of molecular fingerprints for machine learning-based quantitative structure-activity relationship (QSAR) models in drug discovery.&lt;/p&gt;
&lt;p&gt;Machine learning models, created by training algorithms to recognize data patterns, can be either supervised or unsupervised, applied in classification, regression, and more. Here, we’ll explore using PaDELPy to generate fingerprints that are crucial in predictive QSAR modeling, specifically targeting molecular activity prediction within the HCV Drug dataset.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225259643-df0568cd-1cfe-4395-aa7e-980902108f25.png&#34; alt=&#34;Molecular Fingerprint&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;what-is-padelpy&#34;&gt;What Is PaDELPy?&lt;/h2&gt;
&lt;p&gt;PaDELPy is a Python wrapper for the Java-based PaDEL-Descriptor software, streamlining molecular descriptor calculations. With PaDELPy, you can easily compute molecular fingerprints, avoiding the complexity of Java setup and reducing the time required for implementation.&lt;/p&gt;
&lt;h2 id=&#34;getting-started-with-the-code&#34;&gt;Getting Started with the Code&lt;/h2&gt;
&lt;p&gt;In this tutorial, we will create a machine learning model using Random Forest to predict molecular activity within the HCV Drug dataset. The dataset is available 
.&lt;/p&gt;
&lt;p&gt;To install the PaDELPy library, use the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Installing the library
!pip install padelpy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Download and configure XML data files required by PaDELPy:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Downloading XML data files
!wget https://github.com/dataprofessor/padel/raw/main/fingerprints_xml.zip
!unzip fingerprints_xml.zip


# Listing and sorting downloaded files
import glob
xml_files = glob.glob(&amp;quot;*.xml&amp;quot;)
xml_files.sort()
xml_files
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[&#39;AtomPairs2DFingerprintCount.xml&#39;, &#39;AtomPairs2DFingerprinter.xml&#39;, &#39;EStateFingerprinter.xml&#39;, ...]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a list of available fingerprint types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Creating a list of present files
FP_list = [&#39;AtomPairs2DCount&#39;, &#39;AtomPairs2D&#39;, &#39;EState&#39;, &#39;CDKextended&#39;, &#39;CDK&#39;, &#39;CDKgraphonly&#39;, 
		   &#39;KlekotaRothCount&#39;, &#39;KlekotaRoth&#39;, &#39;MACCS&#39;, &#39;PubChem&#39;, &#39;SubstructureCount&#39;, &#39;Substructure&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a data dictionary of file names for easy reference:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Creating Data Dictionary
fp = dict(zip(FP_list, xml_files))
fp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After setting up, load the dataset:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Loading the dataset
import pandas as pd
df = pd.read_csv(&#39;https://raw.githubusercontent.com/dataprofessor/data/master/HCV_NS5B_Curated.csv&#39;)
df.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prepare the data by concatenating necessary columns:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Concatenating necessary columns
df2 = pd.concat([df[&#39;CANONICAL_SMILES&#39;], df[&#39;CMPD_CHEMBLID&#39;]], axis=1)
df2.to_csv(&#39;molecule.smi&#39;, sep=&#39;\t&#39;, index=False, header=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Select a fingerprint type and calculate descriptors:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Setting the fingerprint module
from padelpy import padeldescriptor
fingerprint = &#39;Substructure&#39;
fingerprint_output_file = &#39;&#39;.join([fingerprint, &#39;.csv&#39;])  # Substructure.csv
fingerprint_descriptortypes = fp[fingerprint]

padeldescriptor(mol_dir=&#39;molecule.smi&#39;, 
				d_file=fingerprint_output_file,
				descriptortypes=fingerprint_descriptortypes,
				detectaromaticity=True,
				standardizenitro=True,
				standardizetautomers=True,
				threads=2,
				removesalt=True,
				log=True,
				fingerprints=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Display calculated fingerprints:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;descriptors = pd.read_csv(fingerprint_output_file)
descriptors.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating a Random Forest Model
Using the processed data, create a Random Forest model for classification.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;X = descriptors.drop(&#39;Name&#39;, axis=1)
y = df[&#39;Activity&#39;]  # Target variable

# Removing low variance features
from sklearn.feature_selection import VarianceThreshold

def remove_low_variance(input_data, threshold=0.1):
	selection = VarianceThreshold(threshold)
	selection.fit(input_data)
	return input_data[input_data.columns[selection.get_support(indices=True)]]

X = remove_low_variance(X, threshold=0.1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Split data into training and testing sets:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Splitting into Train and Test sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Train the Random Forest model:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=500, random_state=42)
model.fit(X_train, y_train)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evaluate model performance using Matthews Correlation Coefficient (MCC):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Making predictions
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)


# Calculating MCC for train and test
from sklearn.metrics import matthews_corrcoef
mcc_train = matthews_corrcoef(y_train, y_train_pred)
mcc_test = matthews_corrcoef(y_test, y_test_pred)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perform 5-fold cross-validation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
performance_metrics = pd.DataFrame({
	&#39;Model&#39;: [&#39;Random Forest&#39;],
	&#39;MCC_Train&#39;: [mcc_train],
	&#39;MCC_CV&#39;: [mcc_cv],
	&#39;MCC_Test&#39;: [mcc_test]
})
performance_metrics
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Consolidate performance metrics into a single DataFrame:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
performance_metrics = pd.DataFrame({
	&#39;Model&#39;: [&#39;Random Forest&#39;],
	&#39;MCC_Train&#39;: [mcc_train],
	&#39;MCC_CV&#39;: [mcc_cv],
	&#39;MCC_Test&#39;: [mcc_test]
})
performance_metrics
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this tutorial, we explored using PaDELPy to calculate molecular fingerprints, then developed a Random Forest model to predict molecular drug activity. The high Matthews Correlation Coefficient values suggest that this model is effective on the current dataset, though other algorithms could also be evaluated for further optimization.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Molecular Dynamics Simulations</title>
      <link>https://yboulaamane.github.io/blog/understanding-molecular-dynamics-simulations/</link>
      <pubDate>Sun, 12 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/understanding-molecular-dynamics-simulations/</guid>
      <description>&lt;p&gt;Hey there! Today, let&amp;rsquo;s talk about Molecular Dynamics (MD) simulation and how it can help us understand the behavior of complex molecular systems.
MD simulation works by creating an initial configuration of a system, including the positions, velocities, and masses of all atoms or molecules. The simulation then calculates the forces acting on each particle based on their interactions with other particles in the system.&lt;/p&gt;
&lt;p&gt;These forces are used to update the positions and velocities of each particle over a small time step, typically in the femtosecond to picosecond range. The simulation is repeated for many time steps, allowing the system to evolve over time.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/yboulaamane/yboulaamane.github.io/615fbbb664d302cce6cb72ed92b1e228ca3f45ec/_blog/5post-1.png&#34; alt=&#34;Figure1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 1:  Example MD simulation output plots&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;One of the coolest things about MD simulation is its ability to provide insights into the behavior of complex molecular systems that are difficult or impossible to study experimentally. For example, it can be used to study the behavior of proteins, which are crucial for many biological processes. By simulating the motion of individual atoms and molecules, researchers can gain insights into the structure and function of proteins, including how they interact with other molecules and how their structure changes over time.&lt;/p&gt;
&lt;p&gt;MD simulation is also widely used in the field of materials science. It can model the behavior of polymers, ceramics, metals, and other materials, providing insight into their mechanical properties, stability, and behavior under different conditions. By simulating the behavior of materials at the atomic scale, researchers can develop a deeper understanding of how they behave and how they can be optimized for specific applications.&lt;/p&gt;
&lt;p&gt;One of the strengths of MD simulation is its ability to model complex systems that have a large number of particles. Proteins, for example, are made up of thousands of atoms, making them difficult to study experimentally. However, by using MD simulation, researchers can study the behavior of these systems in detail, gaining insights into their structure, function, and behavior.&lt;/p&gt;
&lt;p&gt;Another advantage of MD simulation is its ability to simulate systems under a wide range of conditions, including different temperatures, pressures, and chemical environments. This makes it a powerful tool for studying how systems behave under different conditions and how they respond to changes in their environment.&lt;/p&gt;
&lt;p&gt;While MD simulation has its limitations, such as accurately modeling the interactions between particles and the computational cost, advances in computing technology have made it more accessible. Researchers are constantly developing new algorithms and techniques to improve the accuracy and efficiency of simulations.&lt;/p&gt;
&lt;p&gt;So, what are some common visualizations used in MD simulations? Trajectories show the positions of particles in a system over time, energy plots show the total energy of a system over time, radial distribution functions measure how particles are distributed around a central particle, and density plots show the density of particles in a system as a function of position.&lt;/p&gt;
&lt;p&gt;In conclusion, MD simulation is a powerful tool for studying the behavior of complex molecular systems, from proteins to materials. It has the potential to provide new insights into a wide range of scientific and technological applications, from drug design to energy storage. If you&amp;rsquo;re interested in learning more about MD simulation, be sure to check out the different types of simulations and visualizations used in the field.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How Long Should Molecular Dynamics Simulations Run? A Practical Guide</title>
      <link>https://yboulaamane.github.io/blog/determining-the-appropriate-length-for-proteinligand-md-simulations/</link>
      <pubDate>Mon, 09 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/determining-the-appropriate-length-for-proteinligand-md-simulations/</guid>
      <description>&lt;p&gt;Molecular dynamics (MD) simulations are a central technique in computational drug discovery, offering atomistic insights into the behavior of protein-ligand complexes. One of the most common practical questions when setting up such simulations is: &lt;em&gt;How long should they run?&lt;/em&gt; The answer depends heavily on the complexity of the system, the research question, and the type of molecular events you aim to observe.&lt;/p&gt;
&lt;h2 id=&#34;general-timeframes-for-proteinligand-simulations&#34;&gt;General Timeframes for Protein–Ligand Simulations&lt;/h2&gt;
&lt;p&gt;There is no one-size-fits-all answer, but several time ranges have become standard based on prior experience and published studies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;50–100 nanoseconds&lt;/strong&gt;: Typically sufficient for analyzing initial binding stability, particularly with small, rigid ligands and relatively stable protein structures.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;100–200 nanoseconds&lt;/strong&gt;: Useful for exploring ligand flexibility, side-chain reorganization, or early conformational transitions within the binding pocket.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;200–500 nanoseconds&lt;/strong&gt;: Recommended for studying slower events, such as partial unbinding, induced fit mechanisms, or domain-level conformational shifts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;500 nanoseconds to 1 microsecond (or more)&lt;/strong&gt;: Required when investigating long-timescale processes, such as allosteric communication, full ligand unbinding, or global protein rearrangements.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are only guidelines. The required simulation time may vary considerably depending on the nature of the system and the endpoints of interest.&lt;/p&gt;
&lt;h2 id=&#34;assessing-convergence-when-can-you-trust-the-results&#34;&gt;Assessing Convergence: When Can You Trust the Results?&lt;/h2&gt;
&lt;p&gt;In MD simulations, convergence refers to the point at which key structural and energetic properties stabilize. If your system hasn&amp;rsquo;t converged, any conclusions drawn—no matter how long the simulation—may be unreliable.&lt;/p&gt;
&lt;h3 id=&#34;key-convergence-metrics&#34;&gt;Key Convergence Metrics&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1. Root Mean Square Deviation (RMSD)&lt;/strong&gt;&lt;br&gt;
Tracks the structural deviation of atoms (commonly the protein backbone) over time. A stable RMSD plateau suggests that the structure has equilibrated. A continually rising RMSD implies ongoing rearrangement or instability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Root Mean Square Fluctuation (RMSF)&lt;/strong&gt;&lt;br&gt;
Measures per-residue flexibility across the simulation. Once the system is stable, RMSF profiles tend to show consistent patterns across time windows. Large fluctuations may signal that equilibrium has not been achieved.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Energy Stability&lt;/strong&gt;&lt;br&gt;
Monitoring total, potential, and kinetic energy can help confirm that the system has reached thermodynamic equilibrium. Sharp energy fluctuations or long-term drift suggest insufficient equilibration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Secondary Structure Content&lt;/strong&gt;&lt;br&gt;
For proteins, consistent secondary structure (e.g., helices, sheets) is a good indicator of folding stability. If secondary structures shift frequently, especially after the initial equilibration period, further simulation may be needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. Interaction Fingerprint Stability&lt;/strong&gt;&lt;br&gt;
The persistence of key protein-ligand contacts—hydrogen bonds, salt bridges, π–π stacking, etc.—is critical. Stable interaction profiles across the trajectory indicate that the binding pose is likely valid.&lt;/p&gt;
&lt;h2 id=&#34;an-illustrative-scenario&#34;&gt;An Illustrative Scenario&lt;/h2&gt;
&lt;p&gt;Consider a protein-ligand system where the RMSD increases during the first 50 nanoseconds as the complex settles into a favorable binding mode. Around 100 nanoseconds, the RMSD plateaus, interaction fingerprints become consistent, and total energy stabilizes. These indicators suggest the system has likely converged, and extending the simulation might not yield significantly different results.&lt;/p&gt;
&lt;p&gt;On the other hand, if the ligand continues to shift within the binding pocket or protein domains undergo progressive rearrangement, longer simulations or enhanced sampling approaches may be required.&lt;/p&gt;
&lt;h2 id=&#34;factors-influencing-simulation-time&#34;&gt;Factors Influencing Simulation Time&lt;/h2&gt;
&lt;p&gt;Several variables determine how long your simulation should run:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System size and flexibility&lt;/strong&gt;: Larger and more flexible proteins typically require longer simulations to sample relevant conformational space.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ligand dynamics&lt;/strong&gt;: Flexible or highly rotatable ligands may explore multiple poses, requiring more time to identify dominant binding modes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scientific objective&lt;/strong&gt;: Short simulations may suffice for pose validation, while mechanistic studies (e.g., unbinding) demand longer runs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Replicates&lt;/strong&gt;: Multiple shorter runs can often provide better statistical reliability than a single long trajectory.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Convergence monitoring&lt;/strong&gt;: Regularly assess key observables (RMSD, energy, interactions) to determine whether additional sampling is necessary.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;final-thoughts&#34;&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;For most protein-ligand MD simulations, a range of 50 to 200 nanoseconds is typically sufficient for analyzing pose stability and interaction patterns. However, in cases where you’re studying complex events—such as ligand unbinding, allosteric modulation, or major conformational shifts—longer simulations may be warranted. Ultimately, simulation length should be guided not by arbitrary cutoffs, but by careful monitoring of convergence and system behavior over time.&lt;/p&gt;
&lt;p&gt;Be cautious when interpreting results from under-converged simulations. Without evidence of structural or energetic stability, conclusions about binding modes or molecular mechanisms may be premature.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Supervised vs. Unsupervised Methods in Machine Learning</title>
      <link>https://yboulaamane.github.io/blog/supervised-vs-unsupervised-methods-machine-learning/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/supervised-vs-unsupervised-methods-machine-learning/</guid>
      <description>&lt;p&gt;The increasing volume of biomedical data in chemistry and life sciences requires development of new methods and approaches for their analysis. New approaches have proved to show improvement and accelerate the joint drug discovery and development processes.
The accumulation of large datasets allows for better integration of machine learning and artificial intelligence to build and integrate more accurate models for predicting the bioactivity and the pharmacokinetics of new drugs in the pharmaceutical field.
Machine learning approaches are divided into three broad categories, which correspond to learning patterns, depending on the nature of the &amp;ldquo;signal&amp;rdquo; or &amp;ldquo;feedback&amp;rdquo; available to the learning system.&lt;/p&gt;
&lt;h2 id=&#34;1-supervised-learning&#34;&gt;1. Supervised learning&lt;/h2&gt;
&lt;p&gt;Machine learning models are supervised by loading them with knowledge so that we can have it predict future instances. Teaching the model requires training it with some data from a labeled dataset.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256631-3a7927f8-0f0e-4c3a-9220-70bc0496e4db.png&#34; alt=&#34;Figure1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 1: Example of a chemical dataset viewed with Pandas.&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The names up here which are called: molecule_chembl_id and smiles are called attributes. Other names such as standard_value represents the numerical values for each sample, whereas the class name represents a categorical value which can be either 1 (active) or 0 (inactive). The columns are called features which include the data. If we plot this data, and look at a single data point on a plot, it&amp;rsquo;ll have all of these attributes that would make a row on this chart also referred to as an observation. Looking directly at the value of the data, you can have two kinds. The first is numerical, when dealing with machine learning, the most commonly used data is numeric. The second is categorical, that is its non-numeric because it contains characters rather than numbers. In this case, it&amp;rsquo;s categorical because this dataset is made for classification.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256633-ae720fd3-3c21-4cc5-bda4-4c4e8bdea928.png&#34; alt=&#34;Figure2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 2: Supervised learning.&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are two types of supervised learning techniques. They are classification, and regression. Classification is the process of predicting a discrete class label, or category. Wheras, regression is the process of predicting a continuous value as opposed to predicting a categorical value in classification.&lt;/p&gt;
&lt;h2 id=&#34;2-unsupervised-learning&#34;&gt;2. Unsupervised learning&lt;/h2&gt;
&lt;p&gt;Unsupervised models are exactly what they sound like, the models are left to work on their own to discover information that may not be visible to the human eye. It means, the unsupervised algorithm trains on the dataset, and draws conclusions on unlabeled data. Generally speaking, unsupervised learning has more difficult algorithms than supervised learning since we know little to no information about the data, or the outcomes that are to be expected. Dimension reduction, density estimation, market basket analysis, and clustering are the most widely used unsupervised machine learning techniques. Dimensionality reduction, and/or feature selection, play a large role in this by reducing redundant features to make the classification easier.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256636-fbbe6ac3-8726-46ff-aad4-9025c25bd75a.png&#34; alt=&#34;Figure3&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 3: Unsupervised learning tasks. Image by Dmytro Nikolaiev (medium.com/@andimid).&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Market basket analysis, on the other hand, is a modeling technique based upon the theory that if you buy a certain group of items, you&amp;rsquo;re more likely to buy another group of items.
Density estimation is a very simple concept that is mostly used to explore the data to find some structure within it.
Finally, clustering is consired to be one of the most popular unsupervised machine learning techniques used for grouping data points, or objects that are somehow similar.
Clustering analysis has many applications in different domains, whether it be a bank&amp;rsquo;s desire to segment his customers based on certain characteristics, or helping an individual to organize in-group his, or her favorite types of music. Broadly though, clustering is used mostly for discovering structure, summarization, and anamoly detection.&lt;/p&gt;
&lt;h2 id=&#34;bottom-line&#34;&gt;Bottom line&lt;/h2&gt;
&lt;p&gt;The biggest difference between supervised and unsupervised learning is that supervised learning deals with labeled data while unsupervised learning deals with unlabeled data. Supervised models employ machine learning algorithms for classification and regression, whereas in unsupervised learning, we have methods such as clustering. In comparison to supervised learning, unsupervised learning has fewer models and fewer evaludation methods that can be used to ensure the outcome of the model is accurate. As such, unsupervised learning creates a less controllable environment as the machine is creating outcomes for us.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chemical Databases Every ML Scientist Should Know for Drug Discovery</title>
      <link>https://yboulaamane.github.io/blog/chemical-databases-machine-learning-drug-discovery/</link>
      <pubDate>Mon, 12 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/chemical-databases-machine-learning-drug-discovery/</guid>
      <description>&lt;p&gt;The ever-increasing bioactivity data that are produced nowadays allow exhaustive data mining and knowledge discovery approaches that change chemical biology research.
A wealth of cheminformatics tools, web services, and applications therefore exists that supports a careful evaluation and analysis of experimental data to draw conclusions that can influence the further development of chemical probes and potential lead structures.&lt;/p&gt;
&lt;h2 id=&#34;1chembl-database&#34;&gt;1.	ChEMBL database&lt;/h2&gt;
&lt;p&gt;ChEMBL is a manually curated database of bioactive molecules with drug-like properties. It brings together chemical and bioactivity data to aid the translation of information into effective new drugs.
Bioactivity data is reported in Ki, Kd, IC50, % of inhibition and EC50. Data can be filtered and analyzed to develop compound screening libraries for lead identification during the drug discovery process.
The availability of curated bioactivity data on small drug-like molecules opens new opportunities for data-driven drug discovery and makes it possible to apply machine learning methodologies to pharmaceutical research field.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225255287-ba98137b-11c2-44e2-8e2e-4f93c26210da.png&#34; alt=&#34;Figure1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 1: Web interface of ChEMBL database (
)&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;2-bindingdb&#34;&gt;2. BindingDB&lt;/h2&gt;
&lt;p&gt;BindingDB is a public database of experimental binding affinities of interactions between macromolecules and small molecules. It contains more than 1.2 million binding data points for more than 6,400 protein targets and around 550,000 small molecules. Furthermore, affinities for protein-protein, protein-peptide as well as host-guest interactions are provided.
BindingDB provides a wide range of searches, possible queries, tools and datasets.
BindingDB also provides a virtual compound screening tool with which the user has the possibility to screen an external dataset of compounds for similar bioactivity.
BindingDB also provides a virtual compound screening tool with which the user has the possibility to screen an external dataset of compounds for similar bioactivity. Access is given by a download option (SD-file, tab-separated value (TSV) or Oracle dump) or by programmatic access (RESTful API, structured URLs, or KNIME).&lt;/p&gt;
&lt;h3 id=&#34;21find-my-compounds-target-tool&#34;&gt;2.1.	Find My Compound’s Target tool&lt;/h3&gt;
&lt;p&gt;Find My Compound’s Target is a tool integrated in BindingDB that aims to predict the target of a small molecule of interest or possible off-targets. The query compound is first compared to other compounds in the database and targets of these compounds are selected if the compounds’ similarity is above the chosen cut-off and the affinity is respectively above a certain threshold.&lt;/p&gt;
&lt;h3 id=&#34;22find-compounds-for-my-target&#34;&gt;2.2.	Find Compounds for My Target&lt;/h3&gt;
&lt;p&gt;Find Compounds for My Target is another tool that tries to find compounds for a specific target. It features advanced search and extraction of curated information from various data sources such as ChEMBL database, PubChem bioassays, D3R, etc.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225255388-5fd0130e-4b2d-48e9-b3c8-891a32bc64d3.png&#34; alt=&#34;Figure2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 2: Web interface of BindingDB (
)&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;3pubchem-bioassays-database&#34;&gt;3.	Pubchem Bioassays Database&lt;/h2&gt;
&lt;p&gt;PubChem is an American database of chemical molecules managed by the National Center for Biotechnology Information (NCBI), branch of the National Library of Medicine of the United States under the authority of the National Institutes of Health (NIH).
PubChem lists several million compounds by putting a large amount of data of various kinds online for each substance free of charge: chemical, biochemical, pharmacological, production, toxicological, environmental, etc.
PubChem BioAssay stores the activity data of small molecules or RNAi and contains curated parts of ChEMBL for which flags for active or inactive compounds are assigned depending on whether the IC50, EC50 or Ki is above 50 μM or not. The data can be accessed and analyzed via a broad range of provided web services and tools (Figure1). Besides using a name, a smiles code can be used or a structure can be drawn to search for an identical molecule, a similar molecule or a substructure. This
leads to information about bioassay results or substance descriptions. Variations of assay results can be analyzed using detailed description of the performed experiments. The data is additionally clustered, e.g., according to the protein or gene target, the type of assay (e.g., cell-based, protein-protein interaction), an assay project or more complex kinds of relationships like target similarity or common active compounds.&lt;/p&gt;
&lt;h3 id=&#34;31pubchempy&#34;&gt;3.1.	PubChemPy&lt;/h3&gt;
&lt;p&gt;PubChemPy offers a way to use and interact with PubChem database directly with Python. It allows chemical searches by name, substructure and similarity, chemical standardization, conversion between chemical file formats, depiction and retrieval of chemical properties. For more information on installing and using PubChemPy package visit the official website (
.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225255636-e925217b-46af-494e-ad91-aa9a0bce1c70.png&#34; alt=&#34;Figure3&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 3: PubChem web interface (
)&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;4pdbbind-database&#34;&gt;4.	PDBbind Database&lt;/h2&gt;
&lt;p&gt;The PDBbind database is a comprehensive collection of experimentally measured binding affinity data (Kd, Ki, and IC50) for the protein-ligand complexes deposited in the Protein Data Bank (PDB). It thus provides a link between energetic and structural information of protein-ligand complexes, which is of great value to various studies on molecular recognition occurred in biological systems.
The basic information of each complex in PDBbind is totally open for browsing. Users are however required to register for access under a license agreement in order to utilize the full functions provided on this web site or to download the contents of PDBbind. The registration is free of charge to all academic and industrial users.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225255699-98f165ba-aa84-4e3b-a27b-59cfc8336670.png&#34; alt=&#34;Figure4&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 4: PDBbind web interface (
)&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;5brenda-enzyme-database&#34;&gt;5.	BRENDA Enzyme Database&lt;/h2&gt;
&lt;p&gt;BRENDA is an enzyme database. It is maintained and developed by the Institute of Biochemistry of the University of Cologne. Data on enzyme functions are taken directly from the primary literature. The database covers 40 entries, with information about enzyme nomenclature, reactions, specificity, structure, method of isolation or preparation, references in scientific literature and cross-references for the sequence or 3D structure.
The database is accessible free of charge for academic and non-profit uses, commercial uses need to acquire a license. To use the database, it is necessary to register by email. The database can be searched by EC nomenclature, enzyme name, organism or an advanced search combining these entries.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225255851-4af4a174-320d-47a5-a9cb-9a7f04fdcba5.png&#34; alt=&#34;Figure5&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 5: Brenda Enzymes Database web interface (
)&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This article has sought to provide an overview of freely available chemical databases that can be readily used for machine learning approaches that support the major research trends in drug discovery. The ever-increasing amount of data and the improvement of analytical tools hold the potential to transform the drug development, leading to new treatments, improved patient outcomes, and lower costs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How to Perform Data Curation and Classify Bioactivity Data on ChEMBL Database</title>
      <link>https://yboulaamane.github.io/blog/perform-data-curation-classify-bioactivity-data-chembl-database/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://yboulaamane.github.io/blog/perform-data-curation-classify-bioactivity-data-chembl-database/</guid>
      <description>&lt;p&gt;The ChEMBL database is a manually curated resource of bioactive molecules with drug-like properties, integrating chemical, bioactivity, and genomic data to facilitate the translation of genomic information into new drugs.
As of February 2022, ChEMBL version 30 contains over 2.2 million compound records, 1.5 million assays, and spans 14,000 targets, 2,000 cells, and 43,000 indications. The database has continued to grow significantly in both scope and scale, with the most recent release, ChEMBL 33, in May 2023, containing 2,786,911 compound records. ChEMBL is an essential resource for the scientific community, enabling the investigation of various health-related and scientific questions [1-3].&lt;/p&gt;
&lt;h2 id=&#34;1-data-search&#34;&gt;1. Data search&lt;/h2&gt;
&lt;p&gt;The first step to use this database is to search the ChEMBL database using keywords of a target protein of interest, it is possible to run a search using other keywords related to diseases, compounds or assays. In this tutorial, we are going to search for Acetylcholinesterase as illustrated in Figure 1.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256089-5c72e4cc-f77c-4ee8-90ea-f548343b5ac4.png&#34; alt=&#34;Figure1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 1: ChEMBL search result example&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notice that our search resulted on 24 targets, it is important to choose the right protein for the right organism of the study of interest. For this example, we are interested in human Acetylcholinesterase corresponding to the ID: CHEMBL220.
After clicking on the target, we will be sent to another page containing all the data concerning the selected target such as: name and classification, drugs and clinical candidates, activity charts, etc.
Scroll down to activity charts and notice the pie chart on the left concerning all the associated bioactivity data compiled from the literature and their distribution according to the activity type.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256100-351cffcb-dc10-4d4a-949c-07397f6b4bb6.png&#34; alt=&#34;Figure2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 2: Activity charts and distribution of activity types of the selected target, CHEMBL220&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Upon observation of the activity chart, we can quickly determine which activity type is the most reported in the literature, in this case it refers to half-maximal inhibitory concentrations (IC50) which have been reported 8205 times.
Once we click on the desired activity type, we can download the entire dataset in CSV or TSV Format containing various informations such as ChEMBL ID for each compound, SMILES, Standard Type and Standard Value referring to the activity type and value respectively.##&lt;/p&gt;
&lt;h2 id=&#34;2-data-curation&#34;&gt;2. Data curation&lt;/h2&gt;
&lt;p&gt;Note that it is necessary to remove any unwanted data before proceeding with data curation. In this case, we are only interested in the compound’s IDs, Smiles, Standard Type and Standard Value. It is possible to perform this task with any CSV reader such as Google Sheets or Microsoft Excel.
Once we have performed the primary cleaning on our data, we can import it on Google Colab or Jupyter Notebook using the code below:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Import necessary libraries&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Read the dataset&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x=pd.read_csv(&#39;ache.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Display the dataset&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256101-c4f9bfc6-652b-46da-af63-dbcab7c91255.png&#34; alt=&#34;Figure3&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 3: AChE curated dataset output.&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;21-remove-duplicate-compounds&#34;&gt;2.1. Remove duplicate compounds&lt;/h3&gt;
&lt;p&gt;When dealing with a large dataset of compounds, it is very likely to find a great deal of duplicates with different reported activities due to different conditions of each laboratory. However, it is possible to deal with this issue by averaging all reported activity by calculating their mean values using the code below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x[&amp;quot;mean_value&amp;quot;]=x[[&#39;Molecule ChEMBL ID&#39;, &#39;Smiles&#39;,&#39;Standard Type&#39;,&#39;Standard Value&#39;]].groupby([&#39;Molecule ChEMBL ID&#39;])[&#39;Standard Value&#39;].transform(&amp;quot;mean&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to merge all the duplicate compounds into one, for this reason we can use the code below to remove all duplicates while keeping only the first one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x=x.drop_duplicates(&amp;quot;Molecule ChEMBL ID&amp;quot;, keep=&amp;quot;first&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256109-4ce6979f-0e42-469a-8191-459dc6530c3b.png&#34; alt=&#34;Figure4&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 4: Pandas output of AChE dataset after removing duplicate compounds.&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It is possible to find some compounds on the dataset with no available activity, notice on the sheet above that some activities are marked with “NaN” which stands for “Not a Number” in computer science, it is therefore necessary to remove them before proceeding. We can simply run the code below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x=x.dropna()
x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256112-91eb87c4-cbd7-424c-80fe-bb45ed014f31.png&#34; alt=&#34;Figure5&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 5: Final curated dataset.&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;3-data-classification&#34;&gt;3. Data classification&lt;/h2&gt;
&lt;p&gt;Once we have curated our data, now it is possible to classify compounds in order to apply it for machine learning classification models. For this reason, we need to define an activity cutoff to define our active and inactive compounds. In the case of enzyme inhibition, the literature indicates that most potent enzyme inhibitors have activities in the nanomolar range. For this reason, we can proceed by setting a threshold of 1000 nM corresponding to 1 μM or lower for defining our active compounds.&lt;/p&gt;
&lt;p&gt;Run the code below to create a variable with all active compounds:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;active=x.loc[x[&#39;mean_value&#39;]&amp;lt;=1000]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We do the same for inactive compounds by setting a cutoff of 10 000 nM (10 μM) or higher using the code below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;inactive=x.loc[x[&#39;mean_value&#39;]&amp;gt;10000]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-data-labelling&#34;&gt;4. Data labelling&lt;/h2&gt;
&lt;p&gt;Now that we have defined our active and inactive compounds, it is necessary to label the data in order to combine the entire dataset. We will simply refer to active compounds as “1” and inactive compounds as “0”.
Run the code below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;active[&amp;quot;Class&amp;quot;]=1
inactive[&amp;quot;Class&amp;quot;]=0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can proceed to combining the entire dataset.&lt;/p&gt;
&lt;p&gt;Run the code below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;combined=pd.concat([active,inactive],axis=0)
combined
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/7014404/225256117-a1a5f883-f733-4679-9ac5-668d4a82e708.png&#34; alt=&#34;Figure6&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;b&gt;Figure 6: Curated dataset with label column indicating whether the compound is active or inactive.&lt;/b&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Finally, we can save our dataset for further use.
Run the code below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;combined.to_csv(&amp;quot;ache_labelled.csv&amp;quot;, index=None)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;5-bottom-line&#34;&gt;5. Bottom line&lt;/h2&gt;
&lt;p&gt;This article’s aim was to demonstrate an alternative way to retrieve bioactivity data from ChEMBL without using code. Furthermore, data curation and data classification was covered in detail as it is a necessary step and can highly impact the performance of machine learning models. If you found this article useful, follow the blog for more tutorials in the future.&lt;/p&gt;
&lt;h2 id=&#34;6-references&#34;&gt;6. References&lt;/h2&gt;
&lt;p&gt;[1] 
&lt;/p&gt;
&lt;p&gt;[2] 
&lt;/p&gt;
&lt;p&gt;[3] 
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
